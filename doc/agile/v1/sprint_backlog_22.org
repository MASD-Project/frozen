#+title: Sprint Backlog 22
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Mission Statement

- Perform the variability model refactor, removing all direct
  dependencies to the physical model.
- Get a good grasp of the physical domain model.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2020-03-16 Mon 08:45]
| <75>                                                    |         |       |      |       |
| Headline                                                | Time    |       |      |     % |
|---------------------------------------------------------+---------+-------+------+-------|
| *Total time*                                            | *79:01* |       |      | 100.0 |
|---------------------------------------------------------+---------+-------+------+-------|
| Stories                                                 | 79:01   |       |      | 100.0 |
| Active                                                  |         | 79:01 |      | 100.0 |
| Edit release notes for previous sprint                  |         |       | 4:11 |   5.3 |
| Create a demo and presentation for previous sprint      |         |       | 0:25 |   0.5 |
| Sprint and product backlog grooming                     |         |       | 8:13 |  10.4 |
| Emacs configuration and issues                          |         |       | 1:02 |   1.3 |
| Analysis on defining a combined logical-physical space  |         |       | 5:55 |   7.5 |
| Analysis on removing physical references in variability |         |       | 5:27 |   6.9 |
| Remove =rapidjson= formatters                           |         |       | 0:03 |   0.1 |
| Separate feature templates from bundles                 |         |       | 9:28 |  12.0 |
| Move enabled to generation                              |         |       | 0:04 |   0.1 |
| Create a chain to encapsulate variability transforms    |         |       | 0:37 |   0.8 |
| Move variability chain into assets                      |         |       | 2:22 |   3.0 |
| Move profile meta-data into profile element             |         |       | 7:12 |   9.1 |
| Add handcrafted stereotype to C# models                 |         |       | 0:04 |   0.1 |
| Split profiles and profile templates in variability     |         |       | 4:31 |   5.7 |
| Consider renaming labels to stereotypes in variability  |         |       | 1:07 |   1.4 |
| Declaring a =std::list= without parameters segfaults    |         |       | 0:10 |   0.2 |
| Add location and modules to variability                 |         |       | 0:43 |   0.9 |
| Implement template instantiation in terms of tags       |         |       | 8:31 |  10.8 |
| Remove duplication from feature bundles and profiles    |         |       | 4:29 |   5.7 |
| Postfix and directory fields should be templates        |         |       | 3:55 |   5.0 |
| Default value overrides are not stable                  |         |       | 5:01 |   6.3 |
| Variability overrides in nightly are broken             |         |       | 0:24 |   0.5 |
| Add command line option to dump all specs               |         |       | 4:58 |   6.3 |
| Document all features                                   |         |       | 0:09 |   0.2 |
#+TBLFM: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2020-02-18 Tue 20:35]
    :LOGBOOK:
    CLOCK: [2020-02-18 Tue 20:30]--[2020-02-18 Tue 20:44] =>  0:14
    CLOCK: [2020-02-18 Tue 19:04]--[2020-02-18 Tue 19:34] =>  0:30
    CLOCK: [2020-02-18 Tue 18:02]--[2020-02-18 Tue 18:37] =>  0:35
    CLOCK: [2020-02-17 Mon 23:16]--[2020-02-18 Tue 00:23] =>  1:07
    CLOCK: [2020-02-17 Mon 22:44]--[2020-02-17 Mon 23:15] =>  0:31
    CLOCK: [2020-02-17 Mon 20:00]--[2020-02-17 Mon 20:10] =>  0:10
    CLOCK: [2020-02-17 Mon 19:51]--[2020-02-17 Mon 19:59] =>  0:08
    CLOCK: [2020-02-17 Mon 19:02]--[2020-02-17 Mon 19:58] =>  0:56
    :END:

Add github release notes for previous sprint.

Title: Dogen v1.0.21, "Nossa Senhora do Rosário"

#+BEGIN_SRC markdown
![Igreja de Nossa Senhora do Rosário](
https://upload.wikimedia.org/wikipedia/commons/thumb/b/b2/Church_in_Tombua%2C_Namibe%2C_Angola.JPG/1280px-Church_in_Tombua%2C_Namibe%2C_Angola.JPG)
_Igreja de Nossa Senhora do Rosário, Tombwa, Namibe, Angola. (C) 2010 Paulo César Santos._

# Introduction

Very much like an iceberg, this sprint was deceptively small on user features but big on internal changes: after several sprints of desperate chasing, we finally completed the mythical "fabric refactor". The coding work was not exactly glamorous, as we engaged on a frontal attack on all "quasi-meta-types" we had previously scattered across the codebase. One by one, each type was polished and moved into the assets meta-model, to be reborn anew as a fully-fledged modeling element. All the while, we tried to avoid breaking the world - but nevertheless did so, frequently. It was grueling work. Having said that, the end of the refactor made for a very exciting sprint, and though the war remains long, we can't help but feel an important battle was won.

So let's have a look at how it all went down.

# User visible changes

This section covers stories that affect end users, with the video providing a quick demonstration of the new features, and the sections below describing them in more detail. All features this sprint are related to the addition of new meta-model types, which resulted in a number of breaking changes. These we have highlighted with :warning:.

[![Sprint 1.0.21 Demo](https://img.youtube.com/vi/J5duq-gw-nI/0.jpg)](https://youtu.be/J5duq-gw-nI)
_Video 1: Sprint 21 Demo._

## New meta-model elements

As we explored the lay of the land of our problem domain, we inadvertently found ourselves allowing Dogen to evolve a "special" set of meta-types. These we used to model files deemed inferior in stature to _real source code_: mostly build-related material, but also some more "regular" source code which could be derived from existing elements - _e.g._ visitors, serialisation registrars and the like. Due to its second-class-citizen nature, these  "special types" were controlled via variability in haphazard ways. Over the years, a plethora of meta-data switches was introduced at the model level but, in the absence of a coherent overall plan, these were _ad-hoc_ and inconsistent. On the main, the switches were used to enable or disable the emission of these "special types", as well as to configure some of their properties. Table 1 provides a listing of these switches.

|Meta-data key|Description|
|-------------------------------------------------------------------------------------|---------------------------------------------------------|
|```masd.generation.cpp.cmake.enabled```|Enable the CMake facet.|
|```masd.generation.cpp.cmake.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.cmake.source_cmakelists.enabled```|Enable the CMakeLists file in ```src``` directory.|
|```masd.generation.cpp.cmake.source_cmakelists.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.cmake.include_cmakelists.enabled```|Enable the CMakeLists file in ```include``` directory.|
|```masd.generation.cpp.cmake.include_cmakelists.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.msbuild.enabled```|Enable the MSBuild facet.|
|```masd.generation.cpp.msbuild.targets.enabled```|Enable the MSBuild formatter for ODB targets.|
|```masd.generation.cpp.msbuild.targets.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.visual_studio.enabled```|Enable the Visual Studio facet.|
|```masd.generation.cpp.visual_studio.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.visual_studio.project_solution_guid```|GUID for the Visual studio solution.|
|```masd.generation.cpp.visual_studio.project_guid```|GUID for the Visual studio project.|
|```masd.generation.cpp.visual_studio.solution.enabled```|Enables a Visual Studio solution for C++.|
|```masd.generation.cpp.visual_studio.solution.postfix```|Postfix to use for filename.|
|```masd.generation.cpp.visual_studio.project.enabled```|Enables a Visual Studio solution for C++.|
|```masd.generation.cpp.visual_studio.project.postfix```|Postfix to use for filename.|
|```masd.generation.csharp.visual_studio.project_solution_guid```|GUID for the Visual studio solution.|
|```masd.generation.csharp.visual_studio.project_guid```|GUID for the Visual studio project.|
|```masd.generation.csharp.visual_studio.solution.enabled```|Enables a Visual Studio solution for C#.|
|```masd.generation.csharp.visual_studio.solution.postfix```|Postfix to use for filename.|
|```masd.generation.csharp.visual_studio.project.enabled```|Enables a Visual Studio project for C#.|
|```masd.generation.csharp.visual_studio.project.postfix```|Postfix to use for filename.|

_Table 1: Meta-data switches related to "special" types._

The meta-data was then latched on to model properties, like so:

```
#DOGEN masd.generation.cpp.msbuild.enabled=true
#DOGEN masd.generation.csharp.visual_studio.project_guid=9E645ACD-C04A-4734-AB23-C3FCC0F7981B
#DOGEN masd.generation.csharp.visual_studio.project_solution_guid=FAE04EC0-301F-11D3-BF4B-00C04F79EFBC
#DOGEN masd.generation.cpp.cmake.enabled=true
...
```

As we continued to mull over the problem across sprints, the entire idea of "implicit" element types - injected into the model and treated differently from regular elements - was [ultimately understood to be harmful](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_11.org#analyse-the-state-of-the-mess-of-refactors). The approach is in fact an _abuse_ of variability, due to how these elements had been (_mis-_)modeled. And it had consequences:

- **Invisibility**: it was not possible to manage variability of the injected types in the same fashion as for all other elements because they were "invisible" to the modeler.
- **Difficulty in troubleshooting**: it was hard to diagnose when something didn't work as expected, because all of the magic was internal to the code generator.
- **Inconsistency in generation**: we had a rather inconsistent way of handling different element types; some "just appeared" due to the state of the model (like ```registrar```); others were a consequence of enabling formatters (_e.g._ ```CMakeLists.txt```); still others required the presence of stereotypes (_e.g._ ```visitor```). It was very hard to explain the rationale for each of these to an unsuspecting user.
- **Inconsistency in population**: properties that were common to other elements had to be handled specially via meta-data. For example, adding comments or changing decoration for these elements required bespoke meta-data and associated transforms, even though we already had a pipeline which operated on "regular" elements.
- **Inconsistencies in facet spaces**: the types did not follow the existing facet conventions - _i.e._, to be placed on a folder named after the facet, _etc_. Even in that they were "special".

Programming is nothing if not a quest for the generalisation and removal of special cases, and these types had been a major thorn in the design. Thus the idea of refactoring fabric out of existence was born. With this release we finally removed all of the above meta-data keys, and replaced them with regular meta-model elements, instantiable via the appropriate stereotypes (Table 2). Sadly, a single use case was left, due to the specificity of its implementation: visitors. These shall be addressed on a future release.

> :warning: **Breaking change**: Users need to update any models which make use of the meta-data in Table 1 and replace them with the corresponding elements and stereotypes.

|Stereotype|Description|
|--------------|---------------|
|```masd::serialization::type_registrar```|The serialisation type registrar used mainly for boost serialisation support.|
|```masd::visual_studio::solution```|Visual Studio solution support.|
|```masd::visual_studio::project```|Visual Studio solution support.|
|```masd::entry_point```| Provides an entry point to a component, _e.g._ ```main```.|
|```masd::orm::common_odb_options```|Element modeling the common arguments for ODB.|
|```masd::visual_studio::msbuild_targets```|Element modeling ODB targets using MSBuild.|
|```masd::build::cmakelists```|Element modeling build files using CMake.|
|```masd::assistant```|C# helper type.|

_Table 2: Stereotypes for the new meta-model elements ._

Now, the observant reader won't fail to notice that _the generated code has not changed_ in any way - well, at least not intentionally. All of these new meta-model elements already existed, but in their previous incantation variability was used to trigger them (mostly). With this release they are modeled as proper meta-model elements, controlled by the user, and processed in the exact same way as all other elements. This means we can make use of all of the existing machinery in Dogen such as profiles.

![Use of new meta-elements in C++](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/cpp_new_meta_elements.png)
_Figure 1: Use of new meta-elements in a C++ model._

Whilst this is a big improvement in usability, there are still a number of pitfalls:

- users now need to remember to add types where Dogen used to inject them automatically. This is the case with ```registrar```, which was generated automatically when a model made use of inheritance.
- there are no errors or warnings when a diagram is on an inconsistent state due to the choice of elements used. For example, one can add a solution without a project.

![Use of new meta-elements in C#](https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/csharp_new_meta_elements.png)
_Figure 2: Use of new meta-elements in a C# model._

These are problems that will hopefully be looked into once we eventually reach the validation work, in a few sprints time.

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see the [sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_21.org).

## Significant Internal Stories

The sprint was mostly dominated by a number of stories dealing with moving fabric types, but since they have user visible consequences, they have been dealt with in _User visible changes_. The only other story of note is described below.

### Remove support for element extensions

In the past we created another "special" concept: element extensions. These allowed two meta-model elements to share the same position in modeling space, _i.e._ two elements sharing the same name. Whilst this may sound crazy on first sight, the initial idea behind it was more or less sound. Files such as forward declarations in C++, or ODB options, were better modeled when using "lightweight" meta-model elements which provided the specific data needed. In order for this to work, we needed to have some kind of way of containing meta-elements within meta-elements, and thus "element extensions" were born. As with fabric types, element extensions did not stood the test of time and added a lot of complexity and special cases. Now that the last fabric types that made use of element extensions were removed, we managed to remove the extensions themselves from the meta-model, greatly simplifying things.

## Resourcing

This sprint was a "model" sprint (if you pardon the pun) in terms of Dogen development. At an overall elapsed time of four weeks, our utilisation rate improved significantly from 23% to an amazing 56%. In other words, we managed to maintain a steady pace and clocked around 20 hours every week. Furthermore, a staggering _75.5%_ of the overall ask was spent on stories directly related to the sprint's mission of refactoring fabric. This is quite possibly the highest in Dogen's eight-year history, as far as I can recall. We spent 19.6% on process related activities, which whilst not the smallest amount ever, its also in line with recent sprints - particularly when we have video recording activities. The remainder of the sprint was used chasing minor spikes such as problems with the setup (1.4%), errors in tests (0.8%), issues with coveralls (0.3%) and so on. Overall, from a resource management perspective, this was a very successful sprint.

![Story Pie Chart](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_21_pie_chart.jpg)
_Figure 3: Cost of stories for sprint 21._

## Roadmap

Two very minor changes were made to the road map this sprint. First and foremost, we finally removed the fabric refactor from the roadmap, which is extremely pleasing. Secondly, we bumped up resource usage by a fair (if somewhat random) amount, which projected timescales in time somewhat, in a more realistic manner. How realistic is up to debate, but at least it is hopefully slightly less wrong.

![Project Plan](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_21_project_plan.png)

![Resource Allocation Graph](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_21_resource_allocation_graph.png)

# Next Sprint

The next great big refactoring battle is with the generation model. We need to move all concepts that had been incorrectly placed in generation to the meta-model, and, with it, reduce the huge code duplication we have between backends.

# Binaries

You can download binaries from [Bintray](https://bintray.com/masd-project/main/dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.21_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.21/dogen_1.0.21_amd64-applications.deb)
- [dogen-1.0.21-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.21/DOGEN-1.0.21-Darwin-x86_64.dmg)
- [dogen-1.0.21-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.21-Windows-AMD64.msi)

**Note:** The OSX and Linux binaries are not stripped at present and so are larger than they should be. We have [an outstanding story](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped) to address this issue, but sadly CMake does not make this trivial.

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.

Happy Modeling!
#+END_SRC markdown

- [[https://twitter.com/MarcoCraveiro/status/1229849866416816129][twitter]]
- [[https://www.linkedin.com/posts/marco-craveiro-31558919_masd-projectdogen-activity-6635632094846476289-oXZM][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    CLOSED: [2020-02-18 Tue 19:03]
    :LOGBOOK:
    CLOCK: [2020-02-18 Tue 18:38]--[2020-02-18 Tue 19:03] =>  0:25
    :END:

Time spent creating the demo and presentation. Use the demo project:

*** COMPLETED Sprint and product backlog grooming                     :story:
    CLOSED: [2020-03-16 Mon 08:45]
    :LOGBOOK:
    CLOCK: [2020-03-15 Sun 18:02]--[2020-03-15 Sun 18:05] =>  0:03
    CLOCK: [2020-03-15 Sun 12:34]--[2020-03-15 Sun 12:44] =>  0:10
    CLOCK: [2020-03-13 Fri 12:48]--[2020-03-13 Fri 12:59] =>  0:11
    CLOCK: [2020-03-13 Fri 08:11]--[2020-03-13 Fri 08:21] =>  0:10
    CLOCK: [2020-03-13 Fri 07:35]--[2020-03-13 Fri 08:10] =>  0:35
    CLOCK: [2020-03-12 Thu 17:59]--[2020-03-12 Thu 18:01] =>  0:02
    CLOCK: [2020-03-12 Thu 12:53]--[2020-03-12 Thu 13:17] =>  0:24
    CLOCK: [2020-03-12 Thu 09:01]--[2020-03-12 Thu 09:09] =>  0:08
    CLOCK: [2020-03-12 Thu 08:46]--[2020-03-12 Thu 09:00] =>  0:14
    CLOCK: [2020-03-12 Thu 08:15]--[2020-03-12 Thu 08:31] =>  0:16
    CLOCK: [2020-03-12 Thu 08:01]--[2020-03-12 Thu 08:07] =>  0:16
    CLOCK: [2020-03-11 Wed 13:44]--[2020-03-11 Wed 13:58] =>  0:14
    CLOCK: [2020-03-11 Wed 08:40]--[2020-03-11 Wed 08:50] =>  0:10
    CLOCK: [2020-03-11 Wed 08:14]--[2020-03-11 Wed 08:39] =>  0:25
    CLOCK: [2020-03-10 Tue 21:40]--[2020-03-10 Tue 21:49] =>  0:09
    CLOCK: [2020-03-09 Mon 16:08]--[2020-03-09 Mon 16:39] =>  0:31
    CLOCK: [2020-03-05 Thu 14:48]--[2020-03-05 Thu 14:53] =>  0:05
    CLOCK: [2020-03-05 Thu 14:20]--[2020-03-05 Thu 14:47] =>  0:27
    CLOCK: [2020-03-05 Thu 14:04]--[2020-03-05 Thu 14:19] =>  0:15
    CLOCK: [2020-03-05 Thu 10:50]--[2020-03-05 Thu 11:13] =>  0:23
    CLOCK: [2020-03-03 Tue 12:37]--[2020-03-03 Tue 12:51] =>  0:14
    CLOCK: [2020-03-03 Tue 11:01]--[2020-03-03 Tue 11:12] =>  0:11
    CLOCK: [2020-03-02 Mon 17:24]--[2020-03-02 Mon 18:02] =>  0:38
    CLOCK: [2020-03-02 Mon 15:20]--[2020-03-02 Mon 15:40] =>  0:20
    CLOCK: [2020-02-28 Fri 17:21]--[2020-02-28 Fri 18:10] =>  0:49
    CLOCK: [2020-02-17 Mon 19:31]--[2020-02-17 Mon 19:50] =>  0:19
    CLOCK: [2020-02-17 Mon 17:43]--[2020-02-17 Mon 18:27] =>  0:44
    :END:

Updates to sprint and product backlog.

*** COMPLETED Emacs configuration and issues                          :story:
    CLOSED: [2020-03-16 Mon 08:45]
    :LOGBOOK:
    CLOCK: [2020-03-12 Thu 14:41]--[2020-03-12 Thu 15:05] =>  0:24
    CLOCK: [2020-03-12 Thu 11:21]--[2020-03-12 Thu 11:32] =>  0:11
    CLOCK: [2020-03-12 Thu 10:20]--[2020-03-12 Thu 10:47] =>  0:27
    :END:

Time spent faffing around with emacs.

- crashes related to large JSON files. Did a package update.
- setup projectile with correct project name and run and test commands.
- crashes due to playing around with GDB.

Links:

- [[https://emacs.stackexchange.com/questions/13080/reloading-directory-local-variables][Reloading directory-local variables]]
- [[https://projectile.readthedocs.io/en/latest/projects/][Projectile: projects]]: section "Configure a Project's Compilation,
  Test and Run commands"

*** COMPLETED Adding reference to itself results in resolution errors :story:
    CLOSED: [2020-02-17 Mon 18:17]

*Rationale*: this was fixed a few sprints ago.

Whilst trying to fix the JSON models we inadvertently added a
self-reference in =dogen.generation.json=:

:    "yarn.reference": "dogen.generation.json",

This resulted in some puzzling errors:

: 2018-10-18 19:15:00.861210 [ERROR] [yarn.transforms.enablement_transform] Duplicate element archetype: quilt.cpp.serialization.registrar_implementation <dogen><generation><registrar>

Ideally we should either warn and ignore or fail to process models
with self-references.

*** COMPLETED Registrar assumes references have serialisation enabled :story:
    CLOSED: [2020-03-02 Mon 15:30]

*Rationale*: this problem was addressed with the new implementation of
registrar, which only adds registrars if the user created them
manually.

At present we are assuming that all references that are nom-proxy
references have serialisation enabled. This is a problem because:

- we are now disabling serialisation where possible unless we need it
- as we move from the data directory into real models we will have a
  number of models that will not require generation and so will not
  have a registrar.

We need to figure out a way to obtain an enablement map of referenced
types. In theory we already have this because we do not add includes
when a facet is off. However, something is not working quite right
with registrar because we are including this file. Sample diff:

: diff -u src/serialization/registrar_ser.cpp src/serialization/registrar_ser.cpp
: Reason: Changed generated file.
: ---  src/serialization/registrar_ser.cpp
: +++  src/serialization/registrar_ser.cpp
: @@ -26,6 +26,7 @@
:  #include <boost/archive/binary_oarchive.hpp>
:  #include <boost/archive/polymorphic_iarchive.hpp>
:  #include <boost/archive/polymorphic_oarchive.hpp>
: +#include "masd/serialization/registrar_ser.hpp"
:  #include "masd.cpp_ref_impl.two_layers_with_objects/serialization/registrar_ser.hpp"
:
:  namespace masd::cpp_ref_impl::two_layers_with_objects {
: @@ -32,18 +33,19 @@
:
:  template<typename Archive>
: -void register_types(Archive&) {
: +void register_types(Archive& ar) {
: +    masd::register_types(ar);
:  }
:

For now we did a quick hack to solve this problem and marked the MASD
model as proxy:

:    "masd.injection.is_proxy_model": true,

*** COMPLETED Analysis on defining a combined logical-physical space  :story:
    CLOSED: [2020-03-03 Tue 12:43]
    :LOGBOOK:
    CLOCK: [2020-03-03 Tue 11:13]--[2020-03-03 Tue 12:36] =>  1:23
    CLOCK: [2020-03-02 Mon 15:41]--[2020-03-02 Mon 15:59] =>  0:18
    CLOCK: [2020-03-02 Mon 13:25]--[2020-03-02 Mon 15:19] =>  1:54
    CLOCK: [2020-02-19 Wed 18:01]--[2020-02-19 Wed 19:01] =>  1:00
    CLOCK: [2020-02-19 Wed 08:02]--[2020-02-19 Wed 08:54] =>  0:52
    CLOCK: [2020-02-19 Wed 07:02]--[2020-02-19 Wed 07:30] =>  0:28
    :END:

*Rationale*: we understand the problem well enough to start moving
forwards a bit with coding. This is too complex to design it all up
front.

It now seems that we have been searching for a meta-model that
combines both aspects of logical modeling as well as physical
modeling. Facets, archetypes etc are all parts of the physical
dimension of this space. We need to find all stories on this topic and
organise them to see if we can come up with a consistent system of
meaning.

Notes:

- archetypes must support a notion of "kind". This is so we can have
  public include headers, private include headers and implementation
  files. This "kind" affects the topology of the physical dimension.
- the locator is a function that takes points in the logical-physical
  space and maps them to filesystem locations. It uses properties of
  those meta-model elements to configure the mapping.
- actually, the separation of technical spaces and backends is
  somewhat artificial. In reality, if we were to clean up all backends
  such that they only contain a single technical space then we
  wouldn't have this distinction. However, there are problems with
  this approach. Some features span across multiple technical spaces,
  such as ODB. It requires:

  - c++ support in generating the pragmas,
  - ODB options files.
  - msbuild for odb targets
  - cmake for odb targets

  It would be tempting to say that ODB is not a technical space, but
  just a feature. In which case we need options files to be a
  technical space not solely connected to ODB. This is possible,
  provided we can find evidence of other systems using options
  files. If we could generalise this then the problem would be
  solved. However, it is not yet clear if ODB is a special case or an
  indicator of a pattern which we are ignoring.
- in this world, we would have a top-level =techspace= model,
  equivalent to generation at present. It would be responsible for
  knowing about all available technical spaces. Component models would
  have one or more representations. A representation can have one
  primary technical space and zero or many secondary technical
  spaces.
- input and output technical spaces are modeling errors. In reality,
  models have types: they are either PIMs or PSMs. If a model is a
  PIM, he must only refer to other PIMs. However, an additional
  wrinkle is that in order to load the mappings, we need to have
  access to the references (as these contain the mappings). Perhaps we
  can allow any reference, but then when resolving, we need to ensure
  that the types are all consistent.
- perhaps we are looking at this in the wrong way. In reality, there
  are only the following permutations:

  - if a model has a single representation, then either a) the input
    technical space is the same as the output (e.g. PSM) or b) its a
    PIM in which case we need to perform the mapping.
  - if a model has more than one representation, then it must be a
    PIM.

  If a model had a way to declare itself PIM, then in resolver we
  could ensure that all types are referencing only other PIM
  types. However, it would still be possible for a C++ model to
  reference a C# model. For this validation to take place, we would
  need a way to associate a technical space to an element and then
  check that on reference resolution. Actually, if we ensure we map
  before we resolve (which we probably already do) then we can rely on
  the fact that only PSM types will exist. If we had a way of knowing
  which types in a PIM need mapping, then we could detect which ones
  did not map. Then we could issue a mapping error. This way the world
  would be cleanly divided between PIM and PSM, and we could ignore
  technical spaces for PIMs. We cannot know at mapping time
- one aspect that is not very clean is that we should only allow more
  than one representation on a model prior to mapping. After mapping,
  there can only be one representation (the technical space we have
  mapped to).

Merged stories:

*Create meta-model elements for location*

We need to factor out all meta-model elements we have scattered around
the generation models which model concepts related to physical
locations, and move them into assets. We then need to create classes
to instantiate these model elements as part of kernel registration, as
well as the associated overrides. Finally, we need a way to compute
paths using these new meta-model elements.

Notes:

- at present, we are relying on archetype location in the variability
  model. The main reason why is template expansion. We have a small
  number of features that are templated, and need to expand across
  physical space (e.g. for each facet, for each archetype, for each
  kernel etc). These we inject into variability by reading them from
  the backend. Thing is, variability is not really connected directly
  to the physical space. That is to say, these archetype locations are
  not points in variability space where we find these features - just
  like when we are using features in the logical model, we are not
  stating that points in logical space "have" features. Instead, we
  have points in feature space that happen to be mapped to points in
  other spaces. We need a clear cut separation between variability
  space and all other spaces to avoid confusion. We could say that
  variability space is hierarchical, and features can live at
  "levels". These levels can then be mapped to the hierarchy of
  physical space or modeling space as required.
- up to know we have assumed that physical space was somehow connected
  to logical space. An alternative way of looking at this is to see
  them as completely separate dimensions. It just so happens that on
  very few occasions, we need to refer to physical concepts in logical
  space, but this is just an implementation detail and should be kept
  to the minimum.
- when we finally enter generation, we require points in the
  logical-physical space in order to resolve them to concrete
  artefacts

*** COMPLETED Analysis on removing physical references in variability :story:
    CLOSED: [2020-03-05 Thu 14:19]
    :LOGBOOK:
    CLOCK: [2020-03-05 Thu 11:24]--[2020-03-05 Thu 13:03] =>  1:39
    CLOCK: [2020-03-04 Wed 17:00]--[2020-03-04 Wed 17:44] =>  0:44
    CLOCK: [2020-03-04 Wed 10:41]--[2020-03-04 Wed 12:38] =>  1:57
    CLOCK: [2020-03-03 Tue 17:26]--[2020-03-03 Tue 17:47] =>  0:21
    CLOCK: [2020-03-03 Tue 15:15]--[2020-03-03 Tue 16:01] =>  0:46
    :END:

By the end of this story there should be no dependencies between the
archetype location model and the variability model.

Notes:

- in reality we only need the archetype location in order to perform
  the template expansion. Which leads to the obvious conclusion that
  we probably should have a type to be used as input for that, and not
  associated with every instance.
- since all we need is a three-tiered hierarchy, we could use the
  terminology of group, subgroup and element, or even set, subset and
  element - both loosely borrowed from maths.
- we can clean up a number of related issues in one go if we shift our
  approach slightly. First, let us posit that we only need template
  instantiation for three cases: kernel, facet, archetype. Then, let
  us redefine facet bundles as facet groups (with potentially the
  ability to rename the facet group name's contribution to the feature
  full name). Let us also redefine facet template initialisers as
  "owners" (the actual name needs some work). In this scenario, there
  is no longer the need to have fully qualified names, as these are
  computed on the basis of ownership: on feature initialisation, the
  owner supplies its name as it registers the feature. In addition, we
  also know the name of the facet group statically. This addresses the
  needs for all non-templatised features. For the templatised
  features, we need to have a way to "inject" owners and groups which
  are "instantiable". For owners we can simply have meta-data for
  this. For groups we could also have meta-data, and allow "empty
  groups" (e.g. groups with no attributes. we can validate that such
  groups must be "abstract" or "instantiable"). However, given that in
  the future we shall introduce the notion of "facets" in the
  meta-model, it may be wiser to allow the creation of groups via
  meta-data. Or maybe this can wait until they are introduced. At any
  rate, finally we need a third concept, which is really only required
  for formatters. We can call these "subgroups". These should be added
  via meta-data since we do not want to have to add a new entity for
  each formatter. Meta-data could look like so:

: #DOGEN masd.variability.subgroup.name=x
: #DOGEN masd.variability.subgroup.description=y

  Of course one needs to associate the new subgroup to an existing
  owner and group.
- in fact there is yet another way of looking at this, and it appears
  to be the best. There are three types of variability elements:

  - feature groups. These map to UML packages. They are containers and
    merely add to path. they support "overrides" such that the
    physical directory may differ from the "logical" directory. For
    example, we want to place features on a folder called =features=
    but we don't want to have to have a feature name =feature.x.y=.
  - feature bundles. These map to UML classes, in terms of how we
    access the features. Note that these do not exist within
    variability itself, only in the logical meta-model. Note also that
    with this we no longer need feature templates everywhere - the
    bundles should contain only features (see next section).
  - feature template bundles: these only contain feature templates,
    not features themselves. Feature templates do not respect
    containment in groups etc. They behave quite differently:
    templates are instantiated against a "range". Ranges are mapped to
    "tags". Any meta-model element can introduce tags. These are
    simple KVPs, of the form:

: #DOGEN masd.variability.tag=X,a.b.c

    Where =X= is the tag, and =a.b.c= is an element in the range. Many
    such elements can be added to the range. For example, let =kernel=
    be the tag and =masd.generation.cpp= be an element in the
    range. Then, in instantiation, any template for tag =X= is
    instantiated for each element in the range. Note that the range is
    a qualified path. It will give rise to the groups
    (e.g. =x.y.z=). Note that these groups are expected to already
    exist, created via the usual meta-model formalism of
    =feature_group=. That will contain the documentation for the
    group.

    With this infrastructure, we can now dump all the features to the
    console, organised by groups, very easily. We just need a
    container which keeps track of this hierarchical structure and
    associated descriptions; we can iterate through it and generate
    text to output in the console. We should also allow for a
    grep-friendly mode where we just simply list all the
    features. This must be done after template instantiation.

    Note that this approach still requires the mapping in order to
    solve the "directory and prefix" duplication issue.

Previous understanding:

Tasks:

- create the notion of "levels".
- replace archetype location with a variability location based on
  levels.
- inject these locations by transforming archetype locations into
  variability locations within engine.

*** COMPLETED Remove =rapidjson= formatters                           :story:
    CLOSED: [2020-03-06 Fri 12:42]
    :LOGBOOK:
    CLOCK: [2020-03-06 Fri 12:39]--[2020-03-06 Fri 12:42] =>  0:03
    :END:

We never finished implementing these and now they are just adding to
the cognitive load. Remove them for now, re-add them properly later.

*** COMPLETED Separate feature templates from bundles                 :story:
    CLOSED: [2020-03-09 Mon 11:46]
    :LOGBOOK:
    CLOCK: [2020-03-09 Mon 11:51]--[2020-03-09 Mon 11:58] =>  0:07
    CLOCK: [2020-03-09 Mon 10:05]--[2020-03-09 Mon 11:46] =>  1:41
    CLOCK: [2020-03-07 Sat 19:04]--[2020-03-07 Sat 19:15] =>  0:11
    CLOCK: [2020-03-07 Sat 17:37]--[2020-03-07 Sat 18:17] =>  0:40
    CLOCK: [2020-03-06 Fri 20:52]--[2020-03-06 Fri 21:59] =>  1:07
    CLOCK: [2020-03-06 Fri 17:16]--[2020-03-06 Fri 18:28] =>  1:12
    CLOCK: [2020-03-06 Fri 15:48]--[2020-03-06 Fri 17:15] =>  1:27
    CLOCK: [2020-03-06 Fri 14:26]--[2020-03-06 Fri 14:59] =>  0:33
    CLOCK: [2020-03-06 Fri 12:43]--[2020-03-06 Fri 13:29] =>  0:46
    CLOCK: [2020-03-06 Fri 10:55]--[2020-03-06 Fri 12:39] =>  1:44
    :END:

At present we have the notion of feature templates where the template
instantiation type is "instance". This is, in effect, the vast
majority of the features. We then have some 5 or less cases where we
use the feature templates proper. We should not have to instantiate
templates for the cases where the instantiation is just the identity
of the feature. We need a way to model these directly as features. We
then need to introduce "feature template bundles", which are marked as
abstract and can only contain feature templates.

Notes:

- need to rename method in registrar, at present its called register
  templates but it also registers features.
- we should create an abstract feature base class to simplify
  code. Given the implementation is trivial we can do it now instead
  of waiting until all of the refactor is finished.

*** COMPLETED Move enabled to generation                              :story:
    CLOSED: [2020-03-09 Mon 11:50]
    :LOGBOOK:
    CLOCK: [2020-03-09 Mon 11:46]--[2020-03-09 Mon 11:50] =>  0:04
    :END:

For some reason we have placed this in the archetypes model.

*** COMPLETED Create a chain to encapsulate variability transforms    :story:
    CLOSED: [2020-03-09 Mon 23:11]
    :LOGBOOK:
    CLOCK: [2020-03-09 Mon 22:47]--[2020-03-09 Mon 23:11] =>  0:24
    CLOCK: [2020-03-09 Mon 20:01]--[2020-03-09 Mon 20:14] =>  0:13
    :END:

At present we are using individual variability transforms in the
engine, and interspersing those with other transforms. A nicer way is
to have a chain in variability that takes in a configuration model set
and runs a chain against it.

Actually we can only encapsulate two transforms:

- profile_binding_transform
- profile_repository_transform

Still, its worthwhile doing it.

*** COMPLETED Move variability chain into assets                      :story:
    CLOSED: [2020-03-10 Tue 18:33]
    :LOGBOOK:
    CLOCK: [2020-03-10 Tue 18:13]--[2020-03-10 Tue 18:33] =>  0:20
    CLOCK: [2020-03-10 Tue 16:10]--[2020-03-10 Tue 18:12] =>  2:02
    :END:

We originally placed this chain in engine because it went across
models (e.g. variability and assets). In reality, the assets model is
already composed of the variability model and they are closely
intertwined so it doesn't make a lot of sense to separate them on that
ground. And now that we are adding proper support for profiles at the
assets level, this is more of a requirement because there are
dependencies between transforms within the assets pipeline and the
variability pipeline. We should just move the chain into assets if
there are no dependencies in engine.

*** COMPLETED Move profile meta-data into profile element             :story:
    CLOSED: [2020-03-11 Wed 10:00]
    :LOGBOOK:
    CLOCK: [2020-03-11 Wed 10:00]--[2020-03-11 Wed 10:22] =>  0:22
    CLOCK: [2020-03-11 Wed 08:51]--[2020-03-11 Wed 09:59] =>  1:08
    CLOCK: [2020-03-10 Tue 21:10]--[2020-03-10 Tue 21:39] =>  0:29
    CLOCK: [2020-03-10 Tue 19:01]--[2020-03-10 Tue 19:16] =>  0:15
    CLOCK: [2020-03-10 Tue 14:16]--[2020-03-10 Tue 16:08] =>  1:52
    CLOCK: [2020-03-10 Tue 09:05]--[2020-03-10 Tue 12:04] =>  2:59
    CLOCK: [2020-03-09 Mon 23:12]--[2020-03-09 Mon 23:19] =>  0:07
    :END:

At present we have left some of the profile meta-data in the
configuration of the profile element. However, for feature templates
and feature bundles, we read out the meta-data in assets and then make
use of it when transforming the element to its variability
representation. We should use the same approach for profiles - if
nothing else at least the approach is consistent.

Notes:

- at present we always declare the features and create the static
  configuration in the same place. This has worked thus far because we
  tend to declare the features where we consume them. Profiles are
  different: a profile is making use of a feature declared for a
  feature. That is, a profile is the instantiation of a feature
  defined elsewhere; remember that features are nothing more than a
  type system designed to give a "strongly typed" feel to the
  meta-data. Profiles are just an instantiation of those strong
  types. In theory, profile meta-data should already exist and match
  exactly what was defined for features. In practice there is a
  mismatch, and this is due to how we modeled features and feature
  bundles: to avoid repetition, we placed some features at the
  top-level and others in the features themselves. This approach does
  not match the shape required for profiles, so we need to redefine
  the bundle. However, of course, we do not want to register the
  features this time around (after all, they already exist) so we need
  to disable feature registration.
- "adaption" is not a word, rename to "adaptation" (in
  =profile_template_adaption_transform=).

*** COMPLETED Add handcrafted stereotype to C# models                 :story:
    CLOSED: [2020-03-11 Wed 14:33]
    :LOGBOOK:
    CLOCK: [2020-03-11 Wed 14:29]--[2020-03-11 Wed 14:33] =>  0:04
    :END:

At present we do not have any tests for C# models with handcrafted. If
we did it would not work because the annotations only set the C++
facets. Add a test for this and fix the annotation profile. The same
problem will apply to all new profiles:

- pretty printable
- serialisable
- hashable

Actually this probably should now work across all kernels, but we need
tests to prove it.

Added a simple type to prove it, just for types. Its good enough for
now.

*** COMPLETED Split profiles and profile templates in variability     :story:
    CLOSED: [2020-03-11 Wed 14:34]
    :LOGBOOK:
    CLOCK: [2020-03-11 Wed 13:59]--[2020-03-11 Wed 14:28] =>  0:29
    CLOCK: [2020-03-11 Wed 10:23]--[2020-03-11 Wed 12:24] =>  2:01
    CLOCK: [2020-03-09 Mon 19:36]--[2020-03-09 Mon 20:00] =>  0:24
    CLOCK: [2020-03-09 Mon 18:49]--[2020-03-09 Mon 19:05] =>  0:16
    CLOCK: [2020-03-09 Mon 18:41]--[2020-03-09 Mon 18:48] =>  0:07
    CLOCK: [2020-03-09 Mon 16:40]--[2020-03-09 Mon 17:54] =>  1:14
    :END:

As with features, we seem to have conflated the profiles with profile
templates. Given we use templates in a very small number of cases, it
should really be two separate concepts to avoid confusing end users
and ourselves.

Notes:

- we should create a chain in engine to gather all of the transforms
  related to variability.
- rename "entities transform" to "features transform" and "application
  transform" to profiles transform". Add lots of commentary explaining
  the three distinct phases of variability processing (feature model
  generation, profile processing and feature processing for code
  generation). Copy across the profile processing from "entities
  transform" into "application transform". Update profile adapter from
  stash (and consider merging it into the application
  transform?). Profiles transform is really a chain as it is calling
  transforms.

*** COMPLETED Consider renaming labels to stereotypes in variability  :story:
    CLOSED: [2020-03-11 Wed 15:41]
    :LOGBOOK:
    CLOCK: [2020-03-11 Wed 14:34]--[2020-03-11 Wed 15:41] =>  1:07
    :END:

It appears we use labels just to store the stereotype of the
profile. If so rename the attribute and associated feature and make it
just a string.

Merged stories:

*Make labels a plain text field not a collection*

At present it is possible to label a profile with multiple
labels. This is not a good idea. Make it a plain text field so we can
only apply a single label.

*** CANCELLED Declaring a =std::list= without parameters segfaults    :story:
    CLOSED: [2020-03-12 Thu 09:26]
    :LOGBOOK:
    CLOCK: [2020-03-12 Thu 09:15]--[2020-03-12 Thu 09:25] =>  0:10
    :END:

By mistake we declared a type like so:

: std::unordered_map<std::string, std::list>

This caused dogen to segfault. We need a slightly more informative
behaviour. Actually it seems that at present we are not doing any
checks on the number of type parameters. This has already been
recorded in the validation story so we will just have to ignore it for
now.

*** CANCELLED Add location and modules to variability                 :story:
    CLOSED: [2020-03-12 Thu 17:19]
    :LOGBOOK:
    CLOCK: [2020-03-09 Mon 15:25]--[2020-03-09 Mon 16:08] =>  0:43
    :END:

*Rationale*: we didn't need these in the end, qualified names are
sufficient.

We need to create a location class in variability, based on a simple
list of strings. It should probably have an attribute called "modules"
in order to follow the same approach as assets. We then need to
replace the existing uses of archetype location with this new,
variability-only, location. However, note that this is only done for
the features, not for the feature templates.

We need to introduce "feature groups". This is a stereotype applied to
packages which generates a feature group with documentation. Note that
these groups do not contribute to the path of physical elements, only
to the path of features - note, specifically *not* to feature
templates. Groups can nest arbitrarily.

Notes:

- we need to also figure out how to code-generate infrastructure for
  templates that allows us to retrieve features for a tag. We may not
  need code generation in fact, given we deal with them
  generically. We should just retrieve them manually. See
  =archetype_location_properties_transform=.
- check what the labels in variability are used for. If nothing,
  remove them. Actually, these are used by profiles (e.g. the
  stereotype to bind with). We probably should consider renaming
  these. If its function is just to name the stereotype for a profile,
  it should be called "stereotype" and there should be just one per
  profile.
- actually we have exactly the same problem with profiles and profile
  templates. We used the approach of "template kind instance" for
  profile templates. This is very confusing. We need to split these
  two types prior to refactoring this code.
- given the usage patterns, we probably don't even need locations. We
  can simply say that there are simple names and qualified
  names. Qualified name can be composed from bundle name or some other
  bundle property.

*** COMPLETED Implement template instantiation in terms of tags       :story:
    CLOSED: [2020-03-12 Thu 17:58]
    :LOGBOOK:
    CLOCK: [2020-03-12 Thu 15:05]--[2020-03-12 Thu 17:58] =>  2:53
    CLOCK: [2020-03-12 Thu 13:32]--[2020-03-12 Thu 14:40] =>  1:32
    CLOCK: [2020-03-12 Thu 11:33]--[2020-03-12 Thu 12:05] =>  0:32
    CLOCK: [2020-03-12 Thu 10:48]--[2020-03-12 Thu 11:20] =>  0:42
    CLOCK: [2020-03-12 Thu 09:26]--[2020-03-12 Thu 10:19] =>  0:53
    CLOCK: [2020-03-12 Thu 09:13]--[2020-03-12 Thu 09:14] =>  0:01
    CLOCK: [2020-03-12 Thu 09:10]--[2020-03-12 Thu 09:13] =>  0:03
    CLOCK: [2020-03-12 Thu 08:32]--[2020-03-12 Thu 08:45] =>  0:13
    CLOCK: [2020-03-11 Wed 15:42]--[2020-03-11 Wed 17:58] =>  2:16
    :END:

At present we are instantiating templates over a physical space
(e.g. kernel, facet, archetypes). We need to replace this with
tags. The idea is that we can inject tags (which are qualified names)
into the model via meta-data:

: #DOGEN masd.variability.tag=X,a.b.c

We can then create feature templates that are instantiated on a range
given by the set of all values for a given tag, for example =X=
(e.g. =kernel=, =facet=, =archetype=). Tags can be introduced by any
model which has a configuration point. However, elements in ranges are
expected to be unique and to point to existing groups.

It is important to note that profile template instantiation is more of
a convention at present. That is, nothing stops you from having a
profile template that instantiates templates across any number of
tags. However, for feature bundles we made it so that a bundle can
only have a template kind (all features will share the same tag
effectively). For symmetry purposes, we probably should make it so
that profile templates can only bind to one tag.

Tasks:

- remove all support for archetype, facet etc in variability which is
  not used at present. This includes repositories, selector etc. We
  should get a much better picture of usage patterns once that is
  done.
- add new KVP feature in assets: =tag=.
- add KVP to all relevant model elements (all, kernel, facet,
  archetype).
- add tags to configuration model in variability (map of string to
  list).
- add tag to feature templates and profile templates. Note that we
  will need a different feature for this which is not a KVP. Maybe
  "tag name"?
- create a new template instantiator that uses the tags to
  instantiate. Do a side-by-side diff of both.
- replace all uses of archetype location in selector, etc.
- remove archetype location from context and context factory for
  variability.
- remove references to archetypes model from variability model.

Notes:

- actually the original tag based approach won't work. The problem is,
  we need the tag information in order to generate the feature model
  in variability's phase one. So we must have access to this
  information at the very start of dogen. As luck would have it, we do
  already: all the information is already encoded in archetype
  locations. The problem is we do not want to _specifically_ bind
  against archetype locations "shape" because we do not want
  variability to be hard-coded against the geometry of the physical
  dimension. However, nothing stops us from creating a container of
  the right shape that is a transformation of the archetype locations
  into string form:

: masd -> all entries for the masd kernel.
: masd.backend -> all backends in the masd kernel.
: masd.generation.cpp -> all facets and formatters in generation.cpp kernel
: masd.facet -> all facets in the masd kernel.
: masd.generation.cpp.facet -> all facets in generation.cpp kernel.

  and so forth. Each of this is an entry on a map, against a list: the
  template instantiation domain. Features and profiles supply the
  template instantiation domain name.

Reviewed tasks:

- add template instantiation domain to context in variability.
- add factory for domains in archetypes.
- generate domains from context factory.
- add domain name property to feature template and profile template in
  variability.
- add domain name property to templates in asset.
- add domain property to variability features in assets.
- read field and populate meta-model elements.
- update adapter to populate variability domain name.
- generate code to populate domain name when creating features.
- create a template instantiator based on domains, side by side with
  existing one.
- remove template kind from assets
- remove template kind from variability
- remove archetype location from features and profiles.
- remove archetype location from context and context factory for
  variability.
- remove references to archetypes model from variability model.

*** COMPLETED Remove duplication from feature bundles and profiles    :story:
    CLOSED: [2020-03-13 Fri 13:58]
    :LOGBOOK:
    CLOCK: [2020-03-13 Fri 13:00]--[2020-03-13 Fri 13:58] =>  0:58
    CLOCK: [2020-03-13 Fri 08:41]--[2020-03-13 Fri 12:12] =>  3:31
    :END:

Add prefixes to feature bundles and profiles. Compute qualified names
based on prefixes plus attribute names.

Notes:

- add an optional prefix to profiles and features in assets.
- if present qualified name is prefix + attribute name. If not
  present, qualified name is attribute name.
- simple name is the tail of the qualified name, using dots as
  separators.

*** COMPLETED Postfix and directory fields should be templates        :story:
    CLOSED: [2020-03-13 Fri 17:53]
    :LOGBOOK:
    CLOCK: [2020-03-13 Fri 13:58]--[2020-03-13 Fri 17:53] =>  3:55
    :END:

We need to understand why we didn't templatise these fields. It is
very painful to have to add these manually for each facet and
formatter.

Most likely it is because each formatter/facet needs to "override" a
base value with its own value. For example, we almost always want a
blank postfix, but occasionally need to set it (=fwd= for forward
declarations and so forth). Our variability implementation does not
cope with this type of overrides. We would have to have some kind of
way of allowing instance templates even though a facet/archetype
template already exists, and then use the instance template as the
override. Alternatively, we could simply check for postfix/directory;
if not present default to empty string.

For extra bonus points, we could allow variables: =${facet.name}=
could expand to the current facet name on the facet template.

The right solution for this is to allow users to supply a map with
KEY, VALUE on a field:

: #DOGEN masd.variability.mapped_default=forward_declaration,fwd

In this case, any archetypes (e.g. "elements" in the new world)
matching the KEY =forward_declaration= would have a default value of
=fwd=.

Notes:

- we incorrectly named the assets features fields as "value" when in
  reality they are transporting the default value. We need to rename
  these.
- we should call this map "default value overrides".
- we should match the overrides on "ends with". More than one match is
  an error.
- we should error if there is a default value override but no default
  value.

Merged stories:

*Field definition templates do not support facet specific defaults*

At present we cannot use field definition templates for fields that
require facet specific default values such as =directory=. We could
either support something like a "variable", e.g. "find facet simple
name" or we could do overrides - the field definition is defined as a
template but then overriden at a facet level. Or we could handle
default values in a totally separate way - maybe a file with just the
default values.

In addition, we have the case where at the facet level we may have a
default value for a field but not at the formatter level - =postfix=.

For variables, the simple way is to have some "special names". For
example =$(facet_name)= could be made to mean the facet name. With
just support for this we could probably handle all of the use cases
except for =postfix=.

*Use templates for directory and prefix fields*

At present we have a lot of duplication on the annotations for certain
fields. This is because we need different defaults depending on the
facet etc. A different approach would be to use the appropriate
template (without default values) and then using profiles to default
those that need defaulting.

Other fields may also need a similar clean up:

- overwrite

In addition, we could add support for "default value variables". These
are useful for directories. They work as follows: the default value is
something like =${facet.simple_name}= or perhaps just
=${simple_name}=, in which case we assume the template kind determines
the target. Say the target is the kernel:

:      "family": "quilt",
:      "kernel": "quilt.cpp",

The simple name is then =kernel - family=, e.g. =cpp=. Unfortunately
this does not work for prefix.

Tasks:

- make prefix a recursive field at archetype level, adding default
  values to profiles.
- make directory a recursive field at facet level,  adding default
  values to profiles.

*Postfix and directory fields in annotations look weird*

Why are we manually instantiating postfix and directory for each
formatter/facet instead of using templates? This is one of the main
reasons for breaks/errors when adding a new formatter.

*** COMPLETED Default value overrides are not stable                  :story:
    CLOSED: [2020-03-15 Sun 15:13]
    :LOGBOOK:
    CLOCK: [2020-03-15 Sun 14:47]--[2020-03-15 Sun 15:13] =>  0:26
    CLOCK: [2020-03-15 Sun 13:40]--[2020-03-15 Sun 14:46] =>  1:06
    CLOCK: [2020-03-15 Sun 12:44]--[2020-03-15 Sun 12:59] =>  0:15
    CLOCK: [2020-03-14 Sat 21:10]--[2020-03-14 Sat 21:12] =>  0:02
    CLOCK: [2020-03-14 Sat 20:37]--[2020-03-14 Sat 21:09] =>  0:32
    CLOCK: [2020-03-14 Sat 19:00]--[2020-03-14 Sat 19:22] =>  0:22
    CLOCK: [2020-03-14 Sat 17:11]--[2020-03-14 Sat 18:18] =>  1:07
    CLOCK: [2020-03-14 Sat 08:01]--[2020-03-14 Sat 09:12] =>  1:11
    :END:

Because KVPs in variability use an unordered map as the underlying
structure, the order of KVPs is liable to move on different
machines. We need to change it to a list and deal with the fallout.

Notes:

- we have an ordering problem. We are aggregating entries using an
  unordered map. This would work ok for the purposes of all value
  types with the exception of KVPs. The reason why is that KVPs go in
  as distinct keys, say for example:

: some.key.a=b
: some.key.c=d

  Thus the map reorders =some.key.a= and =some.key.b= because these
  keys do not get aggregated (and cannot since we do not know how to
  aggregate them until later in the day). We cannot use a map for the
  aggregation. The easy solution is to stop aggregating first and
  instead take the same approach as we do for KVPs but for all
  entries.
- we seem to be reverting the keys in JSON. Check the adaptor to see
  if we are pushing on the front. Actually this seems like a
  consequence of the hackery to fix the first problem. It looks ok
  now.
- add notes on variability overrides explaining that by design you
  cannot override keys on profiles, only those that have been applied
  directly to elements.

*** COMPLETED Variability overrides in nightly are broken             :story:
    CLOSED: [2020-03-15 Sun 15:37]
    :LOGBOOK:
    CLOCK: [2020-03-15 Sun 15:13]--[2020-03-15 Sun 15:37] =>  0:24
    :END:

We are not generating variability overrides in the nightly build. This
was borked with the variability refactor. This happened because of the
profile refactor, which resulted in C# being enabled. Due to this
files were placed under =cpp= directory, causing all sorts of weird
and wonderful problems. We've put things back to where they were so
hopefully this will fix tonight's nightly.

*** COMPLETED Add command line option to dump all specs               :story:
    CLOSED: [2020-03-15 Sun 18:00]
    :LOGBOOK:
    CLOCK: [2020-03-16 Mon 08:01]--[2020-03-16 Mon 08:30] =>  0:29
    CLOCK: [2020-03-15 Sun 15:38]--[2020-03-15 Sun 18:00] =>  2:22
    CLOCK: [2020-03-13 Fri 20:41]--[2020-03-13 Fri 21:54] =>  1:13
    CLOCK: [2020-03-13 Fri 17:54]--[2020-03-13 Fri 18:27] =>  0:33
    CLOCK: [2020-03-12 Thu 19:45]--[2020-03-12 Thu 20:06] =>  0:21
    :END:

We need a way to access a text description of all features in the
command line. The variability model should expose this, and then the
CLI model should use it to print a human readable version of the
features. We should allow for two modes: human friendly (e.g. wrap at
a column, indent by groups) and grep friendly (e.g. no indent, long
lines).

We should probably create a new command called info and then have
options of what to dump:

- features
- frontends
- backends
- stereotypes

And so forth.

Notes:

- we could call this =dumpspecs= like GCC - though the format for
  dumpsecs is somewhat unreadable.
- its not clear if we should have a simple command line option or a
  new activity. Help and version are already bypassing this notion of
  activity. The problem is that we are switching on activities for
  most of the code that involves engine, and this will too. Help and
  version are so simple they can be handled directly in the command
  line options parsing, but dumpspecs cannot.

Links:

- https://www.rosettacode.org/wiki/Word_wrap#C.2B.2B

Merged stories:

*Add annotation types description*

It would be useful to have a description of the purpose of the field
so that we could print it to the command line. We could simply add a
JSON attribute to the field called description to start off with. But
ideally we need a command line argument to dump all fields and their
descriptions so that users know what's available.

This should be sorted by qualified name.

Notes:

- we already added comments to many features. This seems to be the
  right place in the model to record this information. We just need to
  propagate it into the feature template and then into the feature.
- context is already doing all of the hard work for feature
  instantiation. We just need to create a transform that calls the
  context factory, retrieves all of the descriptions as strings
  somehow, and then get the command line to print them out. This can
  then be extended in the future to include backends, etc.

*** COMPLETED Add frontends and backends to =info= command line option :story:
    CLOSED: [2020-03-15 Sun 18:01]

*Rationale*: implemented as part of dumpspecs feature.

#+begin_quote
*Story*: As a dogen user, I want to know what frontends and backends
are available in my dogen version so that I don't try to use features
that are not present.
#+end_quote

With the static registration of importers and backends, we should add
some kind of mechanism to display whats on offer in the command line,
via the =--info= option. This is slightly tricky because the fronend
and backend models do not know of the command line. We need a method
in the frontend that returns a description and a method in the
workflow that returns all descriptions. These must be static. Then
knitter can then call these methods and build the info text.

It would also be nice to have two different invocations of this
command:

- against a model: dumps stats on the model such as number of objects,
  whether the generated code is up-to-date, etc.
- system: information about the backends and frontends.

Note that this story is different from the dumping of all features,
though they share some commonalities.

*** COMPLETED Document all features                                   :story:
    CLOSED: [2020-03-16 Mon 08:40]
    :LOGBOOK:
    CLOCK: [2020-03-16 Mon 08:31]--[2020-03-16 Mon 08:40] =>  0:09
    :END:

At present when we do a =dumpspecs= many features have no description:

: $ ./dogen.cli dumpspecs | grep "missing description" | wc -l
: 606
: $ ./dogen.cli dumpspecs | grep "missing description" | head
:    masd.generation.cpp.build.directory: <missing description>. Binding point: 'global'. Default value: ''. Value type: 'masd::variability::text'.
:    masd.generation.cpp.build.enabled: <missing description>. Binding point: 'any'. Default value: ''. Value type: 'masd::variability::boolean'.
:    masd.generation.cpp.build.include_cmakelists.enabled: <missing description>. Binding point: 'any'. Default value: ''. Value type: 'masd::variability::boolean'.
:    masd.generation.cpp.build.include_cmakelists.formatting_input: <missing description>. Binding point: 'any'. Value type: 'masd::variability::text'.
:    masd.generation.cpp.build.include_cmakelists.formatting_style: <missing description>. Binding point: 'any'. Value type: 'masd::variability::text'.
:    masd.generation.cpp.build.include_cmakelists.overwrite: <missing description>. Binding point: 'element'. Default value: ''. Value type: 'masd::variability::boolean'.
:    masd.generation.cpp.build.include_cmakelists.postfix: <missing description>. Binding point: 'global'. Default value: ''. Value type: 'masd::variability::text'.
:    masd.generation.cpp.build.include_cmakelists.primary_inclusion_directive: <missing description>. Binding point: 'element'. Value type: 'masd::variability::text'.
:    masd.generation.cpp.build.include_cmakelists.secondary_inclusion_directive: <missing description>. Binding point: 'element'. Value type: 'masd::variability::text_collection'.
:    masd.generation.cpp.build.overwrite: <missing description>. Binding point: 'element'. Default value: ''. Value type: 'masd::variability::boolean'.

We need to work through this list and add appropriate descriptions.

Actually there was a bug in template generation causing this: we were
not copying across the description on instantiation.

** Deprecated
*** CANCELLED Disabling facet after regeneration does not delete file :story:
    CLOSED: [2020-02-17 Mon 18:08]

*Rationale*: this issue is likely to do with the fact that we have
ignore regexes for =test= and =tests= on most models.

Steps to reproduce:

- enable tests for all types.
- generate model.
- disable tests for one type.
- generate model.

Expected that disabling tests for type would result in file
deletion. Instead nothing happens. However, if one deletes the
generated file for the type, then the next generation will correctly
not generate code for the type.

It seems there is some weird mismatch between enablement and lint
removal: we are probably adding the file to the list of expected
files, regardless of whether the facet is enabled or not. However,
this is not always the case because we've proven that enabling and
disabling a facet correctly results in the deletion of files. It must
be something to do with how local enablement is handled.

*** CANCELLED Naming of saved yarn/Dia files is incorrect             :story:
    CLOSED: [2020-02-17 Mon 18:11]

*Rationale*: we don't really use this functionality as is, and in the
future we will create new "top-level" "types for serialisaton instead
of using hand-crafted code, so the story does not add value.

For some random reason when we use dogen to save yarn/Dia files the
names look like this:

: test_data/dia_sml/expected/boost_model.xmldia
: test_data/dia_sml/expected/std_model.xmldia

but our tests expect:

: test_data/dia_sml/expected/boost_model.diaxml
: test_data/dia_sml/expected/std_model.diaxml

This must be part of a refactoring that wasn't completed properly.
*** CANCELLED Incorrect generation when changing external modules     :story:
    CLOSED: [2020-02-17 Mon 18:16]

*Rationale*: this issue is likely to do with the fact that we have
ignore regexes for =test= and =tests= on most models.

When fixing the C# projects, we updated the external modules, from
=dogen::test_models= to =CSharpRefImpl=. Regenerating the model
resulted in updated project files but the rest of the code did not
change. It worked by using =-f=. It should have worked without forcing
the write.

*** CANCELLED Tests for error conditions in libxml                    :story:
    CLOSED: [2020-02-17 Mon 18:19]

*Rationale*: we will move to RapidXML.

We do not have any errors that check for error conditions directly in
libxml. This is why the coverage of these functions is red.
*** CANCELLED =Nameable= concept moved position on code generation    :story:
    CLOSED: [2020-02-17 Mon 18:23]

*Rationale*: hasn't happened again for a long time.

During the exogenous model work, yarn's =Nameable= concept moved
position. We need to look at how the parent changes were done to see
if they are stable or not.

*** CANCELLED Consider automatic injection of helpers                 :story:
    CLOSED: [2020-02-17 Mon 18:24]

*Rationale*: helpers will be removed.

At present we are manually calling:

: a.add_helper_methods();

On each of the class implementation formatters in order to inject
helpers. This is fine for existing cases, but its a bit less obvious
when adding the first helper to an existing template: one does not
quite know why the helper is not coming through without
investigating. One possible solution is to make the helper generation
more "mandatory". Its not entirely obvious how this would work.

*** CANCELLED Clean-up helper terminology                             :story:
    CLOSED: [2020-02-17 Mon 18:24]

*Rationale*: helpers will be removed.

The name "helper" was never really thought out. It makes little
sense - anything can be a helper. In addition, we have helpers that do
not behave in the same manner (inserter vs every other helper). We
need to come up with a good vocabulary around this.

- static aspects: those that are baked in to the file formatter.
- dynamic aspects: those that are inserted in to the file formatter at
  run time.
- type-dependent dynamic aspects: those that are connected to the
  types used in the file formatter.

Merged stories:

*Type-bound helpers and generic helpers*

Not all helpers are bound to a type. We have the case of inserter
helper in io which is used by main formatters directly. We need to
make this distinction in the manual.
*** CANCELLED Helper methods should have their own includes           :story:
    CLOSED: [2020-02-17 Mon 18:25]

*Rationale*: helpers will be removed.

This should be fairly straightforward:

- ensure we compute helpers before we do includes in formattables
  factory;
- add include API to helpers (=inclusion_dependencies=)
- during inclusion expansion, go through all helpers associated with a
  element and ask them for their dependencies.
- note that we still need a good solution for the "special helpers" in
  order for this to work.

*Previous Understanding*

When a formatter relies on the helper methods, we have a problem: we
need to determine the required includes from the main formatter
without knowing what the helper methods may need. We have hacked this
with things like the "special includes" but there must be a cleaner
way of doing this. For example, we could ask the helper methods
formatter to provide its includes and it would be its job to either
delegate further or to compute the includes. This would at least
remove the duplication of code between io and types.

This task will be made much easier once we have stitch support
for named regions.

As part of the work to make helpers dynamic we reached the following
conclusions:

Note: when time comes to support includes in helper methods, we can
take a similar approach as we do for formatters now. The helper method
implements some kind of include provider interface, which is then used
by the inclusion dependencies builder. The only slight snag is that we
need to first resolve the type into a type family and then go to the
helper interface.
*** CANCELLED Create different kinds of master header files           :story:
    CLOSED: [2020-03-02 Mon 15:22]

*Rationale*: this feature has been removed.

#+begin_quote
*Story*: As a dogen user, I don't want to include every object in a
model when I use includers.
#+end_quote

At present we are using the facet includers in unit tests. This is not
ideal because it means that every time we do a change in a service
header, all tests recompile. In reality we should have two types of
inclusions:

- canned tests should include only value objects, etc - e.g. no
  services.
- service tests should include the header for the service and any
  additional dependencies the service may require.

Perhaps we could have a second type of includer that only has value
objects, etc.

Another way to look at this is that there should be user-configurable
master header files:

#+begin_quote
*Story*: As a dogen user, I want to create master header files for
user defined sets of files so that I don't have to do it manually.
#+end_quote

Merged stories:

*Add an includer for all includers*

#+begin_quote
*Story*: As a dogen user, I need a quick and dirty way of including
all files in a model so that I can test them without having to
include every file manually.
#+end_quote

It would be nice to totally include a model. For that we need an
includer that includes all other includers. This should be as easy as
keeping track of the different includers for each facet in the map
inside of the includer service.

We need to find a good use case for this.

Taking into account the "[[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/product_backlog.org#consider-renaming-includers][master header]]" rename, this would be a
"master master include" file?
*** CANCELLED Stitch does not handle directories very well            :story:
    CLOSED: [2020-03-02 Mon 15:26]

*Rationale*: stand-alone stitch is no longer supported.

At present we seem to generate log files called =.= when we use stitch
against a directory. This should only happen if we use =.= on the
target parameter, e.g.:

: --target .

Not sure why it is happening when we call stitch from CMake since it
should use the full path to the =cpp= directory.
*** CANCELLED Consider changing fields where "qualified name" is not qualified :story:
    CLOSED: [2020-03-05 Thu 12:58]

*Rationale*: this story will be impacted by the current variability
refactor.

At present, the the qualified field name is not always a prefix +
simple name. For example, for general settings and for stitch, the
qualified field names do not have a prefix. We could just add a prefix
to make everything symmetric (e.g. =formatters.copyright_notice=) but
it would make the fields less readable at the usage point and this was
the reason why we didn't add it in the first place. For now, we will
leave stitch as it is. This is a bit more meaningful with the
annotation rename.

This may even be a more wide-ranging question: why do users need to
know who owns the field? e.g. =dia.comment=, do I care?
*** CANCELLED Add a modeline to stitch                                :story:
    CLOSED: [2020-03-09 Mon 16:17]

*Rationale*: this story is deprecated in light of the changes to
stitch templates and will be even more deprecated when we finish the
templating refactor.

It would be nice to be able to supply the mode and other emacs
properties to stitch templates. For that we just need a special KVP
used at the top that contains the modeline:

: <#@ modeline="-*- mode: poly-stitch; tab-width: 4; indent-tabs-mode: nil; -*-" #>

Stitch can read this KVP and ignore it.

*** CANCELLED Add support for command line meta-data parameters       :story:
    CLOSED: [2020-03-09 Mon 16:20]

*Rationale*: variability overrides solve most of the problems in this
story, and we haven't had use cases for what is not solved, so the
story is considered deprecated.

We do not want to force end users to change their existing file
format. However, it is sometimes necessary to supply parameters into
dogen which are not representable in the existing format. We could
create a very simple extension to the command line arguments that
would generate scribbles; these would then be appended to the model
during the yarn workflow. Example:

: --kvp a=b

or:

: --meta-data a=b

These are in effect model-module level tagged values. We should be
able to supply them in a file or as command-line parameters.

This could cause all sorts of weird and wonderful problems such as
unrepeatable behaviour, so we need to find a very good use case for it
first.

One use case for this is the "enable all" functionality, useful for
testing. It would put dogen in a mode where all facets would be
enabled, regardless.
*** CANCELLED Throw on profiles that refer to invalid fields          :story:
    CLOSED: [2020-03-09 Mon 16:32]

*Rationale*: compatibility mode has been implemented and stand-alone
weaving has been deprecated, so this story has bit-rotted too much to
be useful.

At present during profile instantiation, if we detect a field which
does not exist we skip the profile. This was done in the past because
we had different binaries for stitch, knit etc, which meant that we
could either split profiles by application or skip errors
silently. Now we have a single binary, we could enable this
validation. However, the stitch tests still rely on this
behaviour. The right solution for this is to have some kind of
override flag ("compatibility mode" springs to mind) which is off by
default but can be used (judiciously).

We put a fix in but it seems weave is still borked. The problem
appears to be that we do something in the generation path that is not
done for weaving (and presumably for conversion). The hack was put
back in for now.

This story is dependent on moving annotations out of stitch. Once this
is done we can enable validation.
*** CANCELLED Meta-names do not have namespaces                       :story:
    CLOSED: [2020-03-11 Wed 13:47]

*Rationale*: we shall remove meta-names and bind on stereotypes so
this won't be a problem in the future.

At present the meta-name factory is placing all meta-names in a
top-level namespace. It should really respect the hierarchical
namespaces we have. However, given we want to code-generate this, we
may just leave it as is for now until we fix it properly.

Since all meta-elements should live in assets, we should fix this once
all of them have been moved across.
