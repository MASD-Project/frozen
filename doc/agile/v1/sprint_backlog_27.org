#+title: Sprint Backlog 27
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Sprint Goals

- implement the identification model.
- finish PMM generation.
- implement locator and dependencies via PMM.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2020-09-21 Mon 03:03]
| <75>                                               |         |       |       |       |
| Headline                                           | Time    |       |       |     % |
|----------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                       | *82:42* |       |       | 100.0 |
|----------------------------------------------------+---------+-------+-------+-------|
| Stories                                            | 82:42   |       |       | 100.0 |
| Active                                             |         | 82:42 |       | 100.0 |
| Edit release notes for previous sprint             |         |       |  7:15 |   8.8 |
| Create a demo and presentation for previous sprint |         |       |  0:41 |   0.8 |
| Sprint and product backlog grooming                |         |       |  2:26 |   2.9 |
| Nightly nursing and other spikes                   |         |       |  4:22 |   5.3 |
| Create an =ident= model                            |         |       | 42:02 |  50.8 |
| Rename injection to codec                          |         |       |  0:48 |   1.0 |
| Add artefact's archetype to artefact class         |         |       |  0:07 |   0.1 |
| Remove support for split projects                  |         |       |  0:07 |   0.1 |
| Create a logical to physical projector             |         |       |  0:45 |   0.9 |
| Clean up the Logical-physical model                |         |       |  5:49 |   7.0 |
| Empty path ID error in logs                        |         |       |  1:15 |   1.5 |
| Implement meta-name validator correctly            |         |       |  0:17 |   0.3 |
| Add dependencies to artefacts                      |         |       |  2:28 |   3.0 |
| Add instances of physical meta-model elements      |         |       |  8:48 |  10.6 |
| Add full and relative path processing to PM        |         |       |  5:32 |   6.7 |
#+TBLFM: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2020-07-17 Fri 16:04]
    :LOGBOOK:
    CLOCK: [2020-07-19 Sun 11:02]--[2020-07-19 Sun 11:22] =>  0:20
    CLOCK: [2020-07-17 Fri 14:22]--[2020-07-17 Fri 16:03] =>  1:41
    CLOCK: [2020-07-17 Fri 08:30]--[2020-07-17 Fri 13:16] =>  4:46
    CLOCK: [2020-07-14 Tue 21:25]--[2020-07-14 Tue 21:53] =>  0:28
    :END:

Add github release notes for previous sprint.

Release Announcements:

- [[https://twitter.com/MarcoCraveiro/status/1284151629391040513][twitter]]
- [[https://www.linkedin.com/posts/marco-craveiro-31558919_masd-projectdogen-activity-6674605622907949056-3fJa][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

**** Dogen v1.0.26, "Rio Bentiaba"

#+caption: Rio de Bentiaba
https://prazerdeconhecer.files.wordpress.com/2015/09/img_1128.jpg

/Bentiaba river, Namibe, Angola. (C) 2016 [[https://prazerdeconhecer.wordpress.com/2015/09/16/benguela-post/][O Viajante]]./

***** Introduction

Welcome to yet another Dogen sprint! This one was a bit of a [[https://wiki.c2.com/?KlingonProgramming][Klingon
Release]], if we've ever seen one. Now, I know we did say [[https://github.com/MASD-Project/dogen/releases/tag/v1.0.25][Sprint 25]] was
a hard slog, but on hindsight 'twas but a mere walk in the park when
compared to what was to come. Sprint 26 was /at least/ twice as hard,
lasted almost twice as long in terms of elapsed-time, had around 20%
extra resourcing compared to what we usually allocate to a sprint and
involved /such/ a degree of abstract thinking - given our modest
abilities - we often lost the plot altogether and had to go back to
first principles. To add insult to injury, after such an intense a
bout of coding, we still ended up /miles off/ of the original sprint
goal, which was clearly far too ambitious to begin with. For all of
its hardships, the sprint did end on a high note when we finally had
time to reflect on what was achieved; and the conceptual model does
appear to be nearing its final shape - though, of course, you'd be
forgiven for thinking you've heard /that one/ before. Alas, some
things never change.

But that's quite enough blabbering - let's look at how and where the
action took place.

***** User visible changes

This section covers stories that affect end users, with the video
providing a quick demonstration of the new features, and the sections
below describing them in more detail. As there were only two small
user facing features, the video also discusses the work on internal
features.

#+caption Sprint 1.0.26 Demo
[[https://img.youtube.com/vi/IugTPs_19KQ/0.jpg][https://youtu.be/IugTPs_19KQ]]

/Video 1: Sprint 26 Demo./

****** Archetype Factories and Transforms

The main story visible to end users this sprint is deeply connected to
our physical model changes, so it requires a fair amount of background
in order to make sense of it. Before we proceed, we must first go
through the usual disclaimers, pointing out that whilst this is
/technically/ a user facing story - in that any user can make use of
this feature - in practice, it's only meant for those working in
Dogen's internals - /i.e./ generating the code generator. It's also
worthwhile pointing out that Dogen uses a /generative architecture/,
where we try to generate as much as possible of Dogen using Dogen; and
that we want the generated portion to increase over time. With those
two important bits of information in hand, let's now take a step back
to see how it all fits together.

MASD's logical model contains a set of modeling elements that capture
the essential characteristics of the /things/ we want to
code-generate. Most of these elements are familiar to programmers
because our targets tend to be artefacts created by programmers; these
are classes, methods, enumerations and the like, the bricks and mortar
we typically associate with the coding activity. However, from a MASD
perspective, the story does not end there - and hence why we used the
term "things". Ultimately, /any/ artefact that contributes to a
software product can be modeled as a logical entity, provided it
exhibits "commonalities" which can be abstracted in order to recreate
it via code generation. The fact that we model programming constructs
is seen as more of a "coincidence" than anything else; what we really
care about is locating and extracting /certain kinds/ of structural
patterns on files. One way to think about this is that we see some
files as higher-dimensional structures that embed lower dimensional
structures, which contain enough information to enable us to recreate
the higher-dimensional structure. Our quest is to find cases where
this happens, and to add the lower dimensional structures to our
logical model. It just so happens that those lower dimensional
structures are often programming constructs.

#+caption Archetypes representing M2T transforms in text.cpp
https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/dogen_text_cpp_physical_elements.png

/Figure 1: Archetypes representing M2T transforms in =text.cpp= model, on Sprint 25./

MASD provides a separation between logical entities and their eventual
/physical/ representation as a file. The mapping between the logical
domain and the physical domain is seen as a projection through these
spaces; one logical element projects to zero, one or many physical
elements. In the physical domain, files are abstracted into
/artefacts/ (the /physical model/ or PM), and each artefact is an
instance of an /archetype/ (the /physical meta model/ or PMM). These
are related in very much the same way a class and an object are: the
artefact is an instance of an archetype. Until recently, we had to
tell Dogen about the available archetypes "by hand" (a rough
approximation): each text template had some boilerplate to inject the
details of the archetype into the framework. After a great deal of
effort, [[https://github.com/MASD-Project/dogen/releases/tag/v1.0.25][Sprint 25]] finally brought us to a point where this code was
generated by Dogen in the spirit of the framework. This was achieved
by treating /archetypes themselves/ as logical concepts, and providing
physical projections for these logical elements as we do for any other
logical element. Which neatly brings us to the present.

Archetypes had a single projection that contained two distinct bits of
functionality:

- *Telling the system about themselves*: the above mentioned
  registration of the archetype, which is used by a set of transforms
  to generate the PMM.
- *Providing an M2T transform*: each archetype takes an associated
  logical element and generates its representation as an artefact.

The more we thought about it, the more it seemed strange that these
two very different concerns were bundled into the same
archetype. After all, we don't mix say serialisation with type
definition on the same archetype, and for good reason. After some
deliberation, we concluded it was there only for historical
reasons. So this sprint we decided to project logical representations
of some physical meta-model elements - /e.g./, =backend=, =facet=,
=archetype= - onto two distinct physical archetypes:

- *Factory*: responsible for creating the physical meta-model element
  for the purposes of the PMM.
- *Transform*: responsible for the M2T transform.

#+caption Archetypes for archetype
https://github.com/MASD-Project/dogen/raw/master/doc/blog/images//dogen_archetype_elements.png

/Figure 2: Archetypes after the split in the present sprint./

It all seemed rather logical (if you pardon the pun), until one
started to implement it. Trouble is, because we are knee-deep in the
meta-land, many things end up in surprising places when one takes them
to their logical consequences. Take archetypes for example. There is
an archetype that represents the archetype factory /itself/, as there
is an archetype that represents the archetype transform /itself/ too,
and there are permutations of the two as well - leading us to very
interesting names such as =archetype_class_header_factory_factory=,
=archetype_class_header_transform_transform= and the like. At first
glance, these appear to be straight out of Spolsky's [[http://pages.di.unipi.it/corradini/Didattica/AP-18/DOCS/WhyDoIHateFrameworks.pdf][Factory Factory
Factory]] parable - a threshold that, when reached, normally signals a
need to halt and rethink the design. Which we did. However, in our
defence, there is /some/ method to the madness. Let's dissect the
first name:

- the logical element this archetype maps to is =archetype=;
- the particular item it is interested in is a C++ =class_header=;
- but its not just any old archetype class header, its the one
  specifically made for the =factory= of the archetype;
- which, as it turns out, its also the factory which generates the
  =factory= of the archetype.

I guess every creator of a "framework" always comes up with
justifications such as the above, and we'd be hard-pressed to explain
why our case is different ("it is, honest guv!"). At any rate, we are
quite happy with this change as its consistent with the conceptual
model and made the code a lot cleaner. Hopefully it will still make
sense when we have to maintain it in a few years time.

****** Add Support for CSV Values in Variability

The variability model is a very important component of Dogen that
often just chugs along, with only the occasional sharing of the
spotlight ([[https://github.com/MASD-Project/dogen/releases/tag/v1.0.22][Sprint 22]]). It saw some minor attention again this sprint,
as we decided to add a new value type to the variability
subsystem. Well, two value types to be precise, both on the theme of
CSV:

- =comma_separated=: allows meta-data values to be retrieved as a set
  of CSV values. These are just a container of strings.
- =comma_separated_collection-: allows meta-data values to be
  collections of =comma_separated= values.

We probably should have used the name =csv= for these types, to be
fair, given its a well known TLA. A clean up for future sprints, no
doubt. At any rate, this new feature was implemented to allow us to
process relation information in a more natural way, like for example:

#+begin_example
#DOGEN masd.physical.constant_relation=dogen.physical.helpers.meta_name_factory,archetype:masd.cpp.types.class_header
#DOGEN masd.physical.variable_relation=self,archetype:masd.cpp.types.archetype_class_header_factory
#+end_example

For details on relations in the PMM, see the internal stories section.

***** Development Matters

In this section we cover topics that are mainly of interest if you
follow Dogen development, such as details on internal stories that
consumed significant resources, important events, etc. As usual, for
all the gory details of the work carried out this sprint, see the
[[https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_26.org][sprint log]].

****** Ephemerides

This sprint saw the 12,000th commit to Dogen. To our displeasure, it
also saw the implementation of the new GitHub design, depicted in
Figure 3.

#+caption Dogen 12000th commit
https://github.com/MASD-Project/dogen/raw/master/doc/blog/images//git_commit_12_000th.png

/Figure 3: Dogen's GitHub repo at the 12,000th commit./

****** Milestones

No milestones where reached this sprint.

****** Significant Internal Stories

This sprint had the ambitious goal of replacing the hard-coded way in
which we handle relationships in both the C++ and C# model with a PMM
based approach. As it turns out, it was an extremely ambitious
goal. There were two core stories that captured this work, each
composed with a large number of small sub-stories; we grouped these
into the two sections below.

******* Add Relations Between Archetypes in the PMM

It has been known for a long time that certain kinds of relationships
exist at the /archetype level/, regardless of the state of the logical
modeling element we are trying to generate. In other words, an
archetype can require a /fixed/ set of logical model elements,
projected to a given archetype (/e.g./, say the type definition). For
instance, when you implement an archetype, you may find it needs some
specific "platform services" such as logging, iostreams, standard
exceptions and so forth, which must be present regardless of the state
of the logical model elements processed by the M2T transform. This is
somewhat of a simplification because sometimes there is conditionality
attached to these relations, but its a sufficient approximation of the
truth for the present purposes. These we shall name /constant
relations/, as they do not change with regards to the logical model
element.

In addition, archetypes also have relations with other archetypes
based on the specific contents of the logical model element they are
trying to generate; for example, having an attribute may require
including one or more headers for the logical model elements as given
by the attribute's type - /e.g./, =std::unordered_map<std::string,
some_user_type>= requires =unordered_map= and =string= from the =std=
model, as well as =some_user_type= from the present model; or an
archetype may require another archetype like, for example, a class
implementation will always need the class header. In the first case we
have an /explicit relation/, whereas in the latter case its an
/implicit relation/, but both of these fall under the umbrella of
/variable relations/ because they vary depending on the data contained
in the logical model element. They can only be known for sure when we
are processing a specific model.

Up to now, we have modeled the projection of relations from the
logical dimension into the physical dimension by allowing archetypes
themselves to "manually" create dependencies. This meant that we
pushed all of the problem to "run time", regardless of whether the
relations are variable or constant; worse, it also means we've
hard-coded the relations in a way that is completely transparent to
the models - with "transparent" here having a bad connotation. Listing
1 provides an example of how these are declared. This approach is of
course very much in keeping with Dogen's unspoken motto, shamelessly
stolen [[https://wiki.c2.com/?MakeItWorkMakeItRightMakeItFast][elsewhere]], of "first hard-code and get it to work in /any way
possible/, as quickly as possible, then continuously refactor". Sadly,
now has come the time for the second part of that motto, and that is
what this story concerns itself with.

#+begin_src c++
    const auto io_arch(transforms::io::traits::class_header_archetype_qn());
    const bool in_inheritance(o.is_parent() || o.is_child());
    const bool io_enabled(builder.is_enabled(o.name(), io_arch));
    const bool requires_io(io_enabled && in_inheritance);

    const auto ios(inclusion_constants::std::iosfwd());
    if (requires_io)
        builder.add(ios);

    using ser = transforms::serialization::traits;
    const auto ser_fwd_arch(ser::class_forward_declarations_archetype_qn());
    builder.add(o.name(), ser_fwd_arch);

    const auto carch(traits::canonical_archetype());
    builder.add(o.transparent_associations(), carch);

    const auto fwd_arch(traits::class_forward_declarations_archetype_qn());
    builder.add(o.opaque_associations(), fwd_arch);

    const auto self_arch(class_header_transform::static_archetype().meta_name().qualified());
    builder.add(o.parents(), self_arch);

    using hash = transforms::hash::traits;
    const auto hash_carch(hash::traits::canonical_archetype());
    builder.add(o.associative_container_keys(), hash_carch);
#+end_src

/Listing 1: Fragment of inclusion dependencies in the =class_header_transform=./

The reason why we do not want relations to be transparent is because
the graph of physical dependencies contains a lot of valuable
information; for example, it could tell us if the user has decided to
instantiate an invalid configuration such as disabling the =hash=
facet and then subsequently creating a =std::unordered_map= instance,
which requires it. In addition, we always wondered if there really was
a reason to have a completely separate handling of relations for C++
and C#, or whether it was possible to combine the two into a unified
approach that took into account the gulf of differences between the
languages (/e.g./, =#include= of files versus =using= of
namespaces). So the purpose of this story was to try to bring
relations into the PMM as first class citizens so that we could reason
about them, and then to generate the physical specificities of each
technical space from this abstraction. With this release we have done
the first of these steps: we have introduced all of the machinery that
declares relations as part of the archetype factory generation, as
well as all the paraphernalia of logical transforms which process the
meta-data in order to bring it into a usable form in the physical
domain. It was a very large story in of itself, but there were also a
large number of smaller stories that formed the overall picture. These
can be briefly summarised as follows:

- *Analysis on solving relationship problems*: Much of the work in
  finding a taxonomy for the different relation types came from this
  story, as well as deciding on the overall approach for modeling them
  in the logical and physical models.
- *Create a TS agnostic representation of inclusion*: Due to how we
  hard-coded relations, we needed to extract the requirements for the
  C++ Technical Space in a form that did not pull in too much
  C++-specific concepts. We've had the notion that some archetypes are
  "non-inclusive", that is to say, they generate files which we think
  cannot be part of any relation (/e.g./ inclusion of a =cpp= file
  is not allowed). In this story we tried to generalise this notion.
- *Use PMM to compute =meta_name_indices=*: As part of the PMM
  clean-up, we want to start using it as much as possible to generate
  all of the data structures that we are at present hard-coded. This
  story was one such clean-up, which consolidated a lot of dispersed
  infrastructure into the PMM.
- *Add labels to archetypes*: In the existing implementation we have
  the notion of "canonical archetypes". These exist so that when we
  have a logical model element and require the archetype that contains
  its type definition, we can "resolve" it to the appropriate
  archetype depending on the logical meta-type; /e.g./ =enum_header=,
  =class_header=, and so forth. Labels were designed as generalisation
  of this mapping infrastructure, so that we can have arbitrary
  labels, including the somewhat more meaningful =type_definition=.
- *Analysis on archetype relations for stitch templates*: Stitch
  templates are their own nest of wasps when it comes to relations. We
  incorrectly allowed templates to have their own "inclusion" system
  via the =<#@ masd.stitch.inclusion_dependency "x.hpp">=
  directive. This seemed really clever at the time, but in light of
  this analysis, it clearly suffers from exactly the same issues as
  the regular M2T transforms did - we have no way of knowing what
  these templates are pulling in, whether those models are available
  and so forth. With this analysis story we found a generalised way to
  bring in relations from stitch templates into the fold. However, the
  implementation will be no easy feat.
- *Analysis on reducing the number of required wale keys*: Whilst we
  were looking at stitch it seemed only logical that we also looked at
  our other templating engine, wale (really, a poor man's
  implementation of [[https://mustache.github.io/][mustache]], which we will hopefully replace at some
  point). It seems obvious that we have far too many keys being passed
  in to our wale templates, and that the required data is available in
  the PMM. This story pointed out which bits of information can
  already be supplied by the PMM. We need a follow up implementation
  story to address it.
- *Analysis on implementing containment with configuration*: this
  story provides a much easier way to handle enablement, as opposed to
  the pairs of transforms we have at present that handle first a
  "global configuration" and then a "local configuration". With the
  analysis in this story we could "flatten" these into a single
  configuration which could then be processed in one go. However, the
  implementation story for this analysis will probably have to remain
  in the backlog as its not exactly a pressing concern.
- *Merge kernel with physical meta-model**: We originally had the
  notion of a "kernel", which grouped backends, facets and
  archetypes. However, we still don't really have a good use case for
  having more than one kernel. With this story we deprecated and
  removed the =kernel= meta-entity and flattened the PMM. We can
  always reintroduce it if a use case is found.
- *Move templating aspects of archetype into a generator type*: Due to
  the complexity of having relations for the archetype as well as
  relations for the templates, we factored out the templating aspects
  of the archetype into a new logical entity called
  =archetype_text_templating=. This made the modeling a bit more
  clearer, as opposed to names such as "meta-relations" that had been
  tried before. This story was further complemented by "Rename
  archetype generator" where we changed the name to its present form.
- *Remove traits for archetypes*: With the rise of the PMM, we no
  longer need to hard-code archetype names via the so-called
  "traits". We started removing some of these, but many of the pesky
  critters still remain.
- *Convert =wale_template_reference= to meta-data*: Archetypes always
  had the ability to reference wale templates, as well as containing a
  stitch template. Due to some misguided need for consistency, we
  modeled both stitch template and the reference to a wale template as
  attributes. However, the net result was a huge amount of
  duplication, given that almost all archetypes use one of two wale
  templates. The problem should be fairly evident in [[https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_text_cpp_physical_elements.png][Figure 1]], even
  though it only shows a narrow window of the =text.cpp= model. With
  this story we moved this field to meta-data, meaning we can now use
  the profiling system to our advantage and therefore remove all
  duplication. [[https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_archetype_elements.png][Figure 2]] depicts the new look.
- *Archetype kind and postfix as parts of a larger pattern*: More
  analysis trying to understand how we can reconstruct file paths from
  the generalised elements we have in PMM. We tried to see if we can
  model these using the new labelling approach, with moderate
  success. The implementation story for this analysis is to follow,
  likely next sprint.
- *Split physical relation properties*: Trivial story to improve the
  modeling of relations on the physical domain. These now have its own
  top-level class.

All of these disparate stories molded the logical and physical models
into containing the data needed to handle relations. After all of this
work, we just about got to the point where we were trying to generate
the relations themselves; and then we realised this task could not be
completed until we resolved some key modeling errors of data types
that really belonged in the physical domain but were unfortunately
located elsewhere. So we downed our tools and started work on the next
story.

******* Create an Archetype Repository in Physical Model

This story started with very good intentions but quickly became a
dishevelled grab-bag of refactoring efforts. The main idea behind it
was that we seem to have two distinct phases of processing of the
physical model:

- the first phase happens during the logical to physical projection;
  at this point we need to perform a number of transforms to the
  physical model, but we are not quite yet ready to let go of the
  logical model as we still need the combined logical-physical space
  in order to perform the M2T transforms.
- the second phase happens once we have the stand alone physical
  model. This is fairly straightforward, dealing with any
  post-processing that may be required.

Our key concern here is with the first phase - and hopefully you can
now see how this story relates to the previous one, given that we'd
like to stick the processing of relations somewhere in there. Whilst
it may be tempting to create an instance of the physical model for the
first phase, we would then have to throw it away when we resume the
guise of the logical-physical space in =dogen.text=. Besides, we did
not really need a full blown physical model instance; all that is
required is a set of artefacts to populate. And with this, the notion
of the "artefact repository" was born. Whilst we were doing so, we
also noticed something else that was rather interesting: the
logical-physical space deals mainly with /planes/ of the physical
space that pertain to each individual modeling element (as covered by
the story "Add hash map of artefacts in physical model"). We had
originally incorrectly called these planes "manifolds", but subsequent
reading seems to imply they are just 1D planes of a 2D space (see
[[http://bjlkeng.github.io/posts/manifolds][Manifolds: A Gentle Introduction]]). Once we understood that, we then
refactored both the artefact repository as well as the physical model
to be implemented in terms of these planes - which we have named
=artefact_set= for now, though perhaps the name needs revisiting.

It took some doing to put the artefact repository and the plane
approach in, but once it was indeed in, it made possible a great
number of cleanups that we had been trying to do for many sprints. In
the end, we were finally able to move /all/ physical concepts that had
been scattered around logical and text models - at one point we
generated over 10 temporary non-buildable commits before squashing it
into one [[https://github.com/MASD-Project/dogen/commit/8499f7bc74a60c7717fe7e1ab2a2b52fccf1dd5d][monstrous commit]]. Though some further refactoring is no doubt
required, at least now these types live in their final resting place
in the physical model ([[https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/physical_model_after_artefact_set_refactor.png][Figure 4]]), together with a chain that populates
the artefact repository. In the end, it was a rather rewarding change
though it certainly did not seem so as we in the thick of doing it.

#+caption Physical model
https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/physical_model_after_artefact_set_refactor.png

/Figure 4/: Physical model after refactoring.

******* MDE Paper of the Week (PofW)

This sprint we spent a bit more than usual reading MDE papers (6.1%),
and read a total of 5 papers. It should have really been 6 but due to
time constraints we missed one. As usual, we published a video on
youtube with the review of each paper. The following papers were read:

- [[https://youtu.be/UlYLsBHjU1I][MDE PotW 10: Using Aspects to Model Product Line Variability]]:
  Groher, Iris, and Markus Voelter. "Using Aspects to Model Product
  Line Variability." SPLC (2). 2008. [[https://pdfs.semanticscholar.org/4c77/0315cd8151f6c162ac2f99ecc62225f4c94e.pdf?_ga=2.246561604.1739388568.1592151663-6190553.1592151663][PDF]].
- [[https://youtu.be/9x_pqJOw_FE][MDE PotW 11: A flexible code generator for MOF based modeling
  languages]]: Bichler, Lutz. "A flexible code generator for MOF-based
  modeling languages." 2nd OOPSLA Workshop on Generative Techniques in
  the context of Model Driven Architecture. 2003. [[https://s23m.com/oopsla2003/bichler.pdf][PDF]].
- [[https://youtu.be/_1Xc2L5RpTY][MDE PotW 12: A Comparison of Generative Approaches]]: XVCL and
  GenVoca: Blair, James, and Don Batory. "A Comparison of Generative
  Approaches: XVCL and GenVoca." Technical report, The University of
  Texas at Austin, Department of Computer Sciences (2004). [[http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.457.1399&rep=rep1&type=pdf][PDF]].
- [[https://youtu.be/XfVGK8XOKmk][MDE PotW 13: An evaluation of the Graphical Modeling Framework GMF]]:
  Seehusen, Fredrik, and Ketil Stølen. "An evaluation of the graphical
  modeling framework (gmf) based on the development of the coras
  tool." International Conference on Theory and Practice of Model
  Transformations. Springer, Berlin, Heidelberg, 2011. [[http://hjem.ifi.uio.no/ketils/kst/Articles/2011.ICMT.pdf][PDF]].
- [[https://youtu.be/OvCgcKHc__Y][MDE PotW 14: Features as transformations: A generative approach to
  software development]]: Vranić, Valentino, and Roman
  Táborský. "Features as transformations: A generative approach to
  software development." Computer Science and Information Systems 13.3
  (2016): 759-778. [[https://pdfs.semanticscholar.org/7f20/ee0ef94ba20161611c2ae184e6040f9d2fe1.pdf?_ga=2.47007141.386256099.1594564659-1149343892.1591869910][PDF]]

****** Resourcing

As we alluded to in the introduction, this sprint had a whopping 95
hours worth of effort as opposed to the more traditional 80 hours -
18.7% more resourcing than usual. It also lasted for some 6 weeks
rather than 4, meaning our utilisation rate was a measly 35%, our
second worse since records begun on [[https://github.com/MASD-Project/dogen/releases/tag/v1.0.20][Sprint 20]] ([[https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/physical_model_after_artefact_set_refactor.png][Figure 4]]). Partially
this was due to work and life constraints, but partially it was also
due to the need to have some time away from the rarefied environment
of the logical-physical space, which is not exactly a friendly place
to those who do not favour abstraction.

#+caption Sprint 26 stories
https://github.com/MASD-Project/dogen/raw/master/doc/blog/images/dogen_utilisation_rate_sprint_26.png

/Figure 5_: Utilisation rate since Sprint 20./

If one ignores those glaring abnormalities, the sprint was otherwise
fairly normal. Around 75% of the resourcing was concerned with stories
that contributed directly to the sprint goal - not quite the 80% of
the previous sprint but not too shabby a number either. As the
colouration of Figure 6 attests, those 75% were spread out across a
decent number of stories, meaning we didn't do so bad in capturing the
work performed. On non-core matters, we spent around 6.1% on MDE
papers - up from 5.2% last sprint - but giving us a good bang for the
buck with 5 papers instead of the 4 we had last sprint. Its a bit
painful to read papers after a long week of coding for both
professional and personal projects, but its definitely worth our
while. We also had around 2.2% of the ask wasted on spikes, mainly
troubleshooting problems with the nightly build and with
Emacs/clangd. Finally, we dedicated almost 16% to process related
matters, including 8.4% on editing the release notes and 6.1% on
backlog grooming. Overall, it was a solid effort from a resourcing
perspective, with the exception of the utilisation rate. Hopefully,
regular service will be resumed next sprint on that regard.

#+caption Sprint 26 stories
https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_26_pie_chart.jpg

/Figure 6: Cost of stories for sprint 26./

****** Roadmap

Sadly, not much to be said for our road map. We did not make any
progress with regards to closing the fabled generation meta-model
clean-up given that we are yet to do a dent in the PMM relations. We
probably should rename this milestone as well, given the generation
model is long gone from the code-base. One for next sprint.

#+caption: Project Plan
https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_26_project_plan.png

#+caption: Resource Allocation Graph
https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_26_resource_allocation_graph.png

***** Binaries

You can download binaries from either [[https://bintray.com/masd-project/main/dogen/1.0.26][Bintray]] or GitHub, as per
Table 2. All binaries are 64-bit. For all other architectures and/or
operative systems, you will need to build Dogen from source. Source
downloads are available in [[https://github.com/MASD-Project/dogen/archive/v1.0.26.zip][zip]] or [[https://github.com/MASD-Project/dogen/archive/v1.0.26.tar.gz][tar.gz]] format.

| Operative System    | Format | BinTray                             | GitHub                              |
|---------------------+--------+-------------------------------------+-------------------------------------|
| Linux Debian/Ubuntu | Deb    | [[https://dl.bintray.com/masd-project/main/1.0.26/dogen_1.0.26_amd64-applications.deb][dogen_1.0.26_amd64-applications.deb]] | [[https://github.com/MASD-Project/dogen/releases/download/v1.0.26/dogen_1.0.26_amd64-applications.deb][dogen_1.0.26_amd64-applications.deb]] |
| OSX                 | DMG    | [[https://dl.bintray.com/masd-project/main/1.0.26/DOGEN-1.0.26-Darwin-x86_64.dmg][DOGEN-1.0.26-Darwin-x86_64.dmg]]      | [[https://github.com/MASD-Project/dogen/releases/download/v1.0.26/DOGEN-1.0.26-Darwin-x86_64.dmg][DOGEN-1.0.26-Darwin-x86_64.dmg]]      |
| Windows             | MSI    | [[https://dl.bintray.com/masd-project/main/DOGEN-1.0.26-Windows-AMD64.msi][DOGEN-1.0.26-Windows-AMD64.msi]]      | [[https://github.com/MASD-Project/dogen/releases/download/v1.0.26/DOGEN-1.0.26-Windows-AMD64.msi][DOGEN-1.0.26-Windows-AMD64.msi]]      |

/Table 1: Binary packages for Dogen./

*Note.* The OSX and Linux binaries are not stripped at present and so
are larger than they should be. We have [[https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped][an outstanding story]] to
address this issue, but sadly CMake does not make this a trivial
undertaking.

***** Next Sprint

The goal for the next sprint is carried over from the previous
sprint. Given the overambitious nature of the previous sprint's goal,
this time we decided to go for a single objective:

- implement locator and dependencies via PMM.

That's all for this release. Happy Modeling!

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    CLOSED: [2020-07-17 Fri 16:36]
    :LOGBOOK:
    CLOCK: [2020-07-17 Fri 16:37]--[2020-07-17 Fri 16:46] =>  0:09
    CLOCK: [2020-07-17 Fri 16:04]--[2020-07-17 Fri 16:36] =>  0:32
    :END:

Time spent creating the demo and presentation.

**** Presentation

***** Dogen v1.0.26, "Rio Bentiaba"

    Marco Craveiro
    Domain Driven Development
    Released on 13th July 2020

***** Archetype Factories and Transforms

- split factory from transform

***** Add Support for CSV Values in Variability

- CSV
- CSV collection

***** Add Relations Between Archetypes in the PMM

- add all the types related to relations

***** Create an Archetype Repository in Physical Model

- archetype repository artefact set
- discuss how the chains are now connected.

*** COMPLETED Sprint and product backlog grooming                     :story:
    CLOSED: [2020-09-21 Mon 03:03]
    :LOGBOOK:
    CLOCK: [2020-09-11 Fri 15:58]--[2020-09-11 Fri 16:20] =>  0:22
    CLOCK: [2020-09-11 Fri 10:48]--[2020-09-11 Fri 10:57] =>  0:09
    CLOCK: [2020-09-11 Fri 09:00]--[2020-09-11 Fri 09:32] =>  0:32
    CLOCK: [2020-07-17 Fri 16:47]--[2020-07-17 Fri 17:53] =>  1:06
    CLOCK: [2020-07-13 Mon 23:51]--[2020-07-14 Tue 00:08] =>  0:17
    :END:

Updates to sprint and product backlog.

*** COMPLETED Nightly nursing and other spikes                        :story:
    CLOSED: [2020-09-21 Mon 03:03]
    :LOGBOOK:
    CLOCK: [2020-07-26 Sun 15:41]--[2020-07-26 Sun 19:04] =>  3:23
    CLOCK: [2020-07-19 Sun 11:31]--[2020-07-19 Sun 12:30] =>  0:59
    :END:

Time spent troubleshooting environmental problems.

- clangd seized up, so did a dist-upgrade and updated all emacs
  packages.
- error:

:   SubmitURL: http://my.cdash.org/submit.php?project=MASD+Project+-+Dogen
:   Upload file: /home/marco/nightly/dogen/build/output/clang9/Debug/Testing/20200726-0000/Update.xml to http://my.cdash.org/submit.php?project=MASD+Project+-+Dogen&FileName=lovelace___clang9-Linux-x86_64-Debug___20200726-0000-Nightly___XML___Update.xml&build=clang9-Linux-x86_64-Debug&site=lovelace&stamp=20200726-0000-Nightly&MD5=807f7da98b878c6b03ab45fa7ed66fe1 Size: 602
:   Error when uploading file: /home/marco/nightly/dogen/build/output/clang9/Debug/Testing/20200726-0000/Update.xml
:   Error message was: Operation too slow. Less than 1 bytes/sec transferred the last 120 seconds
:   Problems when submitting via HTTP

  Need to retry submission.

*** COMPLETED Implement formatting styles in physical model           :story:
    CLOSED: [2020-07-17 Fri 17:28]

*Rationale*: implemented with the refactoring in the previous sprint.

We need to move the types related to formatting styles into physical
model, and transfors as well. WE should also address formatting input.

Merged stories:

*Move formatting styles into generation*

We need to support the formatting styles at the meta-model level.

*Replace all formatting styles with the ones in physical model*

We still have a number of copies of this enumeration.

*** COMPLETED Add PMM enablement transform                            :story:
    CLOSED: [2020-07-17 Fri 17:28]

*Rationale*: implemented with the refactoring in the previous sprint.

This transform reads the global enablement flags for backend, facet
and archetype. It is done as part of the chain to produce the PMM.

*** COMPLETED Add a PM enablement and overwrite transform             :story:
    CLOSED: [2020-07-17 Fri 17:28]

*Rationale*: implemented with the refactoring in the previous sprint.

This relies on PMM enablement flags. Also, it reads the local
archetype enablement and overwrite flags and has the logic to set it
as per current enablement transform.

Once this transform is implemented, we should try disabling the
existing enablement transform and see what breaks.

*** COMPLETED Consider bucketing elements by meta-type in generation model :story:
    CLOSED: [2020-07-17 Fri 17:41]

*Rationale*: implemented with the refactoring in the previous sprint.

At the moment we have a flat container of elements in the main
model. However, it seems like one of its use cases will be to bucket
the elements by meta-type before processing: formatters will want to
locate all formatters for a given meta-type and apply them all. At
present we are asking for the formatters for meta-name
repeatedly. This makes no sense, we should just ask for them once and
apply all formatters in one go.

For this we could simply group elements by meta-name in the model
itself and then use that container at formatting time. However, there
may be cases where looping through the whole model is more convenient
(during transforms) so this is not without its downsides.

Alternatively we could consider just bucketing in the formatters'
workflow itself.

This work will only be useful once we get rid of the formattables
model.

This can be done in the generation model, as part of the generation
clean up.

*** COMPLETED Add =is_generatable= to logical model                   :story:
    CLOSED: [2020-07-17 Fri 17:51]

*Rationale*: implemented with the refactoring in the previous sprint.

Logical types which cannot be generated should be removed prior to
physical expansion. There are two types:

- intrinsically non-generatable types such as object templates, etc.
- types that may not be generated depending on state: modules.

In the future, when we support the static / dynamic pattern,

Tasks:

- add a generatable flag in logical model elements with associated
  transform.
- add a pruning transform that filters out all non-generatable types
  from logical model.

Merged stories:

*Intrinsic non-generatable types

In the decoration transform we have this hack:

: bool decoration_transform::
: is_generatable(const assets::meta_model::name& meta_name) {
:     // FIXME: massive hack for now.
:     using mnf = assets::helpers::meta_name_factory;
:     static const auto otn(mnf::make_object_template_name());
:     static const auto ln(mnf::make_licence_name());
:     static const auto mln(mnf::make_modeline_name());
:     static const auto mgn(mnf::make_modeline_group_name());
:     static const auto gmn(mnf::make_generation_marker_name());
:
:     const auto id(meta_name.qualified().dot());
:     return
:         id != otn.qualified().dot() &&
:         id != ln.qualified().dot() &&
:         id != mln.qualified().dot() &&
:         id != mgn.qualified().dot() &&
:         id != gmn.qualified().dot();
: }

This is done because we know up front that some elements in the assets
meta-model cannot be generated. We need a way to tag this elements
statically. This should be done when the elements are code
generated. It is not yet clear how this should be done though.

Notes:

- one possible approach is to have a constant that is code generated
  which states if a type is meant for generation or not.
- however, it would be even better if we could determine if a type has
  formatters or not. This would mean we would cover two possible
  scenarios: types that are intrinsically non-generatable and types
  that are not yet generatable. It may be that there is no need to
  distinguish between these two.
- when we have meta-model elements for logical meta-elements we just
  need to add this as a property (e.g. generatable). If a user tries
  to add a formatter to a non-generatable type we error.

*** COMPLETED Create an =ident= model                                 :story:
    CLOSED: [2020-09-06 Sun 13:37]
    :LOGBOOK:
    CLOCK: [2020-09-06 Sun 13:28]--[2020-09-06 Sun 13:37] =>  0:09
    CLOCK: [2020-09-06 Sun 11:08]--[2020-09-06 Sun 12:24] =>  1:16
    CLOCK: [2020-09-06 Sun 10:05]--[2020-09-06 Sun 11:07] =>  1:02
    CLOCK: [2020-09-05 Sat 22:04]--[2020-09-05 Sat 22:10] =>  0:06
    CLOCK: [2020-09-05 Sat 21:55]--[2020-09-05 Sat 22:03] =>  0:08
    CLOCK: [2020-09-05 Sat 20:41]--[2020-09-05 Sat 20:59] =>  0:18
    CLOCK: [2020-09-05 Sat 14:05]--[2020-09-05 Sat 16:12] =>  2:07
    CLOCK: [2020-09-05 Sat 12:01]--[2020-09-05 Sat 13:30] =>  1:29
    CLOCK: [2020-09-05 Sat 09:22]--[2020-09-05 Sat 10:00] =>  0:38
    CLOCK: [2020-09-04 Fri 15:06]--[2020-09-04 Fri 17:58] =>  2:52
    CLOCK: [2020-09-04 Fri 12:45]--[2020-09-04 Fri 14:29] =>  2:21
    CLOCK: [2020-09-04 Fri 11:31]--[2020-09-04 Fri 11:46] =>  0:15
    CLOCK: [2020-09-04 Fri 08:37]--[2020-09-04 Fri 11:30] =>  2:53
    CLOCK: [2020-08-05 Wed 17:45]--[2020-08-05 Wed 18:02] =>  0:17
    CLOCK: [2020-08-05 Wed 10:25]--[2020-08-05 Wed 11:46] =>  1:21
    CLOCK: [2020-08-04 Tue 19:21]--[2020-08-04 Tue 20:02] =>  0:41
    CLOCK: [2020-08-04 Tue 14:38]--[2020-08-04 Tue 16:05] =>  1:27
    CLOCK: [2020-07-26 Sun 16:01]--[2020-07-26 Sun 19:04] =>  3:03
    CLOCK: [2020-07-26 Sun 01:30]--[2020-07-26 Sun 01:37] =>  0:07
    CLOCK: [2020-07-25 Sat 23:01]--[2020-07-26 Sun 01:21] =>  2:20
    CLOCK: [2020-07-25 Sat 17:35]--[2020-07-25 Sat 17:45] =>  0:10
    CLOCK: [2020-07-25 Sat 16:06]--[2020-07-25 Sat 17:34] =>  1:28
    CLOCK: [2020-07-25 Sat 12:10]--[2020-07-25 Sat 14:40] =>  2:30
    CLOCK: [2020-07-24 Fri 23:48]--[2020-07-25 Sat 01:45] =>  1:57
    CLOCK: [2020-07-24 Fri 14:21]--[2020-07-24 Fri 18:50] =>  4:29
    CLOCK: [2020-07-24 Fri 13:01]--[2020-07-24 Fri 13:07] =>  0:06
    CLOCK: [2020-07-24 Fri 10:00]--[2020-07-24 Fri 13:00] =>  3:00
    CLOCK: [2020-07-19 Sun 12:42]--[2020-07-19 Sun 12:48] =>  0:06
    CLOCK: [2020-07-19 Sun 11:22]--[2020-07-19 Sun 11:30] =>  0:08
    CLOCK: [2020-07-18 Sat 23:51]--[2020-07-19 Sun 01:12] =>  1:21
    CLOCK: [2020-07-18 Sat 18:36]--[2020-07-18 Sat 19:04] =>  0:28
    CLOCK: [2020-07-18 Sat 17:05]--[2020-07-18 Sat 18:16] =>  1:11
    CLOCK: [2020-07-18 Sat 12:05]--[2020-07-18 Sat 13:00] =>  0:55
    :END:

At present we are duplicating a number of concepts related to identity:

- logical and physical names, locations and IDs.
- provenance
- labels
- simple name / qualified name

It seems that we now have enough identification related types to
warrant a model for it. It seems a bit painful to call it
=identification= so we we can use the shorter =ident= name. We should
also add primitives for IDs though we may not start to make use of
them instantly. We should also add a logical physical ID. Note that we
also have some elements which need to be part of this model because
they are shared but are not exactly related to the model's concern:

- technical space: the odd one out, but we need to access it from a
  number of models. We need to make some (improbable) case as to why
  this is related to identification.

Notes:

- it would be nice if we could move the qualified representation stuff
  into a class that is not directly related to the qualified
  name.
- remove uses of string processor in variability, use new identity
  model.
- rename is proxy model feature to PDM.
- rename compute SHA1 hash transform in injection to provenance
  transform.
- for some reason we are still generating artefacts for the global
  module. Check the is generatable transform in logical model.

*** COMPLETED Add a tagged value class                                :story:
    CLOSED: [2020-09-11 Fri 09:14]

*Rationale: done as part of the identification work*

In the injection model we have a simple c++ pair for tagged values. We
should create a class for it, using UML terminology: =tagged_value=,
where name is =tag= and value is =value=.

Links:

- [[https://github.com/ISO-TC211/UML-Best-Practices/wiki/Tagged-values][UML-Best-Practices: Tagged values]]

*** COMPLETED Replace uses of traits in archetype initialisation      :story:
    CLOSED: [2020-09-11 Fri 09:30]

*Rationale*: this was implemented already.

At present we are relying on the traits class to initialise the
archetype in the wale template:

: physical::entities::archetype {{class.simple_name}}::static_archetype() const {
:    static physical::entities::archetype r([]() {
:        physical::entities::archetype r;
:        using pmnf = physical::helpers::meta_name_factory;
:        r.meta_name(pmnf::make(cpp::traits::backend_sn(),
:            traits::facet_sn(), traits::{{archetype.simple_name}}_archetype_sn()));
:        using lmnf = {{meta_name_factory}};
:        r.logical_meta_element_id(lmnf::make_{{meta_element}}_name().qualified().dot());
:        return r;
:    }());
:    return r;
: }

However, given that we now know this template is used only for
archetypes and we want to enforce a structural consistency, we should
start to initialise all of these variables as literal strings supplied
as wale parameters. These should be deduced from the logical model
element. It is fine to hard-code this because we are designing it
explicitly for archetypes, not as a general purpose mechanism.

This can only be done when we are generating the PMM via facets and
backends.

Merged stories:

*Replace traits with calls to the PMM elements*

Where we are using these traits classes, we should really be including
the formatter and calling for its static name - at least within each
backend.

*** COMPLETED Rename injection to codec                               :story:
    CLOSED: [2020-09-11 Fri 10:21]
    :LOGBOOK:
    CLOCK: [2020-09-11 Fri 09:33]--[2020-09-11 Fri 10:21] =>  0:48
    :END:

We need to search the backlog for this. We originally thought
injection would reflect the fact that this model is designed for input
into Dogen but in reality, it has evolved more like an "input -
output" model (i.e. injection and extraction). Since we do not have a
good name for this, we should use =codec= which is well understood
from other domains. After all we are decoding and encoding into
external formats.

*** COMPLETED Add artefact's archetype to artefact class              :story:
    CLOSED: [2020-09-11 Fri 10:30]
    :LOGBOOK:
    CLOCK: [2020-09-11 Fri 10:22]--[2020-09-11 Fri 10:29] =>  0:07
    :END:

*Rationale*: was already implemented.

For now a simple string would do. In the future we may need a pointer
and join the PMM to the PM. We'll see how the use cases develop.

Actually we already have the physical meta-name. Just need to check if
its being populated. Confirmed.

*** CANCELLED Remove support for split projects                       :story:
    CLOSED: [2020-09-11 Fri 16:06]
    :LOGBOOK:
    CLOCK: [2020-09-11 Fri 14:38]--[2020-09-11 Fri 14:45] =>  0:07
    :END:

*Rationale*: this is not much of a win as explained in story.

At present we allow users to have "split projects": this means you can
relocate one of the parts outside the project directory. We had a use
case for this long ago but it has since not been required. This logic
had a large layer of complexity in the new world where everything is
data driven because now we need to keep track all of the relocations
performed in any of the referenced models in order to compute a
path. And it is likely that the existing implementation does not even
support cross-model usage correctly. Due to this we should just remove
it and then re-implement it in the future as the use cases arrive.

Actually to be honest, we cannot get away from reading properties of
the part, backend etc - so the relative path to the part is only a
minor thing. Also, we will always need to handle references correctly
for other reasons so therefore this is not a major block. We should
carry on supporting split projects. Initially we will only support
them for the current use case (i.e. you cannot reference split
models). Eventually when we address the limitations on references we
can also sort out this issue.

*** COMPLETED Create a logical to physical projector                  :story:
    CLOSED: [2020-09-19 Sat 13:48]
    :LOGBOOK:
    CLOCK: [2020-09-19 Sat 12:45]--[2020-09-19 Sat 13:30] =>  1:03
    :END:

The projection logic is now getting really complex. We really need a
class to take over this work. It should also group model elements by
type so that we can obtain the archetypes just once instead of
processing one model element at a time.

*** COMPLETED Clean up the Logical-physical model                     :story:
    CLOSED: [2020-09-19 Sat 14:13]
    :LOGBOOK:
    CLOCK: [2020-09-20 Sun 08:51]--[2020-09-20 Sun 09:40] =>  0:49
    CLOCK: [2020-09-19 Sat 13:31]--[2020-09-19 Sat 14:13] =>  0:42
    CLOCK: [2020-09-19 Sat 13:31]--[2020-09-19 Sat 13:48] =>  0:17
    CLOCK: [2020-09-19 Sat 12:01]--[2020-09-19 Sat 12:45] =>  0:44
    CLOCK: [2020-09-19 Sat 09:31]--[2020-09-19 Sat 09:57] =>  0:26
    CLOCK: [2020-09-19 Sat 06:57]--[2020-09-19 Sat 08:23] =>  1:26
    CLOCK: [2020-09-18 Fri 16:05]--[2020-09-18 Fri 17:30] =>  1:25
    :END:

Thus far we have avoided creating a logical physical model (LPM). This
is mainly because we didn't really know where it should go. However,
as the clean up related to the extraction properties revealed, the
text model /is/ the LPM. What we have done so far obscures this
because we selectively copied properties from both the logical and
physical models and made a few minor modifications to these bits. In
reality, it would be much cleaner if this model had only three
attributes:

- the logical model;
- the physical model;
- the LPM.

The LPM is very simple, just a pairing of logical element to
=artefact_set=.

This means we can clean up a lot of stuff:

- remove all duplicate data structures and associated transforms;
- remove the artefact repository - we can now directly store the
  entire PM in the LPM.

Notes:

- start by copying across the logical model and delete all
  properties.
- rename elements in text model.
- remove properties from extraction properties.
- transforms need to return physical IDs.
- check orchestration physical transforms as we seem to be doing a lot
  of silly things there.
- rename artefact set to physical region to match text model.

*** COMPLETED Empty path ID error in logs                             :story:
    CLOSED: [2020-09-20 Sun 16:27]
    :LOGBOOK:
    CLOCK: [2020-09-20 Sun 15:12]--[2020-09-20 Sun 16:27] =>  1:15
    :END:

We now generate lots of these:

: 2020-09-18 11:38:49.874503 [ERROR] [orchestration.transforms.text_model_to_physical_model_transform] Artefact has an empty path. ID:  { "__type__": "dogen::identification::entities::physical_id", "value": "<global_module><masd.cpp.types.namespace_header>" }
: 2020-09-18 11:38:49.874509 [ERROR] [orchestration.transforms.text_model_to_physical_model_transform] Artefact has an empty path. ID:  { "__type__": "dogen::identification::entities::physical_id", "value": "<cpp_ref_impl.profiles><masd.cpp.types.namespace_header>" }
: 2020-09-18 11:38:49.874512 [ERROR] [orchestration.transforms.text_model_to_physical_model_transform] Artefact has an empty path. ID:  { "__type__": "dogen::identification::entities::physical_id", "value": "<masd.lam><masd.cpp.types.namespace_header>" }
: 2020-09-18 11:38:49.874516 [ERROR] [orchestration.transforms.text_model_to_physical_model_transform] Artefact has an empty path. ID:  { "__type__": "dogen::identification::entities::physical_id", "value": "<masd.lam.text><masd.cpp.types.namespace_header>" }
: 2020-09-18 11:38:49.874520 [ERROR] [orchestration.transforms.text_model_to_physical_model_transform] Artefact has an empty path. ID:  { "__type__": "dogen::identification::entities::physical_id", "value": "<cpp_ref_impl.profiles.composable><masd.cpp.types.namespace_heade

Once this is fixed we can probably get rid of
=text_model_to_physical_model_transform=. It is just doing the
filtering of paths now.

Notes:

- the problem is that we have all artefacts in the model, including
  non generatable ones. The non-generatable ones do not have paths
  populated. We should probably have a transform that filters
  non-generatable artefacts in the physical model.

*** COMPLETED Add instances of physical meta-model elements           :story:
    CLOSED: [2020-09-21 Mon 18:09]
    :LOGBOOK:
    CLOCK: [2020-09-15 Tue 11:50]--[2020-09-15 Tue 11:59] =>  0:09
    CLOCK: [2020-09-15 Tue 09:52]--[2020-09-15 Tue 11:00] =>  1:25
    CLOCK: [2020-09-14 Mon 14:21]--[2020-09-14 Mon 17:37] =>  3:16
    CLOCK: [2020-09-14 Mon 10:50]--[2020-09-14 Mon 12:11] =>  1:21
    CLOCK: [2020-09-14 Mon 09:56]--[2020-09-14 Mon 10:35] =>  0:39
    CLOCK: [2020-09-14 Mon 09:22]--[2020-09-14 Mon 09:38] =>  0:16
    CLOCK: [2020-09-12 Sat 09:30]--[2020-09-12 Sat 09:55] =>  0:25
    CLOCK: [2020-09-12 Sat 07:40]--[2020-09-12 Sat 08:18] =>  0:38
    CLOCK: [2020-09-11 Fri 17:19]--[2020-09-11 Fri 17:28] =>  0:09
    CLOCK: [2020-09-11 Fri 16:31]--[2020-09-11 Fri 17:18] =>  0:47
    :END:

We made a modeling error with regards to the physical meta-model
elements. We assumed that the user configuration of the meta-model
elements could be stored with the PMM. This is incorrect because the
PMM is created from static data; it is as it was code generated by the
state of the =text.cpp= and =text.csharp= models. However, users can
apply their own configuration to these elements: change backend
directory, facet directory etc. These properties are relative to the
models the users load. Worse, they are possibly different for each
reference - though that particular problem will have to be addressed
separately.

This now causes a big conceptual problem: we assumed that artefacts
were instances of archetypes but yet there is a need to have an
archetype instance where the model specific configuration is
stored. The quick hack, is to create some types that sit in between
the meta-type and the instance type:

- =backend_instance=
- =archetype_instance=
- etc.

This is not very nice but it does solve the problem at hand. We can
then associate these with physical models. Alternatively we could use
a more neutral name like =_properties=, =_configuration=... Actually
we already had some suitable types for enablement, they can be
repurposed for this.

Notes:

- add transform to populate meta-model properties
- update enablement to use the properties, deprecate existing ones.
- merge local enablement transform with the reading of local
  properties; merge global enablement transform with the reading of
  meta-model properties. Add comments on local facet (for
  profiles). Add the missing properties to the global field groups.
- actually we can just rename both transforms instead of creating new
  ones.
- backends and parts also need a file path, just like artefacts.
- the meta-model properties also need a file path, which represents
  the component path. Paths can then be computed "recursively": the
  backend path is the component path plus the backend directory and so
  forth.
- that which we called "meta-model" in the PM is really the "component
  meta-model". In the future as we model more physical aspects we will
  have other kinds of meta-models (product, family, etc.). The "model"
  is really the component model because its an instance of a
  component. The product model will be made up of artefacts and will
  have parts and so forth but it will be different from the component
  model. Or perhaps we will just have other kinds of components inside
  the product model. In which case we need to consider having a notion
  of "component types" and possibly "component groups"
  (e.g. "projects").
- technical spaces and their associated versions should be declared by
  the text models and should be part of the PM. The TS should be
  declared on the "global" text model so that backends can reuse them
  (e.g. we can declare XML with associated extensions and then use it
  where required).

*** POSTPONED Implement meta-name validator correctly                 :story:
    CLOSED: [2020-09-21 Mon 03:02]
    :LOGBOOK:
    CLOCK: [2020-09-11 Fri 10:30]--[2020-09-11 Fri 10:47] =>  0:17
    :END:

The logic in the meta- name validator is completely wrong. We are
checking for facet defaults without taking into account the logical
model element component. Thus, there are fundamental problems with the
meta-model validator that are not easy to fix. We need a facet default
for every logical meta-model element. That is, we need to loop through
all logical meta-model elements and ensure they have a facet default;
but this should only be done for meta-model elements which support a
facet default. This cannot be done until:

- we know which elements require a facet default;
- we have created a logical meta-model.

Merged stories:

*Set expectation for facet default*

At present we are only warning when a facet does not have a facet
default. This is because some facets do not have facet defaults (such
as build, visual studio, etc). However, we know this upfront so on the
facet factory we should set up the expectation. Then we can throw.

*** POSTPONED Add dependencies to artefacts                           :story:
    CLOSED: [2020-09-21 Mon 03:02]
     :LOGBOOK:
     CLOCK: [2020-09-11 Fri 14:45]--[2020-09-11 Fri 15:38] =>  0:53
     CLOCK: [2020-09-11 Fri 14:34]--[2020-09-11 Fri 14:37] =>  0:03
     CLOCK: [2020-09-11 Fri 13:55]--[2020-09-11 Fri 14:33] =>  0:38
     CLOCK: [2020-09-11 Fri 11:20]--[2020-09-11 Fri 11:53] =>  0:33
     CLOCK: [2020-09-11 Fri 10:58]--[2020-09-11 Fri 11:19] =>  0:21
     :END:

 We need to propagate the dependencies between logical model elements
 into the physical model. We still need to distinguish between "types"
 of dependencies:

 - transparent_associations
 - opaque_associations
 - associative_container_keys
 - parents

 Basically, anything which we refer to when we are building the
 dependencies for inclusion needs to be represented. We could create a
 data structure for this purpose such as "dependencies". We should also
 include "namespace" dependencies. These can be obtained by =sort |
 uniq= of all of the namespaces for which there are dependencies. These
 are then used for C#.

 Note however that all dependencies are recorded as logical-physical
 IDs.

 We also need a way to populate the dependencies as a transform. This
 must be done in =m2t= because we need the formatters. We can rely on
 the same approach as =inclusion_dependencies= but instead of creating
 /inclusion dependencies/, we are just creating /dependencies/.

 This will also address the uses of traits, e.g.:

 : const auto ch_arch(traits::archetype_class_header_factory_archetype_qn());

 This is because the traits are used to express dependencies.

 Notes:

 - we did the work to record the relations at the archetype level and
   started updating the archetypes with these in =text.cpp=. However,
   we only did a couple of types.
 - in order to instantiate meta-relations onto the LPS, we need to be
   able to resolve a relation type such as "transparent" into a
   concrete archetype. This means the archetype must have a label of
   that relation type.
 - artefacts must have relations stored as LPS points with both the
   logical name and physical meta-name. At this point we no longer care
   about relation type since it has been resolved.
 - a part is really a "meta-part". We still need to instantiate it with
   the actual project path. The physical model needs to contain this
   instantiation.
 - artefacts need to know their parts.
 - archetypes do not have part populated and their type is incorrect
   (=physical_id=).
- parts should have a root folder. These are specified through
  meta-data. The path is relative to the project path. Different
  models can have different part paths. This means we need to remember
  them when computing a reference to an artefact. Actually this is
  only needed because of split projects. We need to deprecate it as it
  makes things very complicated.
- parts need a directory name. This must be supplied by meta data with
  the part name:

: masd.physical.part.folder_name.implementation=src

  Where implementation is a KVP.

- physical model must be split by backend. Backend must have an
  associated folder name or blank for no folder:

: masd.physical.backend.folder_name.cpp=src

- actually we will have exactly the same problem with facets too. We
  need to create instances of all the meta-model elements.
- due to the fact that you can configure physical meta-elements, we
  have no choice but keep track of the referenced models. This is
  because we could have overwritten them differently in any of the
  referenced models.
- actually we found a much more profound problem, which already exists
  in dogen: if you configure backend/facet/archetypes differently in
  say M0 and M1, and if M1 references M0, the paths will not be
  constructed correctly. That is because we assume that we can
  reconstruct M0 paths using M1's configuration, which is true at
  present merely because we use the same variability settings for all
  models within a product; and on the rare cases we don't, we never
  make use of these models from other models - e.g. test models. To
  fix this properly would require a fairly complex set of changes to
  Dogen: we would need to keep track of the references and their types
  all the way through to code generation. This will not be
  easy. However, what we can do is to start introducing the notion of
  reference models and elements; initially this can be used just to
  check that all references have the same configuration. Eventually,
  as use cases arrive we can extend it to implement this per-model
  configuration properly. This also means that it is not possible to
  refer to a model that has more than one backend for now from a model
  that only has a backend.

*** POSTPONED Add full and relative path processing to PM             :story:
    CLOSED: [2020-09-21 Mon 03:02]
    :LOGBOOK:
    CLOCK: [2020-09-18 Fri 14:28]--[2020-09-18 Fri 15:59] =>  1:31
    CLOCK: [2020-09-18 Fri 11:34]--[2020-09-18 Fri 12:45] =>  1:11
    CLOCK: [2020-09-18 Fri 10:14]--[2020-09-18 Fri 10:45] =>  0:31
    CLOCK: [2020-09-18 Fri 09:31]--[2020-09-18 Fri 09:45] =>  0:14
    CLOCK: [2020-09-15 Tue 17:50]--[2020-09-15 Tue 17:51] =>  0:01
    CLOCK: [2020-09-15 Tue 15:45]--[2020-09-15 Tue 17:49] =>  2:04
    :END:

We need to be able to generate full paths in the PM. This will require
access to the file extensions. For this we will need new decoration
elements. This must be done as part of the logical model to physical
model conversion. While we're at it, we should also generate the
relative paths. Once we have relative paths we should compute the
header guards from them. These could be generalised to "unique
identifiers" or some such general name perhaps. That should be a
separate transform.

Notes:

- we are not yet populating the archetype kind in archetypes so we
  cannot locate the extensions. Also we did not create all of the
  required archetype kinds in the text models. The populating should
  be done via profiles.
- we must first figure out the number of enabled backends. The
  meta-model properties will always contain all backends, but not all
  of them are enabled.

Merged stories:

*Map archetypes to labels*

We need to add support in the PMM for mapping archetypes to labels. We
may need to treat certain labels more specially than others - its not
clear. We need a container with:

- logical model element ID
- archetype ID
- labels

** Deprecated

*** CANCELLED Split =text= from the kernel                            :story:
    CLOSED: [2020-07-17 Fri 17:25]

*Rationale*: we moved in the completely opposite direction. We will
now only have a single kernel so there is no mention of the word
kernel anywhere.

At present we have conflated the MASD kernel with =text=. In reality
these are two very different things, and its just not obvious because
we keep referring to "the" MASD kernel. It would have been really
obvious if we had more than one kernel. The best way to avoid this is:

- give the "MASD kernel" a name, so that we future proof ourselves
  against a second kernel (e.g. EMF/MOF). For example we could call it
  =vanilla=, =plain= or any such bland names. It would be nice to have
  a name that reflects the purpose. The purpose of this kernel is to
  provide a "native" programming language implementation. Perhaps
  =native=? Or we could say its not an MDE kernel.
- move all kernel specific code into the kernel. We should probably
  even consider having a single model with all backends for the
  kernel. Though perhaps this will only make sense when we finish the
  generation refactor. At any rate, in this model we need to create
  the kernel and call all backends.
- leave all transforms which aren't kernel specific in =text=. It will
  also contain all of the T2T infrastructure.

*** CANCELLED Do not hard-code the kernel                             :story:
    CLOSED: [2020-07-17 Fri 17:26]

*Rationale*: we moved in the completely opposite direction. We will
now only have a single kernel so there is no mention of the word
kernel anywhere.

It seems quite obvious a EMF/MOF based kernel will come at some point
in the future. We should not hard-code the kernel. This should be easy
enough:

- define a kernel in text for MASD.
- perform some sort of linkage of the backends against the kernel.

*** CANCELLED Move technical space and generability transforms        :story:
    CLOSED: [2020-07-17 Fri 17:40]

*Rationale*: story bit-rotted.

At present these transforms are in generation, but we don't think
that's the right place. We need some analysis to understand what they
do and why they are not in the logical model.
