#+title: Sprint Backlog 28
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) spike(p) }

* Sprint Goals

- reduce the impedance mismatch between the ultimate destination of
  the code-base and its current state.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2020-11-02 Mon 08:29]
| <75>                                                        |         |       |       |       |
| Headline                                                    | Time    |       |       |     % |
|-------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                | *80:01* |       |       | 100.0 |
|-------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                     | 80:01   |       |       | 100.0 |
| Active                                                      |         | 80:01 |       | 100.0 |
| edit release notes for previous sprint                      |         |       |  3:44 |   4.7 |
| Create a demo and presentation for previous sprint          |         |       |  0:39 |   0.8 |
| Sprint and product backlog grooming                         |         |       |  4:25 |   5.5 |
| Directory names and postfixes are PMM properties            |         |       |  5:27 |   6.8 |
| Move =enabled= and =overwrite= into =enablement_properties= |         |       |  0:19 |   0.4 |
| Analysis on a formatables refactor                          |         |       |  0:31 |   0.6 |
| Tracing of orchestration chains is incorrect                |         |       |  1:00 |   1.2 |
| Presentation for APA                                        |         |       |  5:11 |   6.5 |
| Move C++ locator into physical model                        |         |       | 40:15 |  50.3 |
| Create a video series on the formatables refactor           |         |       |  0:37 |   0.8 |
| Add full and relative path processing to PM                 |         |       |  2:27 |   3.1 |
| Create a factory transform for parts and archetype kinds    |         |       |  5:30 |   6.9 |
| Move stand-alone formatables to physical/logical models     |         |       |  8:27 |  10.6 |
| Issues with emacs                                           |         |       |  1:09 |   1.4 |
| Rename =name= to =codec= name                               |         |       |  0:20 |   0.4 |
#+tblfm: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED edit release notes for previous sprint                  :story:
    CLOSED: [2020-09-24 Thu 20:34]
    :LOGBOOK:
    CLOCK: [2020-09-23 WED 22:01]--[2020-09-23 WED 22:40] =>  0:39
    CLOCK: [2020-09-23 WED 18:41]--[2020-09-23 WED 19:32] =>  0:51
    CLOCK: [2020-09-21 MON 19:31]--[2020-09-21 MON 21:45] =>  2:14
    :END:

Add github release notes for previous sprint.

Release announcements:

- [[https://twitter.com/marcocraveiro/status/1308894541135708161][twitter]]
- [[https://www.linkedin.com/posts/marco-craveiro-31558919_release-dogen-v1027-independ%C3%AAncia-activity-6714660822465048576-fYZV][linkedin]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

#+begin_src markdown
![Navio IndepÃªndencia](https://live.staticflickr.com/6026/5975302810_7d04dffb62_b.jpg)
_Abandoned freighter North of Namibe, Angola. (C) Alfred Weidinger, 2011_

# Introduction

We've been working on Dogen for long enough to know that there is no such thing as an easy sprint; still, after a long sequence of very challenging ones, we were certainly hoping for an easier ride this time round. Alas, not to be. Due to never ending  changes in personal circumstances, both with work and private life, Sprint 27 ended up being an _awfully long sprint_, with a grand total of 70 elapsed days rather than the 30 or 40 customary ones. To make matters worse, not only was it a bit of a fragmented sprint _in time_ - a bit stop-start, if we're honest - but it was also somewhat disjointed in terms of the work as well. One never ending story occupied the bulk of the work, though it did have lots of challenging variations; and the remainder - a smattering of smaller stories - were insufficient to make any significant headway towards the sprint goals. Ah, the joys of working on such a long, open-ended project, hey. And to round it all up nicely, we weren't able to do a _single_ MDE Paper of the Week (PofW); there just weren't enough hours in the day, and these were the first ones to fall by the wayside. They will hopefully resume at the usual cadence next sprint.

The picture may sound gloomy, but do not fear. As we shall see in these release notes, we may have not achieved what we set out to achieve originally, but _much else_ was achieved nevertheless - giving us more than sufficient grounds for our unwavering developer optimism. _Omnia mutantur, nihil interit_, as Ovid [would say](https://en.wikipedia.org/wiki/Omnia_mutantur).

# User visible changes

This section normally covers stories that affect end users, with the video providing a quick demonstration of the new features, and the sections below describing them in more detail. As there were no user facing features, the video discusses the work on internal features instead.

[![Sprint 1.0.27 Demo](https://img.youtube.com/vi/swpKj0rKCpM/0.jpg)](https://youtu.be/swpKj0rKCpM)
_Video 1: Sprint 27 Demo._

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see [the sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_27.org).

## Significant Internal Stories

The story arc of the last few sprints has been centred around _reducing the impedance mismatch_ between Dogen's source code and the conceptual model for the Logical-Physical Space (at times called the LPS). In turn, the LPS stemmed from the work we were doing in cleaning up the text models - in particular the C++ and C# backends; in other words, what we have been trying to achieve for some time now is to remove a _large amount_ of hard-coding and just plain old bad modeling in those two models. For a throw back, see the section _Towards a physical Model_ in the release notes of [Sprint 23](https://github.com/MASD-Project/dogen/releases/tag/v1.0.23). At any rate, every time we try to address what appears to be a fairly straightforward issue, we soon realise it has big implications for the LPS, and then we end up going on yet another wild goose chase to try to find a solution that is in keeping with the conceptual model. Once its all resolved, we then go back to the task at hand and move forwards by a metre or so... until we find the next big issue. It has been this way for a while and sadly this sprint was no different. The main story that consumed just under 51% of the ask was the creation of a new model, the ```identification``` model, which was not directly aligned with the sprint goal. We then worked on a series of smaller stories that were indeed aligned with the goal, but which also required what appears to be a never ending series of mini-spikes. Lets have a quick look at all of these stories.

###  Create an ```identification``` model

The graph of relationships between the different models in Dogen has been a source of concern for a very long time, as [this blog](https://mcraveiro.blogspot.com/2018/01/nerd-food-refactoring-quagmire.html) post attests. We are facing the typical engineering trade-offs: on one hand, we do not want cycles between models because that severely impairs testability and comprehension; on the other hand, we do not want a small number of "modelets", which have no well-defined responsibilities beyond simply existing to break up cycles. One such bone of contention has been the strange nature of the relationship between the ```logical``` and ```physical``` models. To be fair, this tangled relationship is largely a byproduct of the fundamental nature of the LPS, which posits that the logical-physical space is one combined entity. Predictably, these two models have a lot of references to each other:

- the ```logical``` model contains inside of it a model of the ```physical``` entities, which is use to code-generate these entities.
- the ```physical``` model represents regions of the LPS for a given point in the logical axis of the LPS, and therefore needs to reference the ```logical``` model.

Until this sprint the problem had been resolved by duplicating types from both models. This was not an ideal approach but it did address both the problem of cycles as well as avoiding the existence of modelets. As we continued to move types around on our clean ups, we eventually realised that there are only a small number of types needed for these cross-model relationships to be modeled correctly; and as it turns out,  pretty much all of these types seem to be related in one way or another to the "identification" of LPS entities. Now, this is not _completely_ true - a few types are common but not really related to identification; but in the main, the notion holds sufficiently true. Therefore we decided to create a model with the surprising name of ```identification``` and put all the types in there. So far so good. This could have possibly been done with a simple set of renames, which would not take us too long. However, we were not content and decided to address a second long standing problem: avoid the use of "strings" everywhere for identification. If you've watched the Kevlin Henney classic presentation [Seven Ineffective Coding Habits of Many Programmers](https://vimeo.com/97329157), you should be aware that using strings and other such types all over the place is a sign of weak domain modeling. If you haven't, as with all Henney talks, I highly recommend it. At any rate, for the purposes of the present exercise, the Thomas Fagerbekk [summary](https://notes.webutvikling.org/7-ineffective-coding-habits/) suffices:

> *4. We don't abstract enough.*
>
> Use your words, your classes, your abstractions. Don't do Strings, Lists and integers all over the place. [...] Instead, think about how you can communicate the meaning of the objects in the domain. Kevlin pulls up a wordcloud of the words used most frequently in a codebase (about 38-minute mark in the video): The most common words should tell you something about what the codebase is about. [...] A bad example shows List, Integer, String and such basic structures as the most common words. The better example has PrintingDevice, Paper, Picture. This makes the code less readable, because such generic variables can represent so many different things.

Now, if you have even a passing familiarity with Dogen's source code, you could not have helped but notice that we have a very large number of distinct IDs and meta-IDs all represented as strings. We've known for a long while that this is not ideal, not just because of Henney's points above, but also because we often end up using a string of "type" A as if it were a string of "type" B (_e.g._ using a logical meta-model ID when we are searching for a physical ID, say). These errors are painful to get to the bottom of. Wouldn't it be nice if the type system could detect them up front? Given these are all related to identification, we thought, might as well address this issue at the same time. And given Dogen already has built-in support for _primitive types_ - that is, wrappers for trivial types such as string - it did seem that we were ready to finally make this change. Designing the new model was surprisingly quick; where the rubber met the road was on refactoring the code base to make use of the shiny new types.

[![Sprint 1.0.27 Demo](https://img.youtube.com/vi/pMqUzX0PU_I/0.jpg)](https://youtu.be/pMqUzX0PU_I)
_Video 2: Part 1 of 3 of the series of videos on the Identification Refactor._

As you can imagine, and we now know first hand, modifying completely how "identification" works across a large code base is anything but a trivial exercise. There were many, many places where these types were used, sometimes incorrectly, and each of these places had its own subtleties. This change was one long exhausting exercise of modifying a few lines of code, dealing with a number of compilation errors and then dealing with many test failures. Then, rinse, repeat. Part of the not-exactly-fun-process was recorded on a series of videos, available on the playlist [MASD - Dogen Coding: Identification Refactor](https://www.youtube.com/playlist?list=PLwfrwe216gF0wxWcw33JrXI4R2gTN9E8X):

- [MASD - Dogen Coding: Identification Refactor - Part 1](https://www.youtube.com/watch?v=pMqUzX0PU_I)
- [MASD - Dogen Coding: Identification Refactor - Part 2](https://www.youtube.com/watch?v=qMqeG2awLac)
- [MASD - Dogen Coding: Identification Refactor - Part 3](https://www.youtube.com/watch?v=rP8r8FPCFfc)

These videos catch a tiny sliver of the very painful refactor, but they are more than sufficient to give a flavour of the over 42 hours of "joy" we went through. Having said that, in the end we did experience moments of non-sarcastic joy because the code base is now so much better for it. If nothing else, at least now a word cloud will not have ```std::string``` as its most common type - or so one would hope; the hypothesis was not put to the test, probably out of fear. At any rate, we felt this approach was such an improvement that we started to think of all the other types of patterns we have which share similarities with primitives; and how _they_ could also benefit from a similar clean up. However, the reverie quickly ended; at this stage, these are but wishful dreams, a mere gathering of requirements for that one day where our copious free time will allow us to take on a side project of such magnitude. Once backlogged, the dreams quickly faded away and we were back to the task at hand.

![Dogen identification](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_identification_model.png)
_Figure 1: The Dogen Identification model._

### Rename ```injection``` to ```codec```

A small but very helpful change - nay, _instrumental_ change - on our never ending quest to clean up the conceptual model was the renaming of the ```injection``` models to ```codec```. In order to understand its importance, we need to go back in time via our old favourite imagine of the Dogen pipeline:

![Dogen Pipeline](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/orchestration_pipeline.png)
_Figure 2: The Dogen pipeline, circa Sprint 12._

Almost every box in this diagram has changed name, as our understanding of the domain evolved, though their functional roles remained fairly constant. This sprint it was the turn of the "injection" box. This happened because we begun to realise that there are several "forces" at play:

- the terms _injection_ and _extraction_ imply the notion that elements are to be _projected_ with regards to a technical space; when _into_ a technical space, then its an _injection_, and when _out of_ a technical space, its an _extraction_.
- the process of performing the projection can be done by the same set of classes. That is, it's often convenient to declare an _encoder_ and a _decoder_ next to each other because the coding and decoding is functionally very similar.
- the generation of _text_ from model elements is considered an extraction, as is the plain conversion of models of one type to another. However, given there is a very well understood set of terms regarding the transformation of model elements into text - _e.g._, _model-to-text transforms_ - its not insightful to call this an extraction.

![Codec model](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_codec_model.png)
_Figure 3: the Dogen Codec model._

When we took all this factors into account, it became obvious we could not call these models "injection" or "injectors", because that is not all that they do. We debated calling them "inxtractors" given they were both injectors and extractors, but quickly realised we were entering the terminological domain of "modems" (_i.e._, "modulators" and "demodulators") and so we settled on calling them "codecs" because they _encode_ and _decode_ elements from the format of one technical space to the format of another. Once the light-bulb went off, all was light and the rename itself was fairly trivial.

### Assorted conceptual model clean ups

A number of small stories worked on were directly or indirectly related to conceptual model clean ups - that is, the polishing of the code to make it coherent with our present understanding of the conceptual model. These were:

- **Create a logical to physical projector**: In the past we had transforms and adapters which had bits of the projection work. Now that we understand projections much better, it makes sense to have dedicated classes responsible for the projection.
- **Clean up the logical-physical model**: A bit of a grab-bag story related to all sorts of miscellaneous clean up work done on the ```text``` and ```physical``` models. Whilst the story itself wasn't huge (7% of the ask), it delivered _immense_ amounts of clarity. As an example, instead of duplicating properties from both the ```logical``` and ```physical``` models in the text model, we now have modeled it very clearly as a representation of LPS, in a way that is completely transparent (_c.f._, Figure 4). We also finally renamed the ```artefact_set``` to a physical ```region```, which is in keeping with the LPS, as well as the removal of a large number of duplicate types and properties in the physical model.

![Dogen LPS](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_text_model_lps.png)
_Figure 4: The refactored Dogen Text model._

- **Empty path ID error in logs**: yet another clean up story, this entailed understanding why we were producing so many weird and wonderful warnings in the log files related to empty paths. Turns out we had missed out some of the logic regarding the filtering out of reference models prior to generation - in particular the Platform Definition Models or PDMs - which resulted in us trying to look for paths where none exist. With this clean up we have a proper transform to filter out all artefacts and even whole regions of physical space which are not supposed to exist at the point at which we write files to the file-system (```remove_regions_transform```).
- **Add instances of physical meta-model elements**: This story was a bit of a mind-bender in terms of the LPS. Thus far we have relied on the usual meta-model taxonomy as prescribed by the [OMG](https://www.omg.org/ocup-2/documents/Meta-ModelingAndtheMOF.pdf). However, with this sprint we started to break with the nice clear cut hierarchical model because we noticed that there is in fact a layer in between the physical meta-model (PMM) and the physical model (PM). This layer comes to be because the PMM is configurable via the variability elements that Dogen supports. This variability means that the _actual_ PMM a given model has could be completely different from another model. Now, of course, we only allow a very restricted form of configuration at this level, but nonetheless its large enough that it requires a large amount of supporting data structures. As we did not quite know what to call these data structures, we decided to go for the suitably incorrect postfix of ```_properties```. Henney would not have been proud, clearly.

![Dogen identification](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_physical_meta_model_properties.png)
_Figure 5: Dogen meta-model properties._

- **Add dependencies to artefacts**: work was started but not completed on adding dependencies to artefacts and archetypes, but we then ran into all of the clean ups mentioned above. It shall continue next sprint, where we will hopefully describe this story properly.
- **Add full and relative path processing to PM**: similarly to the previous story, this is a long standing story which is part of the clean up arc. Each sprint we tend to do a bit of progress on it, but sadly, it also generates a large amount of spikes, meaning we never tend to get very far. When we do complete it, we shall provide a complete description of this endeavour.
- **Other minor stories**: Stories comprising 0.1% to 0.3% of the ask were also completed, but were very minor. For example, we toyed with removing split project support, but in the end concluded this did not provide the bang we expected and, in the end, rolled back the changes.

## Resourcing

As we've already mentioned, resourcing this sprint was completely dominated by one big ol' massive story: updating the entire code base to use the new ```identification``` model. Weighing in at  51%, it amply demonstrates our inability to break up large stories into small, digestible pieces. In reality, we probably should have had an epic encompassing around 3 or 4 stories, one for each chunk of the pipeline - _e.g._ injection, logical, physical, _etc_. As it was, we bundled all the work into one massive story, which is not ideal for the purposes of analysis. For example, the logical work was the largest of them all, but that is not visible through the lens of the data. OK, so the breaking down of stories was not exactly amazing, but on the plus side we did spend 82% of the total ask on "real engineering", as opposed to the other 18% allocated to "housekeeping". These were scattered over release notes (8.8%), backlog management (3%), demos (just under 1%) and addressing issues with nightlies, at a costly 5.3%. Finally, what was _truly_ not ideal was our utilisation rate of 20% - the lowest since records begun in Sprint 20. Sadly, this particular metric is only a function of our desires to a small degree, and much more a function of the environment we operate in, so there is only so much we can do to optimise it. Overall, and given the constraints, one would have to conclude this was a pretty efficient sprint, though we do hope the utilisation rate can start to climb to number levels in the near future.

![Sprint 27 stories](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_27_pie_chart.jpg)
_Figure 6_: Cost of stories for sprint 27.

## Roadmap

Our oracular project plan suffered the traditional updates - that is, move everything forward by a sprint and pray next sprint delivers some action on the sprint goals. To be perfectly honest, there is a very clear pattern asserting itself, which is to say the clean up associated with the LPS is extremely difficult and utterly impossible to estimate. So the always dubious project plan has become of even less value. But since it also works as a roadmap, we'll keep nudging it along - just don't read too much (or anything, really) into those dates. We never did.

![Project Plan](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_27_project_plan.png)

![Resource Allocation Graph](https://github.com/MASD-Project/dogen/raw/master/doc/agile/v1/sprint_27_resource_allocation_graph.png)

# Binaries

You can download binaries from either [Bintray](https://bintray.com/masd-project/main/dogen/1.0.27) or GitHub, as per Table 1. All binaries are 64-bit. For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available in [zip](https://github.com/MASD-Project/dogen/archive/v1.0.27.zip) or [tar.gz](https://github.com/MASD-Project/dogen/archive/v1.0.27.tar.gz) format.

| Operative System | Format | BinTray | GitHub |
|----------|-------|-----|--------|
|Linux Debian/Ubuntu | Deb | [dogen_1.0.27_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.27/dogen_1.0.27_amd64-applications.deb) | [dogen_1.0.27_amd64-applications.deb](https://github.com/MASD-Project/dogen/releases/download/v1.0.27/dogen_1.0.27_amd64-applications.deb) |
|OSX | DMG | [DOGEN-1.0.27-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.27/DOGEN-1.0.27-Darwin-x86_64.dmg) | [DOGEN-1.0.27-Darwin-x86_64.dmg](https://github.com/MASD-Project/dogen/releases/download/v1.0.27/DOGEN-1.0.27-Darwin-x86_64.dmg)|
|Windows | MSI | [DOGEN-1.0.27-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.27-Windows-AMD64.msi) | [DOGEN-1.0.27-Windows-AMD64.msi](https://github.com/MASD-Project/dogen/releases/download/v1.0.27/DOGEN-1.0.27-Windows-AMD64.msi) |

_Table 1: Binary packages for Dogen._

**Note:** The OSX and Linux binaries are not stripped at present and so are larger than they should be. We have [an outstanding story](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#linux-and-osx-binaries-are-not-stripped) to address this issue, but sadly CMake does not make this a trivial undertaking.

# Next Sprint

The goals for the next sprint are:

- to finish PMM generation;
- to implement locator and dependencies via PMM.

That's all for this release. Happy Modeling!
#+end_src

*** COMPLETED Create a demo and presentation for previous sprint      :story:
    CLOSED: [2020-09-23 Wed 23:20]
    :LOGBOOK:
    CLOCK: [2020-09-23 Wed 22:41]--[2020-09-23 Wed 23:20] =>  0:39
    :END:

Time spent creating the demo and presentation.

**** Presentation

***** Dogen v1.0.27, "IndependÃªncia"

    Marco Craveiro
    Domain Driven Development
    Released on 23rd September 2020

***** Create an identification model
***** Rename injection to codec
***** The logical-physical space
*** COMPLETED Sprint and product backlog grooming                     :story:
    CLOSED: [2020-11-02 Mon 08:29]
    :LOGBOOK:
    CLOCK: [2020-11-01 Sun 16:34]--[2020-11-01 Sun 16:36] =>  0:02
    CLOCK: [2020-10-23 Fri 09:41]--[2020-10-23 Fri 10:31] =>  0:50
    CLOCK: [2020-10-09 Fri 09:51]--[2020-10-09 Fri 10:15] =>  0:24
    CLOCK: [2020-10-01 Thu 10:17]--[2020-10-01 Thu 10:23] =>  0:06
    CLOCK: [2020-10-01 Thu 09:00]--[2020-10-01 Thu 09:45] =>  0:45
    CLOCK: [2020-09-26 Sat 07:25]--[2020-09-26 Sat 07:38] =>  0:13
    CLOCK: [2020-09-25 Fri 14:41]--[2020-09-25 Fri 15:35] =>  0:54
    CLOCK: [2020-09-25 Fri 09:35]--[2020-09-25 Fri 09:45] =>  0:10
    CLOCK: [2020-09-25 Fri 08:30]--[2020-09-25 Fri 08:42] =>  0:12
    CLOCK: [2020-09-24 Thu 19:45]--[2020-09-24 Thu 20:34] =>  0:49
    :END:

Updates to sprint and product backlog.

*** COMPLETED Refactor archetype model                                :story:
    CLOSED: [2020-09-24 Thu 20:34]

*Rationale*: already implemented.

- rename model to =physical=.
- create meta-model namespace.
- add missing meta-types from generation (parts, etc).
- remove all types from generation which are not yet used.
- add concept of artefact types (e.g. c++ public header, c++ private
  header, etc). Associate extensions with artefact types (and perhaps
  other properties?).

*** COMPLETED Consider using a primitive for qualified representations :story:
    CLOSED: [2020-09-24 Thu 20:34]

*Rationale*: already implemented.

At present we have a number of maps with =string= as their key. We
can't tell what that string means. It would be better to have a
primitive to represent the different kinds of qualified id's we
have. This would also stop us from making mistakes such as using dot
notation in a container where we expected colon notation, or just
using any random string.

*** COMPLETED Replace =operator<= for sorting with lambdas            :story:
    CLOSED: [2020-09-24 Thu 20:34]

*Rationale*: we've done this in most places.

We have used =operator<= a lot for sorting lists. We don't really need
this since c++ 11, we can just create a simple inline lambda.

*** COMPLETED Directory names and postfixes are PMM properties        :story:
    CLOSED: [2020-09-25 Fri 18:02]
    :LOGBOOK:
    CLOCK: [2020-09-25 Fri 16:19]--[2020-09-25 Fri 18:01] =>  1:42
    CLOCK: [2020-09-25 Fri 15:56]--[2020-09-25 Fri 16:18] =>  0:22
    CLOCK: [2020-09-25 Fri 13:31]--[2020-09-25 Fri 14:40] =>  1:09
    CLOCK: [2020-09-25 Fri 09:45]--[2020-09-25 Fri 11:59] =>  2:14
    :END:

Originally we implemented a number of properties as variability with
suitable defaults:

- backend directory name, facet directory name;
- facet postfix, archetype postfix;

These were first implemented with lots of hard-coding; eventually we
added default value overrides, allowing a single template expansion
to be used across a domain, and then supplying the needed overrides,
e.g.:

: #DOGEN masd.variability.binding_point=global
: #DOGEN masd.variability.default_value_override.cpp.types="types"
: #DOGEN masd.variability.default_value_override.cpp.hash="hash"
: #DOGEN masd.variability.default_value_override.cpp.tests="generated_tests"
: #DOGEN masd.variability.default_value_override.cpp.io="io"
: #DOGEN masd.variability.default_value_override.cpp.lexical_cast="lexical_cast"
: #DOGEN masd.variability.default_value_override.cpp.templates="templates"
: #DOGEN masd.variability.default_value_override.cpp.odb="odb"
: #DOGEN masd.variability.default_value_override.cpp.test_data="test_data"
: #DOGEN masd.variability.default_value_override.cpp.serialization="serialization"
: #DOGEN masd.variability.default_value_override.csharp.types="Types"
: #DOGEN masd.variability.default_value_override.csharp.io="Dumpers"
: #DOGEN masd.variability.default_value_override.csharp.test_data="SequenceGenerators"

However, it is now becoming clear that there are two sides to this
problem. First, we need to define the default value for the field
which is really a property of the PMM. Secondly, we need to allow
users to override this value, which is really a property of the
MMP. The MMP value should default to the PMM value if no overrides are
supplied. We need to move these properties to the correct
places. These would then be used in their final form by the paths
transform to compose a path. For now, we must also be backwards
compatible. We should also make the meta-data "distinct" enough so we
do not get confused. For example, for PMM:

: masd.physical.backend_directory_name=abc

and for the MMP:

: masd.cpp.directory_name=def

Tasks:

- rename the =directory= attributes in the MMP to =directory_name=.
- add =directory= and =postfix= to the PMM and to the LM
  representation of the PMM.
- add the new attributes to diagrams and read them from meta-data.
- generate the new attributes.
- update MMP generation with new attributes.
- add a part factory.

Notes:

- we tried to model all containment based on parts. That is, all
  archetypes had to belong to a facet and all facets had to belong to
  a part. This is a seductive approach because there are no special
  cases. However, the downside of it is that we need to create two
  "special" parts in every backend:

  - the component part;
  - the backend part.

  The component part and backend part may resolve into the same
  physical location, as a function of variability. Seems a bit painful
  to have to define these two "special" parts on every
  backend. Alternatively, we could state that archetypes could be
  contained by any physical meta-element (apart from archetypes
  themselves) and then remove these "special" parts. This would then
  mean that we'd have to query the PMM to look for the right type of
  meta-element that contains us - or we could create a simple index of
  PMM ID to directory + postfix as part of the PMM construction. In
  addition, once we have products, components and projects in the
  physical model, we will also have the potential to have facets and
  archetypes contained in any of these. Again, it makes no sense to
  have to create "parts" purely for symmetry when they add no
  value. We need to generalise the notion of containment.
- having said that, there are cases where we may want to have a facet
  just as a grouping mechanism. For example, the visual studio facet
  does not contribute to the path but is useful as a grouping of
  archetypes and also as a variability knob. The part does not have
  these use cases.

*** COMPLETED Move =enabled= and =overwrite= into =enablement_properties= :story:
    CLOSED: [2020-09-26 Sat 13:31]
    :LOGBOOK:
    CLOCK: [2020-09-26 Sat 13:12]--[2020-09-26 Sat 13:31] =>  0:19
    :END:

Since we already have a class for it, it seems to make more sense than
to have these attributes in the archetype itself.

*** COMPLETED Analysis on a formatables refactor                      :story:
    CLOSED: [2020-10-01 Thu 10:16]
    :LOGBOOK:
    CLOCK: [2020-10-01 Thu 09:59]--[2020-10-01 Thu 10:16] =>  0:17
    CLOCK: [2020-10-01 Thu 09:45]--[2020-10-01 Thu 09:59] =>  0:14
    :END:

We are finding it difficult to map between the meta-model refactor and
the existing code in the text models. The main reason is because there
is such a large delta or impedance mismatch between the two. Ideally
we need the existing code to be closer to the meta-model refactor
representation so that we do not have to hold so much state in the
brain when refactoring. This also means we can reduce an open ended
problem to a series of well-defined software engineering tasks.

*** COMPLETED Tracing of orchestration chains is incorrect            :story:
    CLOSED: [2020-10-02 Fri 12:16]
    :LOGBOOK:
    CLOCK: [2020-10-02 Fri 11:16]--[2020-10-02 Fri 12:16] =>  1:00
    :END:

Whilst looking for tracing information, we noticed that the layout of
directories does not correspond to the chains in source code. Fix the
transforms as required.

*** COMPLETED Presentation for APA                                    :story:
    CLOSED: [2020-10-10 Sat 12:33]
    :LOGBOOK:
    CLOCK: [2020-10-09 Fri 18:40]--[2020-10-09 Fri 21:10] =>  2:30
    CLOCK: [2020-10-09 Fri 14:38]--[2020-10-09 Fri 14:57] =>  0:19
    CLOCK: [2020-10-09 Fri 14:15]--[2020-10-09 Fri 14:37] =>  0:22
    CLOCK: [2020-10-09 Fri 10:16]--[2020-10-09 Fri 12:16] =>  2:00
    :END:

We need to do a 30 min presentation on Dogen and research in general.

- Youtube: https://www.youtube.com/watch?v=yKfAhkYtQYM&ab_channel=Confer%C3%AAnciaAPA
- Flyer:

#+begin_quote
Como Ã© fazer pesquisa em ciÃªncia da computaÃ§Ã£o?

Para o dia 9  de Outubro na Sexta-feira , horÃ¡rio do evento 18:50.

Marco Craveiro Angolano fazendo doutorado (PHD) em ciÃªncia da
computaÃ§Ã£o na Universidade de Hertfordshire na Inglaterra Ã© tambÃ©m
programador sÃ©nior em mercados financeiros na City of London, lidando
hÃ¡ mais de 15 anos com produtos financeiros complexos (derivativos em
FX). A sua carreira estende-se a mais de 20 anos de programaÃ§Ã£o
profissional.

Ele recebeu o Bacharelato de GestÃ£o pela Universidade do Algarve,
Portugal (1998) e o Mestrado em CiÃªncias Computacionais pela
Universidade de Hertfordshire, Inglaterra (2002). Desde 2014
encontra-se no programa de doutoramento da mesma universidade, em
ciÃªncia da computaÃ§Ã£o, onde estuda geraÃ§Ã£o automÃ¡tica de cÃ³digo-fonte
a partir de modelos (MDE - Model Driven Engineering).

Na comunidade open source, ele Ã© conhecido como o autor de Dogen
(https://github.com/MASD-Project/dogen), um projecto aberto que visa
trazer as tecnologias de MDE Ã  comunidade geral de engenheiros de
software.

VocÃª pode participar da live no dia 9 de Outubro na Sexta-feira pelo
nosso canal no youtube :
https://youtube.com/channel/UC8WJYRikef3TWiqbtwQooSw...  Ou pela nossa
pÃ¡gina no facebook :
https://facebook.com/Confer%C3%AAncia-APA-105017044613068
#+end_quote

*** COMPLETED Move C++ locator into physical model                    :story:
    CLOSED: [2020-10-30 Fri 18:44]
    :LOGBOOK:
    CLOCK: [2020-10-30 Fri 16:33]--[2020-10-30 Fri 18:44] =>  2:11
    CLOCK: [2020-10-30 Fri 14:27]--[2020-10-30 Fri 16:13] =>  2:06
    CLOCK: [2020-10-30 Fri 10:25]--[2020-10-30 Fri 12:10] =>  1:45
    CLOCK: [2020-10-25 Sun 20:33]--[2020-10-25 Sun 22:01] =>  1:28
    CLOCK: [2020-10-25 Sun 19:01]--[2020-10-25 Sun 19:40] =>  0:39
    CLOCK: [2020-10-25 Sun 18:09]--[2020-10-25 Sun 18:42] =>  0:33
    CLOCK: [2020-10-25 Sun 14:25]--[2020-10-25 Sun 17:50] =>  3:25
    CLOCK: [2020-10-25 Sun 12:27]--[2020-10-25 Sun 12:56] =>  0:29
    CLOCK: [2020-10-25 Sun 11:00]--[2020-10-25 Sun 12:26] =>  1:26
    CLOCK: [2020-10-24 Sat 16:41]--[2020-10-24 Sat 17:23] =>  0:42
    CLOCK: [2020-10-24 Sat 13:50]--[2020-10-24 Sat 15:39] =>  1:49
    CLOCK: [2020-10-23 Fri 13:42]--[2020-10-23 Fri 15:05] =>  1:23
    CLOCK: [2020-10-23 Fri 10:45]--[2020-10-23 Fri 12:24] =>  1:49
    CLOCK: [2020-10-18 Sun 16:32]--[2020-10-18 Sun 18:38] =>  2:06
    CLOCK: [2020-10-18 Sun 14:00]--[2020-10-18 Sun 16:31] =>  2:31
    CLOCK: [2020-10-17 Sat 17:01]--[2020-10-17 Sat 18:20] =>  1:19
    CLOCK: [2020-10-17 Sat 12:00]--[2020-10-17 Sat 13:30] =>  1:38
    CLOCK: [2020-10-16 Fri 09:01]--[2020-10-16 Fri 13:00] =>  3:59
    CLOCK: [2020-10-03 Sat 16:11]--[2020-10-03 Sat 17:52] =>  1:41
    CLOCK: [2020-10-02 Fri 16:01]--[2020-10-02 Fri 18:07] =>  2:06
    CLOCK: [2020-10-02 Fri 12:16]--[2020-10-02 Fri 13:05] =>  0:49
    CLOCK: [2020-10-02 Fri 09:52]--[2020-10-02 Fri 11:15] =>  1:23
    CLOCK: [2020-10-02 Fri 09:01]--[2020-10-02 Fri 09:51] =>  0:50
    CLOCK: [2020-10-01 Thu 15:22]--[2020-10-01 Thu 16:25] =>  1:03
    CLOCK: [2020-10-01 Thu 10:52]--[2020-10-01 Thu 12:35] =>  1:43
    :END:

- move locator configuration to physical model, reusing meta-model
  properties as required.
- merge extraction properties with =project_path_properties=.
- create a locator helper in physical model.
- create a legacy full path transform in physical model. Have a set of
  simple functions that return the archetype kind given an
  archetype. Then use the kind to determine the locator function to
  call.
- region configuration is null after text transform execution for
  cmakelists.
- JQ query to obtain file paths:

: jq .models[0].physical.regions_by_logical_id[0][1].data.artefacts_by_archetype[][1].data.data.file_path

- locator is now creating a dense representation of paths rather than
  a sparse one. We probably need to understand why that is.
- namespaces are being incorrectly generated. This is because the
  logical name is not correctly annotated with the =is_container=
  flag.
- locator assumes a single backend. In reality it could be either c++
  or c# so we need multiple project directories, depending on the
  current backend.
- archetype needs to have a technical space. It is then propagated to
  artefact during projection. Backend has a major technical space and
  minor TSs. These are the sum of all archetypes in the backend which
  are not of the same TS as the major TS.
- cannot delete locator because odb expander still relies on it. Same
  with =build_files_expander=.
- c# still has inclusion deps properties in interface.

*** COMPLETED Create a video series on the formatables refactor       :story:
    CLOSED: [2020-10-31 Sat 11:15]
    :LOGBOOK:
    CLOCK: [2020-10-23 Fri 12:25]--[2020-10-23 Fri 12:34] =>  0:09
    CLOCK: [2020-10-23 Fri 10:32]--[2020-10-23 Fri 10:45] =>  0:13
    CLOCK: [2020-10-01 Thu 10:24]--[2020-10-01 Thu 10:39] =>  0:15
    :END:

Story to clock time spent on video work which would not be required
from a coding perspective (video uploads, etc).

*** POSTPONED Add full and relative path processing to PM             :story:
    CLOSED: [2020-10-31 Sat 11:15]
    :LOGBOOK:
    CLOCK: [2020-09-26 Sat 15:43]--[2020-09-26 Sat 16:05] =>  0:22
    CLOCK: [2020-09-26 Sat 15:23]--[2020-09-26 Sat 15:31] =>  0:08
    CLOCK: [2020-09-26 Sat 14:35]--[2020-09-26 Sat 15:13] =>  0:48
    CLOCK: [2020-09-26 Sat 13:32]--[2020-09-26 Sat 14:00] =>  0:28
    CLOCK: [2020-09-26 Sat 12:55]--[2020-09-26 Sat 13:12] =>  0:17
    CLOCK: [2020-09-25 Fri 09:00]--[2020-09-25 Fri 09:34] =>  0:34
    :END:

We need to be able to generate full paths in the PM. This will require
access to the file extensions. For this we will need new decoration
elements. This must be done as part of the logical model to physical
model conversion. While we're at it, we should also generate the
relative paths. Once we have relative paths we should compute the
header guards from them. These could be generalised to "unique
identifiers" or some such general name perhaps. That should be a
separate transform.

Notes:

- we are not yet populating the archetype kind in archetypes so we
  cannot locate the extensions. Also we did not create all of the
  required archetype kinds in the text models. The populating should
  be done via profiles.
- we must first figure out the number of enabled backends. The
  meta-model properties will always contain all backends, but not all
  of them are enabled.
- we need to populate the part directories. For this we need to know
  what parts are available for each backend (PMM), and then ensure the
  part properties have been created. We also need a directory for the
  part in variability. It is not clear we have support for this in the
  template instantiation domains - we probably only have backend,
  facet, archetype.
- guiding principle: there should be a direct mapping between the two
  hierarchical spaces: the definition meta-model of the physical space
  and its instances in the file-system.

Merged stories:

*Map archetypes to labels*

We need to add support in the PMM for mapping archetypes to labels. We
may need to treat certain labels more specially than others - its not
clear. We need a container with:

- logical model element ID
- archetype ID
- labels

*** POSTPONED Create a factory transform for parts and archetype kinds :story:
    CLOSED: [2020-10-31 Sat 11:15]
    :LOGBOOK:
    CLOCK: [2020-10-02 Fri 16:22]--[2020-10-02 Fri 18:07] =>  1:45
    CLOCK: [2020-09-27 Sun 14:28]--[2020-09-27 Sun 16:56] =>  2:28
    CLOCK: [2020-09-27 Sun 13:50]--[2020-09-27 Sun 13:59] =>  0:09
    CLOCK: [2020-09-27 Sun 13:26]--[2020-09-27 Sun 13:40] =>  0:14
    CLOCK: [2020-09-27 Sun 12:31]--[2020-09-27 Sun 13:25] =>  0:54
    :END:

- integrate their generation into PMM chains.

Notes:

- it does not make a lot of sense to have an archetype kind
  transform. That is, as with TSs, archetype kinds only provide
  attributes (e.g. data) about physical space, but they won't be
  expressed as actual physical elements. Parts however are connected
  to the transforms; they will in the future be used as part of the
  transform chain.
- do we instantiate template domains over parts? We need to do so in
  order to support directory overrides. The problem is that in order
  for the part to become part of the topology of physical space, we
  now need to make sure we can still convert archetypes into facets. A
  lot of the code is going to break once we add path.

*** COMPLETED Move stand-alone formatables to physical/logical models :story:
    CLOSED: [2020-11-01 Sun 16:34]
    :LOGBOOK:
    CLOCK: [2020-11-01 Sun 16:33]--[2020-11-01 Sun 16:34] =>  0:01
    CLOCK: [2020-11-01 Sun 16:24]--[2020-11-01 Sun 16:32] =>  0:08
    CLOCK: [2020-11-01 Sun 16:08]--[2020-11-01 Sun 16:23] =>  0:15
    CLOCK: [2020-11-01 Sun 13:36]--[2020-11-01 Sun 16:07] =>  2:31
    CLOCK: [2020-11-01 Sun 11:30]--[2020-11-01 Sun 12:45] =>  1:15
    CLOCK: [2020-10-31 Sat 13:30]--[2020-10-31 Sat 16:31] =>  3:01
    CLOCK: [2020-10-31 Sat 11:01]--[2020-10-31 Sat 12:17] =>  1:16
    :END:

Move the assorted types which are not related to helpers to their
final location:

- =facet_properties=
- =project_items=
- ODB related types.
- streaming properties
- =cpp_standards=
- =test_data_properties=
- =aspect_properties=: c++ and c#. Features are still located in TS
  specific namespaces.

*** COMPLETED Issues with emacs                                       :story:
    CLOSED: [2020-11-02 Mon 08:29]
    :LOGBOOK:
    CLOCK: [2020-10-02 Fri 14:51]--[2020-10-02 Fri 16:00] =>  1:09
    :END:

Time spent troubleshooting emacs issues.

- problems loading very long lines in log file. Tried using [[https://www.emacswiki.org/emacs/SoLong][so-long]]
  and fundamental, but still could not solve the problem.

*** POSTPONED Rename =name= to =codec= name                           :story:
    CLOSED: [2020-11-02 Mon 08:29]
    :LOGBOOK:
    CLOCK: [2020-09-24 Thu 20:38]--[2020-09-24 Thu 20:58] =>  0:20
    :END:

- add codec ID to name.

Notes:

- variability is also using the name class.

** Deprecated

*** CANCELLED Add primitives to the archetypes model                  :story:
    CLOSED: [2020-10-01 Thu 09:38]

*Rationale*: superseded by refactors.

Instead of using strings we should use primitives for:

- facets
- formatters
- backends
- simple and qualified names.
- etc.

*** CANCELLED Read variability papers                                 :story:
    CLOSED: [2020-10-01 Thu 09:38]

*Rationale*: We now have the MDE papers section.

Time spent reading the literature on variability. We should do a
"journal club" video for each paper, like Numenta does.

*** CANCELLED Improve errors in dia objects                           :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

At present when adding blanks (spaces) in a dia object we get the
following error:

: 2014-11-09 23:05:58.936785 [ERROR] [dia_to_sml.identifier_parser] Failed to parse string: std::unordered_map<std::string, facet_settings>
: 2014-11-09 23:05:58.938301 [FATAL] [knitter] Error: /home/marco/Development/DomainDrivenConsulting/dogen/projects/dia_to_sml/src/types/identifier_parser.cpp(198): Throw in function sml::nested_qname dogen::dia_to_sml::identifier_parser::parse_qname(const std::string &)
: Dynamic exception type: N5boost16exception_detail10clone_implIN5dogen10dia_to_sml13parsing_errorEEE
: std::exception::what: Failed to parse string: std::unordered_map<std::string, facet_settings>
: [P12tag_workflow] = Code generation failure.

There is no clue as to which object caused the error. Add a class name
and dia object ID to the exception. We should add a test for this as well.

*** CANCELLED Handling of unsupported dia objects                     :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

#+begin_quote
*Story*: As a dogen user, I want to make use of Dia shapes that are
not supported by dogen so that my diagrams can be as expressive as
required.
#+end_quote

At present when we try to use a dia object that dogen knows nothing
about we get an error; for example using a standard line results in:

: 2014-09-10 08:09:43.480906 [ERROR] [dia_to_sml.processor] Invalid value for object type: Standard - Line
: 2014-09-10 08:09:43.487060 [FATAL] [knitter] Error: /home/marco/Development/DomainDrivenConsulting/dogen/projects/dia_to_sml/src/types/processor.cpp(124): Throw in function dogen::dia_to_sml::object_types dogen::dia_to_sml::processor::parse_object_type(const std::string &) const
: Dynamic exception type: N5boost16exception_detail10clone_implIN5dogen10dia_to_sml16processing_errorEEE
: std::exception::what: Invalid value for object type: Standard - Line

However, it may make more sense to just ignore these. To do so we
could relax the code in processor (object_types):

:    BOOST_LOG_SEV(lg, error) << invalid_object_type << ot;
:    BOOST_THROW_EXCEPTION(processing_error(invalid_object_type + ot));

We should also consider having a =strict= command line option to
enable/disable this behaviour.
*** CANCELLED Detect invalid child nodes in dia diagram               :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

#+begin_quote
*Story*: As a dogen user, I want to know when there are invalid child
nodes in diagram so that I can fix them.
#+end_quote

When copying a set of classes from a diagram, where these classes
where contained in a package, dia seems to copy across the =childnode=
id. This is a problem because when pasted in a new diagram, if those
classes are not in a package there is now the potential for total
mismatching - for instance, they could be children of an
association. Dogen should validate that children belong to UML
elements which can have children, and if not issue good error
messages - perhaps even talking about the possible cause for the
error.
*** CANCELLED Add tests for duplicate identifiers in Dia              :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

Detect if a diagram defines the same class or package multiple
times. Should throw an exception. We should also detect multiple
properties with the same name.

*** CANCELLED Split library into JSON and dia                         :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

We should supply the PDMs models as both. This is a good test for PDMs
to make sure that all functionality is available on both. Actually
this story may be superseded by the work on the core library.
*** CANCELLED Add conversion (encoding) support for Dia               :story:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

Approach:

- create an XML schema from the DTD and use the XSD tool to generate
  serialisation code. See how many differences we get by doing trivial
  document updates (in particular, updating colours of elements). If
  this works, we can replace the existing dia model with the XSD
  generated code.

Use cases:

- update the colours of the diagram according to the dogen palette.
- it would be nice if one could take a JSON model and generate a dia
  diagram for it. This is non-trivial because it would require
  computing all of the sizes and locations for all UML elements.
- we could then allow users to submit models in say JSON, eCore etc
  and produce a PNG of the model so they could visualise it. We could
  also try to consume dia as a shared library instead of running the
  full program - e.g. create a service that takes in a dia diagram and
  returns the PNG.
- automatic diagram updates (see story below).

Related stories:

- [[*Add support for XSD tool][Add support for XSD tool]]
- [[*Improvements to dia model][Improvements to dia model]]
- [[*Investigate support for automatic diagram updates][Investigate support for automatic diagram updates]]
*** CANCELLED Improve the integration of dogen with dia                :epic:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

It would be great if the model generation in dia was slightly more
interactive:

- dia could have a button to run/configure an external tool, where the
  setup for dogen would be kept.
- pushing an execute button would code generate.
- pushing a validate button would validate the current diagram, taking
  into account declared references. references to types that are not
  resolved could make the class or function go red.

The idea is to do the least intrusive changes in dia that would
provide us with this support. In order to access dogen, instead of
running the executable and parsing the command line output, it would
make more sense to create a C interface that supports these specific
use cases (and nothing else).

Dia already has a plugin interface, so we should bind to that rather
than require dia to compile against dogen.
*** CANCELLED Dia limitations that impact dogen usage                  :epic:
    CLOSED: [2020-10-01 Thu 10:22]

*Rationale*: Dia is no longer in the product vision for Dogen.

Collection of limitations we found in Dia that are annoying when using
it in anger with dogen:

- moving types in and out of packages does not work very well.
- comments for packages are missing.
- cannot wrap attributes; this is a problem when we have attributes
  with very long types.
- changing a diagram in the filesystem does not trigger any alerts:
  its very easy to loose changes because one updates the files from
  git but the diagram was opened in dia, and did not refresh.
- crossing lines (associations, etc) should "curve" up so that one can
  still follow the relationship.
- dia should have a UUID associated with each element so we can track
  those and know of renames.
- dia should have an XMI export.
- dia should allow selecting groups of objects based on some criteria:
  stereotypes matching regex, class names, classes in namespace, etc.
- attributes should have stereotypes.

It seems like dia is also using GitHub these days:

- https://github.com/GNOME/dia
- https://gitlab.gnome.org/GNOME/dia

If we have a go at creating any patches for the above ideas we should
submit a PR. This repo cannot be used to submit PRs.

Investigation on Python: it seems its fairly trivial to extend dia
using python:

- [[https://wiki.gnome.org/Apps/Dia/Python][Dia Python Plugin]]: includes lots of scripts.
- [[http://pastebin.com/pPkL3PxQ][Manipulating UML in Dia's Python Console]]
- [[https://github.com/GNOME/dia/tree/master/plug-ins/python][Lots of examples of python scripts]]

Another interesting thing to do is to add validation support at the
Dia level. First we need validation support to be implemented. Once
that is done, we could create a python plugin that calls dogen on the
diagram, retrieves the errors (marked against Dia objects) and then
updates the diagram with errors/warnings. For example, we could mark
the classes in red/yellow. If dia had tooltips we could also display
the errors as tooltips.
*** CANCELLED Allow placing types in the global module in Dia         :story:
    CLOSED: [2020-10-01 Thu 10:23]

*Rationale*: Dia is no longer in the product vision for Dogen.

#+begin_quote
*Story*: As a dogen user, I want to code-generate certain types in the
global namespace so that I don't have to manually code them.
#+end_quote

At present all types in a Dia diagram are placed in the model
module. However, there may be cases where one may wish to place types
in the global module. At present this is only done in the hardware
model, and that is supplied via JSON. However, we may need to do this
from Dia. Find example use cases for this first.

In terms of implementation, a trait could be added to dia
=dia.use_global_module=. This would force the type to be contained
directly in the global module rather than the model module. If the
trait is used in the model or a package, all types in the containing
scope will inherit it.
