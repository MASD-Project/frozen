#+title: Sprint Backlog 15
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- finish mopping up the extraction model.
- Start work on moving profiles to metamodel.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2019-04-23 Tue 07:53]
| <75>                                                              |         |       |       |       |
| Headline                                                          | Time    |       |       |     % |
|-------------------------------------------------------------------+---------+-------+-------+-------|
| *Total time*                                                      | *80:22* |       |       | 100.0 |
|-------------------------------------------------------------------+---------+-------+-------+-------|
| Stories                                                           | 80:22   |       |       | 100.0 |
| Active                                                            |         | 80:22 |       | 100.0 |
| Edit release notes for previous sprint                            |         |       |  4:21 |   5.4 |
| Sprint and product backlog grooming                               |         |       |  7:18 |   9.1 |
| Create a video demo for the previous sprint's features            |         |       |  1:35 |   2.0 |
| Fix issues with emacs                                             |         |       |  2:01 |   2.5 |
| Fix issues with nightly build                                     |         |       |  0:08 |   0.2 |
| Add diffing support to string asserter                            |         |       |  1:00 |   1.2 |
| C# generation is borked                                           |         |       |  4:12 |   5.2 |
| Reactivate the boilerplate tests                                  |         |       |  5:58 |   7.4 |
| Update to clang8                                                  |         |       |  0:11 |   0.2 |
| Do not hard-code static library generation                        |         |       |  1:01 |   1.3 |
| Generated models should support both static and dynamic libraries |         |       |  0:09 |   0.2 |
| Fix cmake emacs variable for tab width                            |         |       |  0:38 |   0.8 |
| Re-read variability modeling papers                               |         |       |  2:59 |   3.7 |
| Nursing nightlies                                                 |         |       |  1:50 |   2.3 |
| Fix snags with emacs                                              |         |       |  6:00 |   7.5 |
| Redesign annotations model                                        |         |       | 31:59 |  39.8 |
| Profiles as meta-model elements                                   |         |       |  9:02 |  11.2 |
#+TBLFM: $5='(org-clock-time%-mod @3$2 $2..$4);%.1f
#+end:

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2019-04-08 Mon 16:36]
    :LOGBOOK:
    CLOCK: [2019-04-09 Tue 08:02]--[2019-04-09 Tue 08:26] =>  0:24
    CLOCK: [2019-04-08 Mon 18:22]--[2019-04-08 Mon 18:35] =>  0:13
    CLOCK: [2019-04-08 Mon 16:23]--[2019-04-08 Mon 16:33] =>  0:10
    CLOCK: [2019-04-08 Mon 15:02]--[2019-04-08 Mon 16:22] =>  1:20
    CLOCK: [2019-04-08 Mon 13:51]--[2019-04-08 Mon 15:01] =>  1:18
    CLOCK: [2019-04-08 Mon 11:09]--[2019-04-08 Mon 12:13] =>  1:04
    :END:

Add github release notes for previous sprint.

Title: Dogen v1.0.14, "Deserto"

#+begin_src markdown
![Deserto do Namibe](http://4.bp.blogspot.com/-LiNTT6RDryM/VOyICPXnVDI/AAAAAAAAFMs/41QA7apihtQ/s1600/IMG_0834%2Bcopy.jpg)
_Dunes in the Namib Desert, Namibe Province, Angola. (C) 2012 [Jo√£o P. Baptista](http://xamalundo.blogspot.com/2015/02/deserto-do-namibe-angola.html)_.

# Introduction

This sprint was yet again an extremely busy affair. However, for a change, time was mainly focused on the task at hand rather than on distractions such as testing. As a result, we have finally delivered the first of a number of core meta-model changes that aim to regularise our approach to the modeling of elements across the solution space. In other words, it may appear like a small release to the untrained eye, but it feels like a giant leap to the development team.

As you will not fail to notice, the release notes have been tweaked yet again in response to feedback: we now start with the user visible changes, and proceed to discuss internal matters afterwards.

# User visible changes

This section covers stories that affect end users. The sprint demo provides a quick demonstration on the user visible changes, whereas the below sections provide more detail.

[![Sprint 1.0.14 Demo](https://img.youtube.com/vi/zNnzGF6VSTw/0.jpg)](https://youtu.be/zNnzGF6VSTw)

## Decorative elements are now in meta-model

Before delving into the details of the feature, it is worth providing some context. Up to now we have separated configuration from modeling proper. As a result, there are a number of little configuration files, each declared and consumed by user models via its own ad-hoc mechanisms. As [MDE theory](https://en.wikipedia.org/wiki/Model-driven_engineering) became better understood, and as the MASD approach cemented itself, it became clear that these configuration units are indeed worthy of modeling just like any other higher level concept present in a product. This release sees the start of a **long** process that, when completed, will finally move the architecture to its desired state. Sadly, it will require quite a large engineering effort to get there.

As for the feature itself: this release places the management of modelines, licences, location strings (known in Dogen speak as "generation markers") and other decorative elements into the meta-model. This means that instead of an assortment set of data files of varying formats, these are now contained in a "regular" model and can be extended and/or overridden by users as required.

The ```masd``` model defines a number of these which can readily be used:

![MASD Model](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/masd_model_screenshot.png)

In order to make use of these new model elements, you need to first define a reference to ```masd``` (assuming a Dia model):

```
#DOGEN masd.injection.reference=masd
```

And then you can set up the meta-data as required:

```
#DOGEN masd.generation.decoration.enabled=true
#DOGEN masd.generation.decoration.licence_name=masd.gpl_v3
#DOGEN masd.generation.decoration.modeline_group_name=masd.emacs
#DOGEN masd.generation.decoration.copyright_notice=Copyright (C) 2012-2015 Marco Craveiro <marco.craveiro@gmail.com>
```

As you can see, from a usage perspective these are very similar to the previous approach (modulus the field name changes). However, the advantage is that you can now define you own modeling elements (licences, etc), on either the target model or a model shared by a number of target models - as in the ```masd``` model example above.

Please note that these keys were previously available with different names, so this is a breaking change. The fields have been updated from:

```
masd.decoration.enabled
masd.decoration.licence_name
masd.decoration.copyright_notice
masd.decoration.modeline_group_name
```

to

```
masd.generation.decoration.enabled
masd.generation.decoration.licence_name
masd.generation.decoration.copyright_notice
masd.generation.decoration.modeline_group_name
```

## Language rename

Sadly, this is not the only breaking change in this release. The "language rename" is explained in more detail below on the internal section, but from a end user perspective, it is a breaking change. The following fields have been renamed:

```
#DOGEN masd.injection.input_language=cpp
#DOGEN masd.extraction.output_language=cpp
```

Have been renamed. They must be updated to:

```
#DOGEN masd.injection.input_technical_space=cpp
#DOGEN masd.extraction.output_technical_space=cpp
```

# Development Matters

In this section we cover topics that are mainly of interest if you follow Dogen development, such as details on internal stories that consumed significant resources, important events, etc. As usual, for all the gory details of the work carried out this sprint, see the [sprint log](https://github.com/MASD-Project/dogen/blob/master/doc/agile/v1/sprint_backlog_14.org).

## Milestones

With this release, we have made the 8888th commit to Dogen! I guess a celebration blog post is in order, though it's always difficult to justify taking more time away from coding.

![Commit milestone](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/blog/images/dogen_8888_commit.png)

## Significant Internal Stories

Several very important clean-ups were achieved this sprint:

- **Move from "languages" to "technical spaces"**. This is somewhat difficult to explain without getting into the details (which my thesis will explain properly), but with this release we have started a move from mere programming languages towards [technical spaces](https://userpages.uni-koblenz.de/~laemmel/gttse/2005/pdfs/41430036.pdf) as [MDE](https://en.wikipedia.org/wiki/Model-driven_engineering) understands them. This will in time provide a much cleaner conceptual model.
- **Simpler qualified name representation**. In the past we had relied on maps, and associated qualified names directly with programming languages. With this release we now have a cleaner representation for these.
- **Clean-up of the extraction model**. This story is related to the user visible feature above, but from an internal perspective. We have now moved all code in the extraction model which didn't belong there. There is only one outstanding task to finish the clean-up of this model, but it already looks in a much better shape.

## Resourcing

Most of the sprint's time was spent towards moving extraction model entities into the coding metamodel (~45%). Around 18% of the total time was dedicated to process, with the bulk of it taken by backlog grooming (9.5%), project planning (just below 3%) and the editing of release notes and the creation of the demo for the previous sprint (~2% and ~4% respectively). We also had a couple of spikes.

The first spike had a cost of around 4%, and is related to integrating Report-CI; this is the latest project by [Klemens Morgenstern](http://klemens-morgenstern.github.io), the amazing coder behind [Boost.Process](https://www.boost.org/doc/libs/master/doc/html/process.html) and other core libraries. As always, we are happy to help fellow travellers on their road to product building. In addition, integration was fairly trivial (mainly reviewing Klemens' PRs) and we've already started to see some of the benefits as we start to make use of [the reports](https://github.com/MASD-Project/dogen/runs/95903756) the tool produces.

The second spike cost circa 3.3% and was related to fixes to the emacs setup. Improvements in the development environment are always welcome, and [tend to have a very positive impact](http://mcraveiro.blogspot.com/2015/05/nerd-food-prelude-of-things-to-come.html), though in ways that are somewhat difficult to measure.

The complete story breakdown is as follows:

![Story Pie Chart](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/agile/v1/sprint_14_pie_chart.jpg)

## Planning

Sprint 14 introduces a [project plan](https://github.com/MASD-Project/dogen/blob/master/doc/agile/project_plan.org). Given Dogen is on the critical path of my PhD, it seemed like a good idea to create some kind of road map that gives an inkling as to when I can start to think of completing it. It has the grandiose name of "project plan", but alas, it is nothing like a project plan for a real industry project. In truth, I've never been a great believer in the estimation process; the objective here is just to have some kind of projection, regardless of how crude, of what is left to do in order to release the [fabled v2 release](https://github.com/MASD-Project/dogen/blob/master/doc/agile/product_backlog.org#required-for-v2).

At the end of sprint 14, the plan looks like this:

![Project Plan](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/agile/v1/sprint_14_project_plan.png)

![Resource Allocation Graph](https://raw.githubusercontent.com/MASD-Project/dogen/master/doc/agile/v1/sprint_14_resource_allocation_graph.png)

We will keep it updated with each release.

# Next Sprint

As per the project plan above, we are expecting to continue the meta-modeling work in the next sprint by tackling a very thorny issue: moving profiles into the meta-model. This is a feature of pivotal importance to make Dogen usable because it will finally mean users can define profiles such as ```serializable``` and the like on their own diagrams, associate them with user defined configuration, and ultimately apply them to element types. Profiles are key to unlocking Dogen functionality, so we are extremely excited to finally get to work on this feature.

# Binaries

You can download binaries from [Bintray](https://bintray.com/masd-project/main/dogen) for OSX, Linux and Windows (all 64-bit):

- [dogen_1.0.14_amd64-applications.deb](https://dl.bintray.com/masd-project/main/1.0.14/dogen_1.0.14_amd64-applications.deb)
- [dogen-1.0.14-Darwin-x86_64.dmg](https://dl.bintray.com/masd-project/main/1.0.14/dogen-1.0.14-Darwin-x86_64.dmg)
- [dogen-1.0.14-Windows-AMD64.msi](https://dl.bintray.com/masd-project/main/DOGEN-1.0.14-Windows-AMD64.msi)

For all other architectures and/or operative systems, you will need to build Dogen from source. Source downloads are available below.

Happy Modeling!
#+end_src

- [[https://twitter.com/MarcoCraveiro/status/1115302519067090947][Tweet]]
- [[https://www.linkedin.com/feed/update/urn:li:activity:6521068658024804352][LinkedIn]]
- [[https://gitter.im/MASD-Project/Lobby][Gitter]]

*** COMPLETED Sprint and product backlog grooming                     :story:
    CLOSED: [2019-04-22 Mon 09:28]
    :LOGBOOK:
    CLOCK: [2019-04-22 Mon 08:55]--[2019-04-22 Mon 09:07] =>  0:12
    CLOCK: [2019-04-18 Thu 18:11]--[2019-04-18 Thu 18:25] =>  0:14
    CLOCK: [2019-04-18 Thu 12:02]--[2019-04-18 Thu 12:35] =>  0:33
    CLOCK: [2019-04-18 Thu 09:21]--[2019-04-18 Thu 09:36] =>  0:15
    CLOCK: [2019-04-17 Wed 07:22]--[2019-04-17 Wed 07:43] =>  0:21
    CLOCK: [2019-04-17 Wed 07:13]--[2019-04-17 Wed 07:21] =>  0:08
    CLOCK: [2019-04-16 Tue 15:01]--[2019-04-16 Tue 16:12] =>  1:11
    CLOCK: [2019-04-14 Sun 14:04]--[2019-04-14 Sun 14:45] =>  0:41
    CLOCK: [2019-04-14 Sun 13:21]--[2019-04-14 Sun 13:25] =>  0:04
    CLOCK: [2019-04-14 Sun 12:52]--[2019-04-14 Sun 13:20] =>  0:28
    CLOCK: [2019-04-14 Sun 07:08]--[2019-04-14 Sun 08:07] =>  0:59
    CLOCK: [2019-04-12 Fri 07:40]--[2019-04-12 Fri 07:58] =>  0:18
    CLOCK: [2019-04-10 Wed 16:50]--[2019-04-10 Wed 17:02] =>  0:12
    CLOCK: [2019-04-10 Wed 11:55]--[2019-04-10 Wed 12:05] =>  0:10
    CLOCK: [2019-04-09 Tue 10:13]--[2019-04-09 Tue 10:29] =>  0:16
    CLOCK: [2019-04-09 Tue 09:55]--[2019-04-09 Tue 10:12] =>  0:17
    CLOCK: [2019-04-09 Tue 09:35]--[2019-04-09 Tue 09:45] =>  0:10
    CLOCK: [2019-04-09 Tue 08:55]--[2019-04-09 Tue 09:20] =>  0:25
    CLOCK: [2019-04-08 Mon 18:14]--[2019-04-08 Mon 18:21] =>  0:07
    CLOCK: [2019-04-08 Mon 15:02]--[2019-04-08 Mon 15:09] =>  0:07
    CLOCK: [2019-04-08 Mon 10:58]--[2019-04-08 Mon 11:08] =>  0:10
    :END:

Updates to sprint and product backlog.

*** COMPLETED Create a video demo for the previous sprint's features  :story:
    CLOSED: [2019-04-08 Mon 18:04]
    :LOGBOOK:
    CLOCK: [2019-04-08 Mon 18:04]--[2019-04-08 Mon 18:13] =>  0:09
    CLOCK: [2019-04-08 Mon 17:59]--[2019-04-08 Mon 18:03] =>  0:04
    CLOCK: [2019-04-08 Mon 16:36]--[2019-04-08 Mon 17:58] =>  1:22
    :END:

Demo the delete empty directories feature.

*** COMPLETED Fix issues with emacs                                   :story:
    CLOSED: [2019-04-08 Mon 10:57]
    :LOGBOOK:
    CLOCK: [2019-04-08 Mon 10:37]--[2019-04-08 Mon 10:57] =>  0:20
    CLOCK: [2019-04-08 Mon 08:55]--[2019-04-08 Mon 10:36] =>  1:41
    :END:

Fix any pending issues with emacs left over from previous sprint.

- modeline not quite displaying correctly.
- setup treemacs in dot emacs
- symlinks are confusing treemacs, delete them.
- get eyebrowse mode to work properly so we can make use of desktops.

*** COMPLETED Fix issues with nightly build                           :story:
    CLOSED: [2019-04-09 Tue 08:35]
    :LOGBOOK:
    CLOCK: [2019-04-09 Tue 08:27]--[2019-04-09 Tue 08:35] =>  0:08
    :END:

Seems like the nightly did not run due to changes in the path. Fix these.

*** COMPLETED Read =generate_preamble= from dynamic object            :story:
    CLOSED: [2019-04-09 Tue 10:20]

*Rationale*: done as part of the work in previous sprint.

We need to generate the field definitions and update the general
settings factory.

*** COMPLETED Improve formatters code generation marker               :story:
    CLOSED: [2019-04-09 Tue 10:21]

*Rationale*: done as part of the work in previous sprint.

Things the marker can/should have:

- model level version;
- the dogen version too. However, this will make all our tests break
  every time there is a new commit so perhaps we need to have this
  switched off by default.

*** COMPLETED Add diffing support to string asserter                  :story:
    CLOSED: [2019-04-09 Tue 16:18]
    :LOGBOOK:
    CLOCK: [2019-04-09 Tue 16:19]--[2019-04-09 Tue 16:56] =>  0:37
    CLOCK: [2019-04-09 Tue 15:55]--[2019-04-09 Tue 16:18] =>  0:23
    :END:

It would be nice to have a unified diff coming out of the asserter. At
present we are dumping the actual and expected and then having to
manually diff these.

Tasks:

- move differ to utility.
- add trivial diff method that does not care about paths.
- use differ in asserter.

*** COMPLETED C# generation is borked                                 :story:
    CLOSED: [2019-04-10 Wed 11:54]
    :LOGBOOK:
    CLOCK: [2019-04-10 Wed 09:32]--[2019-04-10 Wed 11:54] =>  2:22
    CLOCK: [2019-04-10 Wed 06:21]--[2019-04-10 Wed 08:11] =>  1:50
    :END:

We do not seem to be detecting diffs in C#. The problem is that we are
not using the element artefact properties to determine the overwrite
flag. We neeed to copy the logic from c++ assistant.

*** COMPLETED Reactivate the boilerplate tests                        :story:
    CLOSED: [2019-04-10 Wed 16:49]
    :LOGBOOK:
    CLOCK: [2019-04-10 Wed 16:14]--[2019-04-10 Wed 16:49] =>  0:35
    CLOCK: [2019-04-10 Wed 14:42]--[2019-04-10 Wed 16:03] =>  1:21
    CLOCK: [2019-04-10 Wed 14:11]--[2019-04-10 Wed 14:41] =>  0:30
    CLOCK: [2019-04-09 Tue 19:00]--[2019-04-09 Tue 19:45] =>  0:45
    CLOCK: [2019-04-09 Tue 17:48]--[2019-04-09 Tue 18:59] =>  1:11
    CLOCK: [2019-04-09 Tue 16:57]--[2019-04-09 Tue 17:47] =>  0:50
    CLOCK: [2019-04-09 Tue 11:42]--[2019-04-09 Tue 12:06] =>  0:24
    CLOCK: [2019-04-09 Tue 11:06]--[2019-04-09 Tue 11:25] =>  0:19
    CLOCK: [2019-04-09 Tue 10:30]--[2019-04-09 Tue 10:33] =>  0:03
    :END:

Split these out into decoration tests and boilerplate tests.

*** COMPLETED Update to clang8                                        :story:
    CLOSED: [2019-04-11 Thu 10:16]
    :LOGBOOK:
    CLOCK: [2019-04-11 Thu 09:39]--[2019-04-11 Thu 09:50] =>  0:11
    :END:

We seem to have a lot of spurious errors with clangd-7. Try with
clangd-8. However, in order to do this we need to get the code to
compile with clang 8.

*** COMPLETED Properties vs configuration                             :story:
    CLOSED: [2019-04-17 Wed 07:38]

*Rationale*: this investigation is complete.

Originally we had defined properties to mean things which are computed
and configuration to mean things which are read directly from the
meta-data and not touched afterwards. This made life easier in
determining how each class was used. However, this was not strictly
enforced and now there are many cases where properties are used when
configuration should have been (and probably vice-versa). In addition,
we have cases where we should have used configuration but used nothing
(type parameters springs to mind). We need to do a clean up of the
meta-model.

Actually we now have a clear answer to this question, based on feature
modeling and variability analysis: we have a feature model, composed
of features; this is what we have so far called "properties". The
instances of these features are called configurations. We just need a
strategy for mapping features into UML models, for which there are
several in the literature.

*** COMPLETED Do not hard-code static library generation              :story:
    CLOSED: [2019-04-19 Fri 16:09]
    :LOGBOOK:
    CLOCK: [2019-04-19 Fri 15:08]--[2019-04-19 Fri 16:09] =>  1:01
    :END:

It seems we need to support building shared libraries in order to use
cling at present. However, we've hard-coded dogen to use static
libraries. Remove the hard-coding.

*** COMPLETED Generated models should support both static and dynamic libraries :story:
    CLOSED: [2019-04-19 Fri 16:21]
    :LOGBOOK:
    CLOCK: [2019-04-19 Fri 16:15]--[2019-04-19 Fri 16:21] =>  0:06
    CLOCK: [2019-04-19 Fri 16:11]--[2019-04-19 Fri 16:14] =>  0:03
    :END:

At present we have hard-coded the CMake files to generate static
libraries on all generated . We should allow the user to choose at
build time. See other story:

- Allow user to choose whether to build shared or static libraries

*** COMPLETED Fix cmake emacs variable for tab width                  :story:
    CLOSED: [2019-04-19 Fri 17:00]
    :LOGBOOK:
    CLOCK: [2019-04-19 Fri 16:22]--[2019-04-19 Fri 17:00] =>  0:38
    :END:

We need to replace uses of =tab-width= in cmake files with
=cmake-tab-width=, as explained here:

[[http://stackoverflow.com/questions/25751408/controlling-the-indent-offset-for-cmake-in-emacs][Controlling the indent/offset for CMake in emacs]]

We need to do this for both code generated and manually generated
files.

*** COMPLETED Re-read variability modeling papers                     :story:
    CLOSED: [2019-04-20 Sat 17:56]
    :LOGBOOK:
    CLOCK: [2019-04-20 Sat 17:57]--[2019-04-20 Sat 18:02] =>  0:05
    CLOCK: [2019-04-20 Sat 17:37]--[2019-04-20 Sat 17:56] =>  0:19
    CLOCK: [2019-04-20 Sat 15:02]--[2019-04-20 Sat 17:37] =>  2:35
    :END:

Given that we are refactoring the variability model, we should take
this opportunity to re-read the papers on variability modeling to make
sure we didn't miss anything obvious.

Notes:

- our approach to variability is anchored on pushing it to the
  archetype space.
- the modeling space allows structural variability but it is not
  directly linked to variability modeling. Modeling space is composed
  of two models, the product and the component model. Both are
  projected into archetype space.
- we make use of positive and negative variability as we map our M2T
  transforms into the archetype space. However, these are not
  important for end users and can be thought of as implementation details.
- we have chosen to use a very simplified feature model, with
  restricted ability to capture features and their relationships. Our
  target is to avoid the complexity that most feature models have, as
  well as the complexity in solving and satisfiability.
- end users can only configure; they cannot define new features. We
  make a clear separation between the "inherent features" - those
  define by the MASD feature model and the "end user features" - those
  defined by the end user in creating a solution for their problem
  domain. We do not support end user feature modeling.
- core assets are the SRAPs. These are defined by MASD and codified
  into archetype space.
- end user is expected to add configuration and product specific
  assets (hand-crafted code).
- variability management is done by defining configurations and
  profiles. Profiles support the SPLE use case because they can be
  stored in models that can be shared by products. A product familiy
  is thus defined by sharing variability profiles and the associated
  vocabulary it defines.
- our approach may be minimalistic but still shares the advantages
  defined by Groher for variability management. We just don't fully
  implement the vision.
- we do not require any weaving between the feature model and the
  model because of how we have mixed the two models.
- we see aspect orientation as an implementation detail. It is
  relegated to M2T and not made visible to the end user.
- Models describe product lines (via the profiles). Variants are
  defined at the model level. All products are product variants of
  MASD. Variants are therefore not a very useful term. Families are
  defined by sharing configurations. These are useful to end users.
- Transforms create libraries and running applications, though we are
  not expected to code generate a product without handcrafting.
- DSLs/problem space meta-models are out of the scope of MASD.
- MASD uses feature based variability.
- Model assumes traditional creative construction via a normal
  metamodel such as the UML. IT does not preclude a larger
  pre-processing pipeline with user defined metamodels that combine
  with MASD for code generation. This is outside the scope of MASD
  though.
- "The model is an expression of configurative variability."
- other approaches make the variability itself a responsibility of the
  end user. We only allow configuration.
- separation between system features (MASD) and user defined
  features. User defined features may be implemented using MASD
  features.
- the process of mixing features and classes is called "the mixing
  process". Conversely the un-mixing process extracts the variability
  model from a mixed model. This is also called "Amalgamated
  Approach.": "Annotate a Base Model by Means of Extensions."
- a selection is a configuration which has been selected to be used on
  a modeling element. Is this a better name than a "profile"? at least
  it is not confusing with UML profiles, and it appears to be used by
  variability domain experts.
- SRAP is a predefined set of core assets with an associated feature
  model.
- we need to find a name for our mixing technique.
- features can be activated or deactivated. All of our feature
  activation occurs at generation time.
- archetype space makes use of positive and negative variability and
  aspects.
- our approach to variability is close ended in the sense that the
  variability model is scoped only to the archetype
  space. Superimposed over the archetype space? or derived from it?
- most variability models are very flexible, but if applied to large
  industrial systems they would result in extremely complex models and
  would be very difficult to maintain. Our variability model is
  designed to keep complexity low even if it is very inflexible. It is
  a trade-off we want to make.
- we have copied some of the ideas from the TDM: global features,
  typing, modularity.
- as with TDM we also have created a methodology to anchor the
  variability approach. It would not make sense without it.
- feature relations: requires, conflicts. Sets of features a feature
  is related to. This would be really helpful when determining valid
  configurations.
- it is the end user's responsibility to trace requirements (problem
  space) to configurations. We do not have any support for this.
- Goher: "we express as many artefacts as possible using models. This
  allows for processing these artefacts using model transforms." Our
  approach is anchored on this, in the limit.
- model weaving: add to core. Model tailoring: optional parts are
  removed.

*** COMPLETED Nursing nightlies                                       :story:
    CLOSED: [2019-04-22 Mon 09:28]
    :LOGBOOK:
    CLOCK: [2019-04-20 Sat 07:44]--[2019-04-20 Sat 07:49] =>  0:05
    CLOCK: [2019-04-20 Sat 07:16]--[2019-04-20 Sat 07:43] =>  0:27
    CLOCK: [2019-04-20 Sat 06:46]--[2019-04-20 Sat 07:15] =>  0:29
    CLOCK: [2019-04-18 Thu 06:15]--[2019-04-18 Thu 06:24] =>  0:09
    CLOCK: [2019-04-17 Wed 07:01]--[2019-04-17 Wed 07:19] =>  0:18
    CLOCK: [2019-04-16 Tue 06:50]--[2019-04-16 Tue 07:12] =>  0:22
    :END:

Time taken fixing assorted issues with nightly builds.

- changing compilers to clang8 caused nightlies to break.
- because we use the ctest script from git to run the nightly, we are
  always out of sync with the script: the git update is done within
  the script. This means that when we do changes to the script we need
  to manually update the directory or wait another day for it to sync
  up.

*** COMPLETED Fix snags with emacs                                    :story:
    CLOSED: [2019-04-22 Mon 09:28]
    :LOGBOOK:
    CLOCK: [2019-04-18 Thu 06:25]--[2019-04-18 Thu 06:35] =>  0:10
    CLOCK: [2019-04-14 Sun 14:46]--[2019-04-14 Sun 15:09] =>  0:23
    CLOCK: [2019-04-11 Thu 09:16]--[2019-04-11 Thu 09:20] =>  0:04
    CLOCK: [2019-04-11 Thu 08:02]--[2019-04-11 Thu 09:15] =>  1:13
    CLOCK: [2019-04-10 Wed 17:50]--[2019-04-10 Wed 20:05] =>  2:15
    CLOCK: [2019-04-10 Wed 13:27]--[2019-04-10 Wed 14:11] =>  0:44
    CLOCK: [2019-04-10 Wed 13:01]--[2019-04-10 Wed 13:26] =>  0:25
    CLOCK: [2019-04-09 Tue 11:26]--[2019-04-09 Tue 11:42] =>  0:16
    CLOCK: [2019-04-09 Tue 10:34]--[2019-04-09 Tue 11:04] =>  0:30
    :END:

Keep track of time spent faffing around with emacs (troubleshooting,
installing new modes, etc).

Notes:

- it seems CQuery is no [[https://github.com/cquery-project/cquery/issues/867][longer actively maintained]]. We snapshotted it
  a while ago, but we seem to be using a lot of CPU for no reason
  quite a few times, grinding emacs to a halt. Investigate moving to
  clangd.
- experiments with minimap.

*** COMPLETED Redesign annotations model                              :story:
    CLOSED: [2019-04-23 Tue 07:53]
    :LOGBOOK:
    CLOCK: [2019-04-21 Sun 12:18]--[2019-04-21 Sun 12:31] =>  0:13
    CLOCK: [2019-04-21 Sun 12:06]--[2019-04-21 Sun 12:17] =>  0:11
    CLOCK: [2019-04-21 Sun 12:00]--[2019-04-21 Sun 12:05] =>  0:05
    CLOCK: [2019-04-21 Sun 11:25]--[2019-04-21 Sun 11:59] =>  0:34
    CLOCK: [2019-04-19 Fri 20:33]--[2019-04-19 Fri 20:49] =>  0:16
    CLOCK: [2019-04-19 Fri 18:01]--[2019-04-19 Fri 20:32] =>  2:31
    CLOCK: [2019-04-19 Fri 17:01]--[2019-04-19 Fri 17:15] =>  0:40
    CLOCK: [2019-04-18 Thu 18:39]--[2019-04-18 Thu 18:50] =>  0:11
    CLOCK: [2019-04-18 Thu 18:25]--[2019-04-18 Thu 18:39] =>  0:14
    CLOCK: [2019-04-18 Thu 17:31]--[2019-04-18 Thu 18:10] =>  0:52
    CLOCK: [2019-04-18 Thu 14:02]--[2019-04-18 Thu 15:59] =>  1:57
    CLOCK: [2019-04-18 Thu 09:45]--[2019-04-18 Thu 12:01] =>  2:41
    CLOCK: [2019-04-18 Thu 07:37]--[2019-04-18 Thu 07:45] =>  0:08
    CLOCK: [2019-04-18 Thu 07:24]--[2019-04-18 Thu 07:36] =>  0:12
    CLOCK: [2019-04-18 Thu 06:35]--[2019-04-18 Thu 07:23] =>  0:48
    CLOCK: [2019-04-17 Wed 17:54]--[2019-04-17 Wed 17:59] =>  0:05
    CLOCK: [2019-04-17 Wed 17:50]--[2019-04-17 Wed 17:53] =>  0:03
    CLOCK: [2019-04-17 Wed 17:16]--[2019-04-17 Wed 17:49] =>  0:33
    CLOCK: [2019-04-17 Wed 14:02]--[2019-04-17 Wed 17:15] =>  3:13
    CLOCK: [2019-04-17 Wed 09:22]--[2019-04-17 Wed 11:06] =>  1:44
    CLOCK: [2019-04-16 Tue 07:12]--[2019-04-16 Tue 08:24] =>  1:12
    CLOCK: [2019-04-15 Mon 14:05]--[2019-04-15 Mon 17:41] =>  3:36
    CLOCK: [2019-04-13 Sat 14:38]--[2019-04-13 Sat 17:41] =>  3:03
    CLOCK: [2019-04-13 Sat 12:55]--[2019-04-13 Sat 14:37] =>  1:42
    CLOCK: [2019-04-13 Sat 10:52]--[2019-04-13 Sat 12:30] =>  1:38
    CLOCK: [2019-04-13 Sat 06:03]--[2019-04-13 Sat 06:33] =>  0:30
    CLOCK: [2019-04-12 Fri 17:41]--[2019-04-12 Fri 17:49] =>  0:08
    CLOCK: [2019-04-12 Fri 17:27]--[2019-04-12 Fri 17:40] =>  0:13
    CLOCK: [2019-04-12 Fri 17:06]--[2019-04-12 Fri 17:26] =>  0:20
    CLOCK: [2019-04-12 Fri 14:21]--[2019-04-12 Fri 15:30] =>  1:09
    CLOCK: [2019-04-12 Fri 14:06]--[2019-04-12 Fri 14:20] =>  0:14
    CLOCK: [2019-04-12 Fri 11:15]--[2019-04-12 Fri 11:29] =>  0:14
    CLOCK: [2019-04-12 Fri 09:00]--[2019-04-12 Fri 10:53] =>  1:53
    :END:

*Rationale*: the redesign was completed with the modeling work. We now
have to implement it, which is a different story.

There has been a great deal of confusion regarding how annotations
have been used. We have the following use cases/names:

- annotation: store of configuration. The store is "dynamic", in the
  sense that the values are changeable at run time.
- coding configuration: "adapter" to allow the meta-model to carry
  "configuration templates" - that which we call profiles.
- profiles: templates for configuration. These are stored as
  templates, and subsequently instantiated into annotations.

Note that the annotations are of two "types":

- stand alone annotations: these are the product of configuration
  template instantiation. These are sourced from JSON files (at
  present) or model elements (the coding configuration). These are
  unbound configurations.
- element owned annotations: these are sourced from regular model
  elements. These are bound configurations.

The objective is to apply stand alone configurations to element owned
configurations via the mappings in stereotypes. Given all of this, the
existing names are woefully inadequate, and its becoming more
confusing as we make increased use of this functionality. We need to
rename all of these model types to more sensible names and document
their responsibilities else this code will become (even more)
unmaintainable.

Notes:

- the annotations model should really be called configuration because
  it deals with all of the primitives for configuration. Or better
  yet: variability2. Note that this model is concerned with structural
  variability. We will leave non-structural variability (configuration
  files) for another time. we need to split this out in the backlog.
- the annotation class is really a typed configuration
  store. We use the name store to avoid confusion with the established
  repository idiom, e.g.: =configuration::store=.
- profiles are configuration templates.
- the annotation expander is a =store_builder=. It creates a store
  from a set of configuration templates.
- the coding configuration is actually a configuration template.
- a type is actually a (typed) feature. What we are calling type
  groups are feature groups. Traits are feature names. In the future,
  we will code-generate the insertion of features into the variablity
  model feature store, and the conversion of dynamic configurations
  into concrete configurations (c++ types). By declaring a model
  element as a feature group, each attribute becomes a feature. The
  code generator reads the features and injects them into the
  variability model. It also creates the C++ type. It also creates
  code to convert from and to the dynamic configuration
  representation. It also contains the feature and feature group
  documentation, accessible at run-time.
- maybe we should call feature group "feature set" instead to avoid
  confusion with xor/or-groups in feature diagrams.
- what we are calling scope types is perhaps called "binding times".
- there is a simple algebra of configurations such as a + b = c
  (confiugrations are additive), etc. The algebra dictates the order
  of operations.
- tagged values could be configuration points. This is not to be
  confused with variation points.
- unlike Clauss, Possompes et al., our approach to variability is to
  only expose it at the code generator level. Users can create
  configurations but on the happy path they are not expected to create
  new features. In addition, if they do create new features, these can
  only be used to configure the behaviour of the code generator
  (e.g. their own templates). It is structural variability, but not
  for user models. Concretely, this means you cannot use features to
  determine the shape of modeling elements (have a sort algorithm
  interface that has variation points to determine the actual
  algorithm to use). This is explicitly a non-goal of our approach. In
  effect, we are focused only on structural variability inside the
  archetype space, not the coding space.
- we need to use the names bound and unbound configurations. The
  expander takes a set of unbound configurations, finds those that
  bind to stereotypes (candidate bindings) and then performs the
  addition operation between the element bound configuration and the
  stereotype bound configuration. Maybe we should call it "binder"?
- merger should be called "adder": it performs the "addition"
  operation on two configurations. However, our addition is
  non-commutative and non-associative. Maybe its not addition? Its not
  clear by looking at wikipedia so lets stick to merger.
- tracing is dependent on variability at present. This is only because
  we are dumping the inputs. We need a different way of doing this.
- we could create a top-level variability chain - the "profile binding
  chain" - that receives as input a configuration model set and a
  feature model. Configuration model sets are made up of configuration
  models. These are made up of a set of profile templates, the global
  configuration and the local configuration. The last two are
  pointers. The chain then is made up of the following transforms:
  - instantiate all profile templates across all models in the model
    set.
  - process all profile template relationships.
  - create all profiles.
  - bind all profiles to configurations.
  - apply the global to local configuration transform.
- at the coding level we then copy across the configurations to the
  corresponding model elements. This is done
- add variable to determine if a feature is available to the
  configuration/profile or not.

Tasks:

- rename annotations to variability.
- rename type to feature.
- rename type group to feature group. Leave traits as is for now.
- rename annotation to configuration.
- create archetype model and mode archetype related types there.

*** POSTPONED Profiles as meta-model elements                         :story:
    CLOSED: [2019-04-22 Mon 09:28]
    :LOGBOOK:
    CLOCK: [2019-04-12 Fri 07:59]--[2019-04-12 Fri 09:00] =>  1:01
    CLOCK: [2019-04-11 Thu 18:39]--[2019-04-11 Thu 19:09] =>  0:30
    CLOCK: [2019-04-11 Thu 18:35]--[2019-04-11 Thu 18:38] =>  0:03
    CLOCK: [2019-04-11 Thu 18:15]--[2019-04-11 Thu 18:34] =>  0:19
    CLOCK: [2019-04-11 Thu 17:50]--[2019-04-11 Thu 18:11] =>  0:21
    CLOCK: [2019-04-11 Thu 16:53]--[2019-04-11 Thu 17:49] =>  0:56
    CLOCK: [2019-04-11 Thu 14:04]--[2019-04-11 Thu 16:52] =>  2:48
    CLOCK: [2019-04-11 Thu 09:51]--[2019-04-11 Thu 12:38] =>  2:47
    CLOCK: [2019-04-11 Thu 09:21]--[2019-04-11 Thu 09:38] =>  0:17
    :END:

Initially we separated the notion of annotations and profiles from the
metamodel. This is a mistake. Profiles are metamodel
elements. Annotations are just a way to convey profiles in UML.

In the same fashion, there is a distinction between a facet (like say
types) and a facet configuration (enable types, enable default
constructors, etc). These should also be metamodel elements. User
models should create facet configurations (this is part of the profile
machinery) and then associate them with elements.  This means we could
provide out of the box configurations such as =Serialisable= which
come from dogen profiles. We could also have =JsonSerialisable=. Users
can use these or override them in their own profiles. However,
crucially, modeling elements should not reference facets directly
because this makes the metamodel very messy.

In this view of the world, the global profile could then have
associations between these facet configurations and metamodel element
types, e.g.

: object -> serialisable, hashable

These can then be overridden locally.

In effect we are extending the notion of traits from Umple. However,
we also want traits to cover facets, not just concepts.

Terminology clarification:

- traits: configuration of facets. [Actually these are now understood
  to be configurations. Traits will be the object templates, though we
  need to re-read the umple paper.]
- profile: mapping of traits to metamodel elements, with
  defaults. E.g. =object -> serialisable, hashable=. []Actually these
  are just the stereotypes.]

Actually there is a problem: traits as used in MOP are close to our
templates. We should rename templates to traits to make it
consistent. However, we still need the notion of named collections of
facet configurations with inheritance support.

*Thoughts on Features*

There is a facet in dogen called "features". The facet can have
multiple backends:

- dogen/UML: special case when adding new features to dogen
  itself. Any features added to this backend will be read out by dogen
  and made available to facets.
- file based configuration: property tree or other simple system to
  read configuration from file.
- database based configuration: a database schema (defined by the
  facet) is code-generated.
- etcd: code to read and write configuration from etcd is generated.

The feature facet can be used within a component model or on its own
model. Features are specifically only product features, not properties
of users etc. They can be dynamically updated if the backend supports
it. Generated code must handle event notification.

*Thoughts on Terminology*

- traits should be used in the MOP sense.
- profiles/collections of settings/configurations should be called
  =capabilities=. This is because they normally have names like
  =serialisable= etc. When not used in the context of modeling
  elements it should be called just configuration (in keeping with
  feature modeling). A capability is a named configuration for
  reuse. The only slight snag is that there are named configurations
  that should not be called capabilities (say licensing details,
  etc). These are required for product/product line support. Perhaps
  we should just call them "named configurations". Crucially, named
  configurations should inherit the namespace of the model and there
  should not be any clashes (e.g. dogen should error). Users are
  instructed to define their product line configuration in a model
  with the name of the product line (e.g. =dogen::serialisable=
  becomes the stereotype). To make the concept symmetric, we need the
  notion of a "model level stereotype". This can easily be achieved by
  conceiving the model as a package. For the purposes of dia we can
  simply add a =dia.stereotype= which conveys the model
  stereotypes. With these we can now set named configurations at the
  model level. This then means the following:
  - define a model for dogen (the product) with all named
    configurations. These are equivalent to what we call "profiles" at
    present and may even have the same names. the only difference is
    that because they are model elements, we now call them
    =dogen::PROFILE=, e.g. =dogen::disable_odb_cmake=. We should also
    add all of the missing features to the named configurations
    (disable VS, disable C#, etc).
  - add stereotypes to each model referencing the named configuration.
- with this approach, product lines become really easy - you just need
  to create a shared model for the product line (its own git repo and
  then git submodules). Because named configurations can use
  inheritance you can easily override at the product level as well as
  at the component level.
- when a named configuration is applied to a model element, the
  features it contains must match the scope. We should stop calling
  these global/local features and instead call them after the types of
  modeling elements: model, package, element, etc.
- traits are now only used for the purposes intended by MOP.
- features are integrated with UML by adding features to the
  metamodel.
- =profiles= should be used in the UML sense only.

*Thoughts on code generation*

- create a stereotype for =dogen::feature_group=. The name of the
  feature (e.g. the path for the kvp) will be given by the model name
  and location plus package plus feature group name plus feature
  name. example =dogen.language.input= instead of
  =yarn.input_languages=.
- the UML class's attributes become the features. The types must match
  the types we use in annotation, except these are also real dogen
  types and thus must be defined in a model and must be fully
  qualified. We must reference this model. Default value of the
  attribute is the UML value.
- any properties of the feature that cannot be supplied directly are
  supplied via features:

:    "template_kind": "instance",
:    "scope": "root_module"

- note that these are features too, so there will be a feature group
  for feature properties. Interestingly, we can now solve the
  enumeration problem because we can define a
  =dogen::features::enumeration= that can only be used for features
  and can be used to check that the values are correct. One of the
  values of the type is any element who's meta-type is
  =feature_enumeration=. Actually we don't even need this, it can be a
  regular enumeration (provided it knows how to read itself from a
  string). Basically a valid type for a feature is any dogen
  enumeration.
- annotations become a very simple model. There are no types in
  annotation itself, just functions to cast strings. These will be
  used by generated code. The profile merging code remains the same,
  but now it has no notion of artefact location; it simply merges KVPs
  based on a graph of inheritance (this time given by model
  relationships, but with exactly the same result as the JSON
  approach).
- annotation merging still takes place, both at the named
  configuration levels, and then subsequently at the element
  level. Named configurations are just meta-model entities so we can
  locate them by name, and literally copy across any key that we do
  not have (as we do now).
- code generation creates a factory for the feature group containing:
  - a registration method. We still need some kind of registration of
    key to scope so that we can validate that a key was not used in
    the wrong scope.
  - a class with all the members of the feature group in c++ types;
  - a factory method that takes in a KVP or an annotation and returns
    the class.
- there are no templates any longer; we need to manually create each
  feature in the appropriate feature group. Also, at present we are
  reading features individually in each transform. Going forward this
  is inefficient because we'd end up creating the configuration many
  times. We need some kind of way of caching features against
  types. At present we do this via properties. We could create
  something like a "configuration" class and then just initialise all
  features in one go. The transforms can then use these. Model
  elements are associated with configurations. The easiest way is to
  have a base class for configurations and then cast them as required
  (or even have a visitor, since we know of the types). Alternatively,
  we need to change the transforms so that we process a feature group
  all in one go. This would be the cleanest way of doing it but
  perhaps quite difficult given the current structure of the code.
- we could also always set the KVP value to be string and use a
  separator for containers and make it invalid to use it in strings
  (something like |). Then we could split the string on the fly when
  time comes for creating a vector/list.

Notes:

- loading profiles as meta-model elements is going to be a challenge,
  especially in a world where any model can make use of them. The
  problem is we must have access to all profile data before we perform
  an annotation expansion; at present this is done during the creation
  of the context in a very non-obvious way (the annotation_factory
  loads up profiles on construction). We either force users to have
  configuration models (CMs, configuration models?) in which case we
  can simply load all of these up first or we need a two-pass approach
  in which we load up the models but only process the mappings,
  initialise the annotation factory and then do the regular
  processing. The other problem is that we are only performing
  resolution later on, whereas we are now saying we need to expand the
  stereotype into a full blown annotation by resolving the stereotype
  into a name quite early in the pipeline. In the past this worked
  because we were only performing a very shallow resolution (string
  matching and always in the same model?) whereas now we are asking
  for full location resolution, across models. This will also be a
  problem for mappings as meta-model elements.
- a possible solution is to split processing into the following
  phases:
  1. load up target model.
  2. read references from target, load references. Need also to
     process model name via annotations. This means its not possible
     to use external modules as a named configuration (or else its
     recursive, we cannot find a configuration because its missing
     EMs, and its missing EMs because we did not process the named
     configuration). In a world where external modules are merged with
     model modules, this becomes cleaner since the model module must
     be unique for each model.
  3. collect all elements that need pre-processing and pre-process
     them: mappings, licences, named configurations/profiles. Not
     traits/object templates. All initialised structures are placed in
     the context. Note that we are actually processing only these
     elements into the endomodel, everything else is untouched. Also
     we need to remove these elements from the model as well so that
     they are not re-processed on the second phase. In addition, we
     need resolution for the meta-elements on the first phase, so we
     need to prime the resolver with these entities somehow,
     independently of the model merging. Or better, we need to create
     a first phase model-merge that only contains entities for the
     first phase and process that. So: load target, collect all
     first-phase meta-elements and remove from target, add target to
     cache. Then repeat process with references. Then merge this model
     and process it.
  4. Second phase is as at present, except we no longer load the
     models, we reuse them from an in-memory cache, after the
     filtering has taken place.
- note that the new meta-model elements are marked as non-generatable
  so a model that only contains these is non-generatable. Same with
  object templates/traits.
- the only slight problem with this approach is that we wanted the
  context to be const. This way we need to do all of these transforms
  before we can initialise the context. One possible solution is to
  split out first pass from second pass (different namespaces) so that
  "context" means different things. We can then say that the second
  phase context depends on first phase transform chain (in fact the
  input for the second phase is the output of the first phase,
  including cached models etc).

Links:

- https://cruise.eecs.uottawa.ca/umple/Traits.html

Notes:

- on a first pass, add the dot names (dogen.enable_all_facets). Remove
  this as soon as we get things to work. We should only rely on model
  names (e.g. masd::enable_all_facets). We should also remove labels.
- move generation of profile repository outside of annotation
  expander.
- remove uses of annotations expander from stitch, if any are still
  left.
- move annotation expansion from adaptor into its own transform. It is
  done against the model set.
- profile repository appears deprecated, remove it?
- we probably should rename =coding::configuration= to "unbound
  configuration" or some other name to make it distinct from
  =variability::configuration=.

** Deprecated
*** CANCELLED Consider code generating utility at a product level     :story:
    CLOSED: [2019-04-17 Wed 07:39]

*Rationale*: this is a bad idea. Utility will be moved over to a
PDM-like model instead.

At present we are copying and pasting logging from utilities to all
new projects and then adding log initialisation to binaries. It would
be nicer if this was part of dogen itself, and we could somehow state
that we are targeting Boost.Log at the executable level and have the
logging initialisation code all generated, including
initialisation. Of course, when using it on a product with multiple
components, it would be even better if this code could be shared. We
need to review all the code in utilities and see if there is a way to
create a model that can take on that functionality as meta-data
parameters. Useful things:

- dogen "standard" exceptions: invalid enum value, etc. Exceptions
  that we think may be useful in several applications but for which
  there is no c++ standard equivalent.
- file utilities: read whole file etc.
- hashing
- io
- etc.

In effect what we really want is to have a way to generate the utility
library for each product, which is what we are doing at present
manually. A better way of doing this would be to have a product line
level option whereby users could state they would like it included
with their product. Dogen would then code generate it with all the
right options. In effect, its a configurable model with trivial
utilities. We could also just go back to the ideas around needle and
call it =needle=, or something else that is not very likely to clash
with user code.

Another way to look at this is to consider the utility model as just
like any other model and instead introduce "type bundles" for certain
functionality. For example: logging, etc. We could just have a
stereotype for these "bundles", applicable to a package:

: masd::bundle::logging

This would generate a namespace with logging functionality. Users can
create a small package and not bother with supplying details or create
a large package and add their own types to it as well.

The bundle expands during transformation to the generation of the
types associated with the bundle. This means we need individual
meta-types for each type. In the cases where we have helpers per type
(e.g. IO, etc) maybe it makes more sense to use these as properties
and enable them specifically:

: masd::bundle::io
: masd.bundle.io.add_type=std::array

Similarly, the test bundle provides a number of dogen tests for
types. If you'd like to test models, you need to enable it on your
utility model - e.g. models must reference a utility model and then we
check to see if the test bundle is enabled.

For extra marks, with would be great if you could associate a bundle
with a facet as well, so that the IO, hashing etc types would go into
the right facet folders rather than under types.

Notes:

- once we have the concept of products and once we support meta-data
  for vcpkg (other story), we can then generate a "vcpkg script" per
  product. This is a script that gets vcpkg, bootstraps it and
  installs all of the dependent packages.
