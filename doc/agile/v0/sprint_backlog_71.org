#+title: Sprint Backlog 71
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) spike(p) }

* Mission Statement

- Perform the main refactors to tack and yarn;
- Simplify templates;
- Integrate Clang.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75
#+CAPTION: Clock summary at [2015-08-10 Mon 14:58]
| <75>                                                                        |         |       |      |
| Headline                                                                    | Time    |       |      |
|-----------------------------------------------------------------------------+---------+-------+------|
| *Total time*                                                                | *31:08* |       |      |
|-----------------------------------------------------------------------------+---------+-------+------|
| Stories                                                                     | 31:08   |       |      |
| Active                                                                      |         | 31:08 |      |
| COMPLETED Sprint and product backlog grooming                               |         |       | 2:15 |
| POSTPONED Compile dogen in Windows using Visual Studio 2015                 |         |       | 8:47 |
| COMPLETED Rename SML to =tack=                                              |         |       | 4:33 |
| COMPLETED Merge frontend with =tack=                                        |         |       | 4:38 |
| COMPLETED Rename dia to tack to tack dia                                    |         |       | 0:27 |
| COMPLETED Remove troubleshooting options                                    |         |       | 0:52 |
| COMPLETED Rename =dia_tack= test data to =tack_dia=                         |         |       | 0:08 |
| CANCELLED Dia hydrator should hydrate with path                             |         |       | 0:16 |
| COMPLETED Remove support for split projects                                 |         |       | 2:10 |
| COMPLETED Analysis on the need for two meta-models in dogen                 |         |       | 7:02 |
#+end:

*** COMPLETED Sprint and product backlog grooming                     :story:
    CLOSED: [2015-08-10 Mon 14:57]
    CLOCK: [2015-08-07 Fri 16:48]--[2015-08-07 Fri 17:44] =>  0:56
    CLOCK: [2015-08-05 Wed 17:08]--[2015-08-05 Wed 17:44] =>  0:36
    CLOCK: [2015-08-03 Mon 17:42]--[2015-08-03 Mon 17:59] =>  0:17
    CLOCK: [2015-07-20 Mon 14:30]--[2015-07-20 Mon 14:56] =>  0:26

Updates to sprint and product backlog.

- backlog reviewed up to "Failed facet dependencies should be treated
  as errors".

*** POSTPONED Compile dogen in Windows using Visual Studio 2015       :story:
    CLOSED: [2015-08-10 Mon 14:57]
    CLOCK: [2015-08-04 Tue 23:11]--[2015-08-04 Tue 23:35] =>  0:24
    CLOCK: [2015-08-04 Tue 23:05]--[2015-08-04 Tue 23:10] =>  0:05
    CLOCK: [2015-08-04 Tue 22:59]--[2015-08-04 Tue 23:04] =>  0:05
    CLOCK: [2015-08-04 Tue 14:26]--[2015-08-04 Tue 14:39] =>  0:13
    CLOCK: [2015-08-01 Mon 09:00]--[2015-08-01 Mon 17:00] =>  8:00

Using our "SoC" resources, we need to setup a Dogen development
environment on Windows using VS 2015. We need to also create a blog
post about it.

Issues:

- is polymorphic in instrinsics for microsoft, remove comment. see
  patch in github.
- update find boost with MSVC version
- add string to enum io
- update exception classes: remove default in base constructor, and
  add explicit to base and derived as well as by ref.

File with instructions:

0. cd c:\DEVELOPEMENT\output
1. (only once - as admin) update version of msvc in cmake C:\Program
  Files (x86)\CMake\share\cmake-3.3\Modules\FindBoost.cmake
  look for msvc-140 and update it to msvc-150
2. set CMAKE_INCLUDE_PATH=C:\boost\include;C:\DEVELOPEMENT\libxml2-2.7.8.win32\include
   set CMAKE_LIBRARY_PATH=C:\boost\lib;C:\DEVELOPEMENT\libxml2-2.7.8.win32\lib
3. cmake ..\dogen -G "Visual Studio 14 2015" -Wno-dev (CONFIGURATION COMMAND)

if you need to re-run: delete the cache:

del CMakeCache.txt

4. msbuild dogen.sln /t:config

5.msbuild dogen.sln /t:dia /fileLogger   => used to create log for
  errors- called msbuild.log in output directory

Links:

- [[http://dominoc925.blogspot.co.uk/2013/04/how-i-build-boost-for-64-bit-windows.html][How I build Boost for 64 bit Windows]]
- [[https://svn.boost.org/trac/boost/ticket/11449][C++11 - is_polymorphic doesn't work with final-ed class in MSVC.]]
- [[https://github.com/boostorg/type_traits/blob/04a8a9ecc2b02b7334a4b3f0459a5f62b855cc68/include/boost/type_traits/intrinsics.hpp][type_traits/include/boost/type_traits/intrinsics.hpp]]
- [[http://stackoverflow.com/questions/20800166/cmake-compile-with-mt-instead-of-md][CMake - compile with /MT instead of /MD]]
- [[http://www.cmake.org/cmake/help/v3.1/manual/cmake-generators.7.html][CMake Generators]]
- [[http://choorucode.com/2014/06/06/how-to-build-boost-for-visual-studio-2013/][How to build Boost for Visual Studio 2013]]

*** COMPLETED Rename SML to =tack=                                    :story:
    CLOSED: [2015-08-03 Mon 17:32]
    CLOCK: [2015-08-03 Mon 17:33]--[2015-08-03 Mon 17:42] =>  0:09
    CLOCK: [2015-08-03 Mon 14:32]--[2015-08-03 Mon 17:32] =>  3:00
    CLOCK: [2015-07-31 Fri 18:44]--[2015-07-31 Fri 19:25] =>  0:41
    CLOCK: [2015-07-31 Fri 08:04]--[2015-07-31 Fri 08:47] =>  0:43

This will now be the name to reflect its "intermediate" state.

#+begin_quote
In sewing, to tack or baste is to make quick, temporary stitching
intended to be removed.
#+end_quote

**** Comments from SML that need to be moved to new model

@section sml_0 Core Ideas

SML has at its core the ideas explained by Eric Evans in Domain Driven
Design (DDD), and it is mainly a domain model to model the DDD domian.
However, it also contains some influences from Java's EMF - more precisely
eCore, which was the first meta-model we looked at. eCore is itself rooted
in UML. We also took some ideas from Stepanov and Jones, in Programming
Elements (those which we could just about understand).

In more general terms, SML is a meta-model - that is a model that models
models - but we are not too hang-up on the classic terminology of meta-modeling
because a lot of people find it confusing. Instead, we chose to use the
@e ubiquitous @e language defined in th DDD book because its very clear, but
avoids the complexity of the terms usually associated with meta-modeling.

The objective of SML is to provide the required scaffoling to represent domain
models, and to do so in a way that is programming language neutral. Thus is
should provide a representation that is suitable for further transformations
into models representing programing languages, and from there, to code
generation.

At the root of SML is the @ref model, short for domain model. It is the root
of an aggregate containing a number of @e modeling @elements which together
make up the software representation of a given domain model. The key types of
modeling elements in SML are:

@li @b model: the model itself, modeling domain models
@li @b modules: packaging unit; logical sub-division of the model.
@li @b concepts: not present in DDD; models the C++ notion of a concept.
@li @b enumeration: value type that models enumerations
@li @b primitive: value type that models primitive types such as int, etc.
@li @b object: models the notion of an @e object as defined in object oriented
languages.

The remaining ideas are refinements of these core concepts.

**** Comments from SML that may be applicable to Tack but need refactoring

@section sml_1 Merging and Resolving

Tack models begin their life as disjointed models with lots of missing
references to types. This expectation arises from the fact that we
have most likely transformed some kind of external model into Tack - a
dia diagram, say - and that the tools used for working on that model
are not aware of Tack or Dogen in general.

Thus, in order to become useful, a Tack model needs to be merged with
all of its dependencies. This is done by providing the @e target model
- i.e. that which one intends to really work on - and its @e
references - i.e. any models which are picked up due to being
referenced from within the tatget model - and pass them over to the
@ref merger. It is the merger's job to create a @e merged model.

A further step is still required, which is to @e resolve all of the references,
to ensure we do not have any missing dependencies. This is the job of the
@ref resolver.

All of these steps are encompassed in the SML @ref workflow.

*** COMPLETED Merge frontend with =tack=                              :story:
    CLOSED: [2015-08-04 Tue 21:29]
    CLOCK: [2015-08-04 Tue 20:57]--[2015-08-04 Tue 21:28] =>  0:31
    CLOCK: [2015-08-04 Tue 17:54]--[2015-08-04 Tue 18:04] =>  0:10
    CLOCK: [2015-08-04 Tue 17:28]--[2015-08-04 Tue 17:53] =>  0:25
    CLOCK: [2015-08-04 Tue 16:34]--[2015-08-04 Tue 17:25] =>  0:51
    CLOCK: [2015-08-04 Tue 14:41]--[2015-08-04 Tue 16:33] =>  1:52
    CLOCK: [2015-08-03 Mon 21:15]--[2015-08-03 Mon 22:04] =>  0:49

Combine the two models performing the necessary renames. Notes:

- merge frontend with tack. Rename frontend interface to something
  like model source or just source. Remove the dia frontend class,
  moving the code into the dia transformer.
- consider creating a top-level workflow that unites the frontend
  workflow with the "merging" workflow.
- Find good names for all workflows. A good name for the current SML
  workflow is =assembler= because it assembles a complete model from
  all the parts.
- consider creating a "file opener" that takes an input descriptor and
  returns a stream. This way the source interface can just be an
  ostream. This probably makes no sense for certain sources like dia
  though.
- create tack_json. this is in preparation for =tack.dia=, etc.
- use pointer map in registrar rather than shared pointers.

*** COMPLETED Rename dia to tack to tack dia                          :story:
    CLOSED: [2015-08-04 Tue 21:57]
    CLOCK: [2015-08-04 Tue 21:30]--[2015-08-04 Tue 21:57] =>  0:27

- rename dia to tack to tack_dia. this is in preparation for
  =tack.dia=, etc.

*** COMPLETED Factor all =housekeeping_required= methods into one     :story:
    CLOSED: [2015-08-04 Tue 22:58]

In knit model we seem to have several of these: =housekeeping_required=.

*** COMPLETED Remove troubleshooting options                          :story:
    CLOSED: [2015-08-04 Tue 22:50]
    CLOCK: [2015-08-04 Tue 21:58]--[2015-08-04 Tue 22:50] =>  0:52

*New Understanding*

We don't really use the troubleshooting options so remove it and all
associated infrastructure.

*Previous Understanding*

We seem to have the ability of saving dia diagrams etc when importing
a tack model but this is not used any where. It was borked with the
latest refactor. Remove this functionality.

*** COMPLETED Rename =dia_tack= test data to =tack_dia=               :story:
    CLOSED: [2015-08-04 Tue 22:58]
    CLOCK: [2015-08-04 Tue 22:50]--[2015-08-04 Tue 22:58] =>  0:08

This was not picked up in previous rename.

*** CANCELLED Dia hydrator should hydrate with path                   :story:
    CLOSED: [2015-08-04 Tue 23:16]
    CLOCK: [2015-08-04 Tue 23:00]--[2015-08-04 Tue 23:16] =>  0:16

*Rationale*: We are initialising the libxml reader on construction,
which is used by all methods in the class. A better design for this
would take a while to get right so we will leave it like this for
now.

At present the hydrator is constructed with the file path. This is not
ideal.

*** CANCELLED Handling of include cmakelists in split projects is not correct :story:
    CLOSED: [2015-08-05 Wed 14:57]

*Rationale*: no longer a problem after removing split project support.

At present we are only generating a cmakelists file for include
folders on non-split projects. This means that the header files for
split projects won't be packaged up. It also means that for ODB
projects we won't get the ODB targets.

*** COMPLETED Make knitter's module path consistent for target and refeences :story:
    CLOSED: [2015-08-05 Wed 17:05]

At present we have two ways of supplying module paths, one for target
and another for references. Make it consistent.

*** COMPLETED Remove support for split projects                       :story:
    CLOSED: [2015-08-05 Wed 17:07]
    CLOCK: [2015-08-05 Wed 14:57]--[2015-08-05 Wed 17:07] =>  2:10

We don't really have any use cases for split projects. Remove this
feature and associated infrastructure.

*** COMPLETED Analysis on the need for two meta-models in dogen       :story:
    CLOSED: [2015-08-10 Mon 14:57]
    CLOCK: [2015-08-07 Fri 14:21]--[2015-08-07 Fri 16:55] =>  2:26
    CLOCK: [2015-08-07 Fri 07:55]--[2015-08-07 Fri 10:50] =>  2:55
    CLOCK: [2015-08-06 Thu 07:54]--[2015-08-06 Thu 08:52] =>  0:58
    CLOCK: [2015-08-05 Wed 21:49]--[2015-08-05 Wed 22:00] =>  0:11
    CLOCK: [2015-08-05 Wed 17:44]--[2015-08-05 Wed 18:05] =>  0:21
    CLOCK: [2015-08-05 Wed 14:53]--[2015-08-05 Wed 14:56] =>  0:03

*New Understading*

- after reviewing all use cases and all of the problems with the
  current implementation, there does not seem to be enough of a need
  for another intermediate model. Most of the look-ups that are done
  in =cpp= are due to the internal data structures it needs to
  generate; the only exception is with helper methods, which are a
  hack anyway.
- there are no good solutions for the cycle problems in =cpp= and most
  of the ideas are far too complicated to make sense of. We need to
  continue to make incremental changes and try to get the code in a
  slightly more maintainable position rather than find one big
  conceptual solution for it - we have tried this over a very long
  period of time and failed. All big conceptual stories should be
  closed, and in their stead, we need to raise a set of concrete
  stories that tackle well understood parts of the problem. Overall,
  the =cpp= model will remain as is, minus a couple of changes.

Things we can do:

- rename =tack= to =yarn=. Bit of a mistake using =tack=, it meant
  "temporary" because we thought there would be a "final"
  representation with =yarn= Without =yarn=, =tack= no longer sounds
  like a good name.
- split properties from formattables.
- add some kind of marker that tells inclusion builder when its
  building includes for internal =cpp= types rather than tack..
- clean up factory.
- add kernel to ownership hierarchy, clean it up.
- clean up qname with the model name / model path separation, paving
  the way for supporting dot separated model names.
- close all stories in backlog around big refactors. This marks the
  end of that cycle, the architecture is now stable.

*Previous Understanding*

We need to create a meta-model with the following characteristics:

- rename frontend to middle end workflow to yarn generation workflow
  or some such name.
- have a look at eCore/MOF type names for inspiration.
- single top-level type for all types with a container. Use boost
  pointer container. add a visitor for the type.
- consider not having a top-level entity called model but instead use
  a top-level package.
- wherever we are using qnames to refer to external types, use a
  reference instead. Use reference wrapper where required.
- we could probably merge backends with yarn and call these
  "sinks". This way we could have "sources" in tack and "sinks" in
  yarn.
- we do not need a qname. We need a name that is made up of just a
  string (the actual name of the object) plus a reference to the
  containing module. The containing module has a structure of paths
  similar to =qname=.

Use cases:

- we know the sizes of all containers in C++ up front, as well as the
  "positions"; basically we could attribute a number to all types and
  all formatters and use those numbers as indices in a vector; the
  vector could be sized up front. It is effectively a two dimensional
  vector of =(type, formatter)=. We could collapse this two one
  dimension by spacing out type id's by the formatter size (e.g. type
  index * formatter size sort of thing). Make the container dense
  rather than sparse; if a formatter is disabled, its still in the
  container.
- We could create a class to represent all intermediate properties and
  make that the value of the two-dimensional vector.
- for enablement, qname could be any type id (int, etc.). We don't use
  it directly. We just need access to the dynamic object. We need to
  inject the id's for the registrar (one per target + reference
  model). We just need a linear way to iterate through the model's ids
  mapped to a dynamic object.
- for path derivatives we need the qname (or something like the qname:
  name + location). We generate all paths associated with each
  qname. We need to inject the registrar qnames. The resulting
  derivatives can be mapped against an id. Here we could iterate
  through all types in the model and access their name + location and
  generate their path derivatives. We need the root object's dynamic
  object to generate the path settings, but otherwise we don't need
  the dynamic object.
- for inclusion directives, we need to have path derivatives
  generated. We also need the dynamic object to find out if there are
  any overrides to inclusion directives.

Tasks:

- create an id property in element which is computed on the basis of
  name and location. Add a location property which is the same as in
  tack.

** Deprecated
*** CANCELLED Create knitter options for each frontend                :story:
    CLOSED: [2015-08-05 Wed 17:14]

*Rationale*: not required after latest refactor.

At present some knitting options are specific to a frontend
(particularly in troubleshooting). We should create different classes
to represent options on a per fronend basis.
*** CANCELLED Add identity management to =sml::property_indexer=      :story:
    CLOSED: [2015-08-07 Fri 15:40]

*Rationale*: identity was removed.

At present we are populating the identity properties in dia to sml. We
need to move this to property indexer in SML.

We found a problem with moving this: we need the identity properties
to be in the object before we inject system types (they are used to
generate keys) but property indexing happens after injection. We
cannot move property indexing to be before injection (we need system
types to exist). We probably need to split property indexing into
two. The other problem is that if we take into account concepts, the
identity properties should only be indexing after concepts have been
indexed. This requires a bit of thinking.

See [[https://github.com/DomainDrivenConsulting/dogen/blob/master/patches/move_identity_attribute_to_sml.patch][the patch]] for the latest on this.
*** CANCELLED Support ordering of includes                            :story:
    CLOSED: [2015-08-07 Fri 16:57]

*Rationale*: we already have a function to order includes more or less
along these lines. There is no use case for further configurability.

One of my personal preferences has always been to group includes by
"library". Normally first come the C includes, then the standard
library ones, then boost, then utilities and finally types of the same
model. Each of these can be thought of as a group. Inside each group
the file names are normally ordered by size, smallest first. It would
be nice to have support for such a feature in Dogen.

Formatters would then push their includes into the correct
group. Group names could be the model name (=std=, etc).

A bit of a nitpick but nice nonetheless.

*** CANCELLED Consider renaming =knit= to =weave=                     :story:
    CLOSED: [2015-08-07 Fri 17:03]

*Rationale*: term reserved for AOP. Added story to keep track of terms.

We seem to have missed an obvious term: weaving. We can either save it
for later or perhaps rename =knit= to =weave=.

Actually, since weave is a well-known term in AOP, we should save it
for if/when we decide to support AOP.

*** CANCELLED Adding a dependency to a non-existent expander crashes dogen :story:
    CLOSED: [2015-08-07 Fri 17:17]

*Rationale*: expanders have long since been removed.

We are not checking that all dependencies exist when building the
graph. If we add a dependency to a expander that does not exist we
crash and burn:

: /home/marco/Development/DomainDrivenConsulting/dogen/projects/knit/spec/workflow_spec.cpp(550): last checkpoint
: dogen_knit_spec: /usr/include/boost/smart_ptr/shared_ptr.hpp:653: typename boost::detail::sp_member_access<T>::type boost::shared_ptr<dogen::dynamic::expansion::expander_interface>::operator->() const [Y = dogen::dynamic::expansion::expander_interface]: Assertion `px != 0' failed.
: unknown location(0): fatal error in "all_primitives_model_generates_expected_code": signal: SIGABRT (application abort requested)

The cause of this is that we may end up creating vertices for
dependencies (initialised with a null shared pointer) but never
actually =add= the expander that corresponds to that expander name to
the graph. We then visit the graph and assume all vertices have valid
expanders, which results in the error above.

We can do two things:

- validate that all dependencies exist by placing all expanders in a
  set and resolving the dependencies; this can be done before the
  graph.
- checking that the expander pointer points to not null or throw.

*** CANCELLED Consider introducing =archetypes= to simplify output models :story:
    CLOSED: [2015-08-07 Fri 17:38]

*Rationale*: this story is far too complicated and confusing. We need
to continue thinking around this area (and take some ideas from this)
but the entire thing is unusable.

We haven't quite arrived at the ideal configuration for the cpp
model. We are close, but not there yet. The problem we have at the
moment is that the formatters drive a lot of the work in
formattables, resulting in a circular dependency. This is happening
because we are missing some entities. This story is just a random set
of thoughts in this space, trying to clear up the terminology across
the board.

*Random thoughts*

What is probably needed is to have facets, aspects and "file kinds" as
top-level concepts rather than just strings with which we label
formatters. In addition, we need a good name for "file kinds". This is
a meta-concept, something akin to a file template. The formatter
produces a physical representation of that meta-concept. As part of
the formatter registration, we can also register this meta-concept
(provided it relies on an existing formattable). And in effect, these
are the pieces of the puzzle:

- you define a "file kind".
- a facet and a model are groupings of "file kinds". These happen to
  be hierarchical groupings. There are others: header and
  implementation, or class header formatter. Those are
  non-hierarchical.
- you bind a transformer to a SML type to generate a formattable.
- a formattable is associated with one or more "file kinds" or better
  yet a file kind is associated with a formattable. It is also
  associated with formatting properties and settings. It is those
  tuples that we pass to the formatters.
- you bind a formatter to a "file" and process the associated
  formattable.

Perhaps we can call these "file kinds" file archetypes or just
archetypes.

What can be said about an archetype:

- conceptual notion of something we want to generate.
- one SML entity can map to zero or many archetypes. Concept at
  present maps to zero. Object maps to many.
- a representation of the archetype as source code is done by the
  formatter. It uses a template to help it generate that
  representation.
- a given archetype maps to one and only one SML entity.
- a given archetype maps to one and only one CPP entity.
- archetypes can be grouped in many ways. One way is facets and
  models.
- archetypes have definitions: name of the archetype, what groups it
  belongs to.
- archetypes have associated data: formattables, settings,
  properties. This is an entity and needs a name.
- formatters work on one and only one archetype.
- archetypes have qualified names; this is (mostly) what we called
  ownership hierarchy. Qualified names can be represented as separate
  fields or using the dot notation.
- archetypes have labels: this is what we called groups.
- dynamic is a model designed to augment SML with some archetype
  data. This is not true in the dia case. Check all fields to see if
  it is true everywhere else.
- an aspect is a property of one or more archetypes; it is a knob that
  affects the generation of the source code representation.
- an archetype instance belongs to an archetype.
- we should remove the concept of "integrated facets". It just happens
  that a facet such as types may have aspects that enable features
  similar to aspects in other facets. There may be rules that
  determine that when certain aspects are enabled, certain facets must
  be switched off because they are incompatible.
- facet is a good name for grouping archetypes, but model isn't. We
  need a better name for a set of facets. Aspect is also a good
  name. In addition, a model group is also a bad name. A "model" is a
  cohesive group of archetypes that are meant to be used together. A
  "model group" is a cohesive group of models that provide the same
  conceptual representations in different programming languages. Maybe
  we should use a more "random" name such as: pod. Then perhaps a
  model group could become a "pod family": a family of related pods. A
  given model can be represented by one pod family or another - they
  are mutually exclusive. Of course, from a command line perspective,
  its better to think of "modes". Each mode corresponds to choosing
  one "pod family" over another. This does not map very cleanly.
- archetypes have an associated programming language - a grammar.
- a facet may exist in more than one programming language and an
  aspect too.
- pods are programming language specific.
- formattables are kind of like an archetype friendly representation
  of the domain types. We need a good name for this.
- internal and external now make slightly more sense, at least once we
  got a good name for formatters. We still need a good name for it
  though. If the archetype instance is generated because of the
  presence of the domain type, it is external. If the archetype has no
  sensitivity to domain types (but may have sensitivity to other
  things such as options) it is internal. The naming around this is
  not totally clear.
- internal formatters may not be allowed to be disabled. For example,
  if serialisation is on, registrar must be generated. With
  CMakeLists, we may want do disable them altogether.
- in the thrift story in the backlog we mention the existence of
  mutually exclusive groups of facets. We should also come up with a
  name for these.
- archetype may not quite be the right name. See [[http://www.pearsonhighered.com/samplechapter/032111230X.pdf][Archetypes and
  archetype patterns]]. See also:
  - [[http://www.step-10.com/SoftwareDesign/ModellingInColour/ColourCoding.html][Class Archetypes, UML and Colour]]
  - [[http://www.step-10.com/SoftwareDesign/ModellingInColour/index.html][Peter Coad's 'Modeling in Color']]
  - [[http://www.step-10.com/Books/JMCUBook.html][Java Modeling in Color with UML]]
- the process of mapping domain types to archetypes could be called
  "expansion" because its a one to many relationship in most cases.
- its not quite correct to call CPP types "formattables". The
  archetype has to have an ordered container of inputs to the
  formatter. This is sort of the "payload" for formatting; the
  archetype is a container of such entities. Taking into account the
  cases where more than one type is placed in the same file, this
  would result in the includes being merged. Or perhaps these things
  are really formattables, but then we need a way to distinguish
  between "top-level formatters" that generate archetypes from
  "partial" formatters that can be combined.
- with "facet specific types" we go one level deeper: it should be
  possible to add an enumeration definition to say test data. This
  would mean that archetypes and facets are not quite so aligned as we
  first thought. Potentially, one should be able to ask for say a
  formattable at facet X in an artchetype at facet Y.
- One way to look at it is as follows: there is the modeling
  dimension, in which we have an entity, say entity =A=; and there is
  the implementation dimension, in which =a= can be represented by
  =A1, A2, ..., An= archetypes. In effect, the implementation
  dimension has multiple dimensions, one for each pod (and of course
  the pod families would be an extra dimension and so on). Actually,
  we probably have 3 steps: the modeling dimension, the translation of
  that into a language-specific representation and then finally the
  archetype dimension.
- a good name for the top-level container of archetypes is
  "kernel". This was inspired (loosely) in some ideas from EMF. So
  we'd have say the "quilt kernel", with support for multiple
  programming languages such as cpp, java etc. We we'd have the "pleat
  kernel" and so forth. Each kernel has a set of languages and the
  languages have archetypes. Archetypes have a collection of
  properties such as the formattables they need, the formatters and so
  on. The job of a model such as =quilt::cpp= is to implement this
  binding.
- dynamic fields can be owned by archetypes or by other types of
  owners (e.g. dia). We should have a way of expressing this
  ownership.
- we haven't used the word "feature" anywhere yet (properly; we
  mentioned it in the manual and so on, but not given it any good
  meaning).
- we created a split between "internal" and "external" formatters, but
  its interesting to notice that we have "internal" formatters that
  are "regular" formatters - in that we need to create a qname for
  them and the formatter properties will work correctly; whereas some
  others are "irregular" formatters - they have strange filenames that
  cannot be generated without some fiddling. Actually, ODB options is
  the main problematic one. If we could place it in a sensible
  location we could probably get rid of irregular formatters
  altogether.
- we need to have "special" facets; cmake files for example should not
  really have a facet but it seems having an empty facet name breaks a
  lot of stuff.
- we need a map between types/states in SML and enablement. For
  example, if a type is "non-generatable" that is taken to mean
  "generate types if file does not exist, default all else to
  disabled". We need a way to express this sort of logic. This is akin
  to an "enablement map". For example, users could define these maps
  somewhere, given them a name and then assign a type to a map. In
  addition, we need a way to express "generate but don't override" and
  "generate and override".

*Merged with other stories*

It is important not to confuse formatters with archetypes. A formatter
(or at least, a "top-level formatter"; those that generate files) is
in a sense a "category" of archetypes. In other words, for a given
formatter many archetypes will be generated. This may mean that the
"archetype" is not a very good choice because it may imply some kind
of meta-class-ness. In a sense, we are dealing with arch-entities
("entity" being SML's base class for all modeled domain types). So
fundamentally, the correct workflow is vaguely like this:

- we create a model for some problem domain. We represent this model
  in SML. All objects are identifiable by a qname.
- we apply a transformation of this model into something which is
  closer to the programming language that we wish to generate; these
  we choose to call formattables.
- we may also inject some formattables which do not have a mapping to
  the original domain objects. These have synthetic qnames.
- we apply a function that takes the qname, the SML entity, the
  formattable and generates an archetype skeleton. To start off with,
  this is made up of only a file name and a top-level formatter. The
  structure exists in memory as a map of qnames to formatter names to
  archetypes.
- we then fill in the blanks: compute includes, enablement, etc. The
  final blank that needs to be filled in is the generation of the
  file, which is done by applying a formatter to a number of the
  archetype properties.

Another point of interest is that we may be able to move some of the
archetype processing to common code. For example, file name
generation, enablement, and so on are not language specific. However,
we need to have a representation of the archetype which is specific to
a model (e.g. =quilt::cpp= say) because not all properties will be
common. We could, possibly, have an archetype base class, which then
would imply a formatter's base class and so on - but then we hit the
visitor across models problem.

In this approach we do have an advantage which is we can parallelise a
lot of work across each stage in the "pipeline". For instance we can
run transformation from SML to formattables in parallel. We could
conceivably even have futures for each of the archetype
properties. None of this is a concern for the foreseable future, of
course.

FIXME: improve references by having models inside of models; we should
be able to keep only the types that we refer in the final model.
