#+title: Sprint Backlog 89
#+options: date:nil toc:nil author:nil num:nil
#+todo: STARTED | COMPLETED CANCELLED POSTPONED
#+tags: { story(s) epic(e) }

* Mission Statement

- finish refactoring quilt.cpp.
- tidy-up services, origin types and generation types.

* Stories

** Active

#+begin: clocktable :maxlevel 3 :scope subtree :indent nil :emphasize nil :scope file :narrow 75 :formula %
#+CAPTION: Clock summary at [2016-10-10 Mon 09:04]
| <75>                                                                        |          |        |       |       |
| Headline                                                                    | Time     |        |       |     % |
|-----------------------------------------------------------------------------+----------+--------+-------+-------|
| *Total time*                                                                | *101:19* |        |       | 100.0 |
|-----------------------------------------------------------------------------+----------+--------+-------+-------|
| Stories                                                                     | 101:19   |        |       | 100.0 |
| Active                                                                      |          | 101:19 |       | 100.0 |
| STARTED Sprint and product backlog grooming                                 |          |        |  5:36 |   5.5 |
| COMPLETED Edit release notes for previous sprint                            |          |        |  0:07 |   0.1 |
| COMPLETED Generation of formattable is incorrect                            |          |        |  2:30 |   2.5 |
| COMPLETED Visitor includes are incorrect                                    |          |        |  0:20 |   0.3 |
| COMPLETED Add includer to quilt.cpp                                         |          |        |  1:46 |   1.7 |
| COMPLETED Add reducer to quilt.cpp                                          |          |        |  0:22 |   0.4 |
| COMPLETED Add new index to formtter container                               |          |        |  0:19 |   0.3 |
| COMPLETED Add path expander to quilt.cpp                                    |          |        |  0:49 |   0.8 |
| COMPLETED Add guard expander to quilt.cpp                                   |          |        |  0:27 |   0.4 |
| COMPLETED Investigate borked travis build                                   |          |        |  0:37 |   0.6 |
| COMPLETED Add decoration expander to quilt.cpp                              |          |        |  0:23 |   0.4 |
| COMPLETED Add aspect expander to quilt.cpp                                  |          |        |  1:26 |   1.4 |
| COMPLETED Run tests that are passing on windows                             |          |        |  0:10 |   0.2 |
| COMPLETED Add helper expander to quilt.cpp                                  |          |        |  1:26 |   1.4 |
| COMPLETED Merge pre and post workflows                                      |          |        |  0:16 |   0.3 |
| COMPLETED Fix bug in aspect and helper generation                           |          |        |  0:15 |   0.2 |
| COMPLETED Investigate element annotation support                            |          |        |  2:05 |   2.1 |
| CANCELLED Add streaming settings expander                                   |          |        |  0:36 |   0.6 |
| COMPLETED Create the formattables model                                     |          |        |  1:32 |   1.5 |
| COMPLETED Hook formattables into formatters                                 |          |        |  3:58 |   3.9 |
| COMPLETED Remove empty context                                              |          |        |  1:09 |   1.1 |
| COMPLETED Review main classes in quilt.cpp                                  |          |        |  3:42 |   3.7 |
| COMPLETED Clean up element segmentation                                     |          |        |  1:20 |   1.3 |
| COMPLETED Get OSX build to compile code                                     |          |        |  7:05 |   7.0 |
| COMPLETED Add a banner to readme                                            |          |        |  1:29 |   1.5 |
| COMPLETED Remove formatter group                                            |          |        |  0:23 |   0.4 |
| COMPLETED Add more types to =quilt::cpp= canned tests                       |          |        |  0:15 |   0.2 |
| CANCELLED Remove formatter id                                               |          |        |  0:04 |   0.1 |
| COMPLETED Analysis around terminology in formatting space                   |          |        |  3:24 |   3.4 |
| COMPLETED Remove =original_model_name=                                      |          |        |  0:16 |   0.3 |
| COMPLETED Refactor code around model origination                            |          |        |  4:08 |   4.1 |
| COMPLETED Remove formatter level facet folders                              |          |        |  0:06 |   0.1 |
| COMPLETED Consider removing the "fake" primitive formatters                 |          |        |  0:01 |   0.0 |
| COMPLETED Expander refactor in =quilt.cpp=                                  |          |        |  3:03 |   3.0 |
| COMPLETED Create the notion of a formatter alias                            |          |        |  3:15 |   3.2 |
| COMPLETED Remove enabled formatters from formatter configuration            |          |        |  0:22 |   0.4 |
| COMPLETED Handle registration of services properly                          |          |        |  3:41 |   3.6 |
| COMPLETED Move stereotypes to element                                       |          |        |  0:21 |   0.3 |
| COMPLETED Improve project banner                                            |          |        |  0:32 |   0.5 |
| CANCELLED Add support for profiles                                          |          |        | 10:40 |  10.5 |
| COMPLETED Move emacs to rtags                                               |          |        |  5:28 |   5.4 |
| COMPLETED Refactor =yarn.dia= transformer                                   |          |        |  8:49 |   8.7 |
| COMPLETED Create a dynamic expander in yarn                                 |          |        |  5:52 |   5.8 |
| COMPLETED Create a streaming configuration expander                         |          |        |  1:15 |   1.2 |
| COMPLETED Merge helper annotations with helper expander                     |          |        |  0:14 |   0.2 |
| COMPLETED Merge aspect annotations with expander                            |          |        |  0:16 |   0.3 |
| COMPLETED Merge inclusion directive annotations                             |          |        |  0:59 |   1.0 |
| COMPLETED Merge path annotations with locator                               |          |        |  2:34 |   2.5 |
| CANCELLED Merge annotations with formattables                               |          |        |  2:35 |   2.5 |
| POSTPONED Clean up terminology in dynamic                                   |          |        |  1:07 |   1.1 |
| POSTPONED Rewrite profile support                                           |          |        |  1:26 |   1.4 |
| POSTPONED Generate formatter interfaces                                     |          |        |  0:28 |   0.5 |
#+TBLFM: $5='(org-clock-time% @3$2 $2..$4);%.1f
#+end:

*** STARTED Sprint and product backlog grooming                       :story:
    CLOCK: [2016-10-09 Sun 18:02]--[2016-10-09 Sun 18:08] =>  0:06
    CLOCK: [2016-10-06 Thu 11:44]--[2016-10-06 Thu 11:47] =>  0:03
    CLOCK: [2016-10-06 Thu 11:36]--[2016-10-06 Thu 11:43] =>  0:07
    CLOCK: [2016-10-06 Thu 11:30]--[2016-10-06 Thu 11:35] =>  0:05
    CLOCK: [2016-10-05 Wed 20:20]--[2016-10-05 Wed 20:45] =>  0:25
    CLOCK: [2016-10-04 Tue 19:06]--[2016-10-04 Tue 19:19] =>  0:13
    CLOCK: [2016-10-03 Mon 10:17]--[2016-10-03 Mon 10:21] =>  0:04
    CLOCK: [2016-10-03 Mon 09:00]--[2016-10-03 Mon 10:16] =>  1:16
    CLOCK: [2016-10-02 Sun 21:25]--[2016-10-02 Sun 21:40] =>  0:15
    CLOCK: [2016-10-02 Sun 20:15]--[2016-10-02 Sun 21:24] =>  1:09
    CLOCK: [2016-10-02 Sun 10:50]--[2016-10-02 Sun 11:54] =>  1:04
    CLOCK: [2016-09-27 Tue 10:04]--[2016-09-27 Tue 10:13] =>  0:09
    CLOCK: [2016-09-26 Mon 15:36]--[2016-09-26 Mon 15:39] =>  0:03
    CLOCK: [2016-09-26 Mon 09:49]--[2016-09-26 Mon 10:00] =>  0:11
    CLOCK: [2016-09-26 Mon 09:22]--[2016-09-26 Mon 09:48] =>  0:26

Updates to sprint and product backlog.

*** COMPLETED Edit release notes for previous sprint                  :story:
    CLOSED: [2016-09-26 Mon 10:08]
    CLOCK: [2016-09-26 Mon 10:01]--[2016-09-26 Mon 10:08] =>  0:07

Add github release notes for v88.

Text:

#+begin_src markdown
Overview
=======

We continue our long road of internal refactorings, focusing on the ```quilt.cpp``` model. There are no user visible changes in this release.

For more details see the [sprint log](https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_88.org).
#+end_src

*** COMPLETED Generation of formattable is incorrect                  :story:
    CLOSED: [2016-09-26 Mon 13:03]
    CLOCK: [2016-09-26 Mon 12:50]--[2016-09-26 Mon 13:03] =>  0:13
    CLOCK: [2016-09-26 Mon 12:30]--[2016-09-26 Mon 12:49] =>  0:19
    CLOCK: [2016-09-26 Mon 11:51]--[2016-09-26 Mon 12:16] =>  0:25
    CLOCK: [2016-09-26 Mon 11:42]--[2016-09-26 Mon 11:51] =>  0:09
    CLOCK: [2016-09-26 Mon 10:09]--[2016-09-26 Mon 11:33] =>  1:24

The new formattable type is generating an invalid header file. It is
missing the forward declaration of the yarn element.

Note: to login to postgres from emacs, [[http://emacs.1067599.n8.nabble.com/sql-postgresql-authentication-failure-td71620.html][leave server empty]].

Load relevant data into postgres for querying:

: grep dogen.knitter.quilt.cpp.log -e "Finished inclusion directives repository" > crap.txt
: cut -b142- crap.txt > ~/inclusion.json
: create table inclusion_directives_json (values jsonb);
: \copy inclusion_directives_json from '~/inclusion.json';

Now create a row per entry in the container:

: create table inclusion_directives2_json (values jsonb);
: insert into inclusion_directives2_json
: select jsonb_array_elements(values->'by_name')
: from inclusion_directives_json;

Now find out type:

: select values as val
: from inclusion_directives2_json
: where values::text like '%<dogen><quilt><cpp><formattables><formattable>%';

And dump it to a file:

: \copy (select values as val from inclusion_directives2_json
: where values::text like '%<dogen><quilt><cpp><formattables><formattable>%')
: to 'out.json';

Actually this was for the directives. We need the same but for the dependencies:

: grep dogen.knitter.quilt.cpp.log -e "Finished creating inclusion dependencies: " > crap.txt
: cut -b144- crap.txt > ~/inclusion_deps.json
: create table inclusion_deps2_json (values jsonb);
: \copy inclusion_deps_json from '~/inclusion_deps.json';

Split objects:

: insert into inclusion_deps2_json
: select jsonb_array_elements(values->'by_name')
: from inclusion_deps_json;

Find our object:

: select values from inclusion_deps2_json
: where values::text like '%<dogen><quilt><cpp><formattable>%';

Save it:

: copy (select values from inclusion_deps2_json where values::text
: like '%<dogen><quilt><cpp><formattables><formattable>%')
: to '~/deps.json';

Actually the problem really was with the inclusion directives! It
seems we are not generating the forward declarations for element:

: select values as val
: from inclusion_directives2_json
: where values::text like '%<dogen><yarn><element>%';

No mention of forward declarations. The problem is fabric is only
injecting forward declarations for the target model. we need to relax
this and do it for all models.

When we do this we seem to overwrite the helper configuration for
types such as =boost::filesystem::path=.

*** COMPLETED Visitor includes are incorrect                          :story:
    CLOSED: [2016-09-26 Mon 13:25]
    CLOCK: [2016-09-26 Mon 13:17]--[2016-09-26 Mon 13:25] =>  0:08
    CLOCK: [2016-09-26 Mon 13:04]--[2016-09-26 Mon 13:16] =>  0:12

We are adding an include to the descendants' header for no
reason. Remove it.

*** COMPLETED Add includer to quilt.cpp                               :story:
    CLOSED: [2016-09-26 Mon 15:13]
    CLOCK: [2016-09-26 Mon 14:43]--[2016-09-26 Mon 15:13] =>  0:30
    CLOCK: [2016-09-26 Mon 13:26]--[2016-09-26 Mon 14:42] =>  1:16

Responsible for computing the inclusion dependencies.

- add a flag in builder to choose new or old API. Supply formattables
  container by ID and new directives repository. When using old API,
  these are default initialised. With new API the other parameters are
  default initialised. Actually a better approach is to create two
  builder impls and to decide which one to use based on the
  constructor of the builder.

*** COMPLETED Do not compute inclusion directives for system models   :story:
    CLOSED: [2016-09-26 Mon 15:23]

*Rationale*: Fixed with new inclusion expander. We only compute
directives as a last resort.

It seems we are computing inclusion directives and other path
derivatives for system models:

: {
:   "__type__": "dogen::cpp::expansion::path_derivatives",
:   "file_path": "/home/marco/Development/DomainDrivenConsulting/output/dogen/clang-3.5/stage/bin/../test_data/all_primitives/actual/std/include/std/serialization/unique_ptr_fwd_ser.hpp",
:   "header_guard": "STD_SERIALIZATION_UNIQUE_PTR_FWD_SER_HPP",
:   "inclusion_directive": "<quote>std/serialization/unique_ptr_fwd_ser.hpp<quote>"
: }

This comes out of the workflow, so we possibly are then ignoring it
for the non-target types. So:

- can we avoid computing these altogether?
- are we ignoring it?

Actually this is the usual problem with the "origin" of the type. We
need a way to determine if this type needs computations or not. We
need to create a story to clean up the =origin_type= and
=generation_type= and then we can make use of it to determine if we
need to compute inclusion, path etc or not.

*** COMPLETED Add reducer to quilt.cpp                                :story:
    CLOSED: [2016-09-26 Mon 15:36]
    CLOCK: [2016-09-26 Mon 15:14]--[2016-09-26 Mon 15:36] =>  0:22

Removes all types that are non-generatable.

Merged stories:

*Add filter to quilt.cpp*

Removes the non-target formattables.

*** COMPLETED Add new index to formtter container                     :story:
    CLOSED: [2016-09-26 Mon 17:48]
    CLOCK: [2016-09-26 Mon 16:56]--[2016-09-26 Mon 17:15] =>  0:19

It is actually quite useful to look for a formatter by formatter
name. We should provide this in formatter container and use it from
inclusion expander.

*** COMPLETED Add path expander to quilt.cpp                          :story:
    CLOSED: [2016-09-26 Mon 17:49]
    CLOCK: [2016-09-26 Mon 17:16]--[2016-09-26 Mon 17:49] =>  0:33
    CLOCK: [2016-09-26 Mon 16:39]--[2016-09-26 Mon 16:55] =>  0:16

Generates the full paths.

*** COMPLETED Add guard expander to quilt.cpp                         :story:
    CLOSED: [2016-09-26 Mon 18:17]
    CLOCK: [2016-09-26 Mon 17:50]--[2016-09-26 Mon 18:17] =>  0:27

Generates the header guards. Merged with path generator.

*** COMPLETED Investigate borked travis build                         :story:
    CLOSED: [2016-09-26 Mon 18:38]
    CLOCK: [2016-09-26 Mon 20:43]--[2016-09-26 Mon 21:05] =>  0:22
    CLOCK: [2016-09-26 Mon 18:18]--[2016-09-26 Mon 18:33] =>  0:15

We seem to have borked the build some how:

https://travis-ci.org/DomainDrivenConsulting/dogen/builds/162785692
https://travis-ci.org/DomainDrivenConsulting/dogen/builds/162801645

Hopefully this is just due to not running tests locally. Checkout a
worktree and check.

: git worktree add ../dogen_1fd4399 origin/master
: cd ../dogen_1fd4399/
: mkdir build/output
: build/scripts/build.linux.sh Release gcc /usr/local/personal run_knit.tests

Problem reproduced locally, must have forgotten to run the tests.

: Running 33 test cases...
: ../../../../projects/knit/tests/workflow_tests.cpp(203): error: in "workflow_tests/trivial_inheritance_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(233): error: in "workflow_tests/std_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(239): error: in "workflow_tests/boost_model_generates_expected_code": check generate_and_diff(target) has failed
: ../../../../projects/knit/tests/workflow_tests.cpp(245): error: in "workflow_tests/stereotypes_model_generates_expected_code": check generate_and_diff(target) has failed
:
: *** 4 failures are detected in the test module "knit_tests"
: ninja: build stopped: subcommand failed.

Actually, the problem persists. It seems this is related to clean
builds. We seem to have lost service forward declarations.

*** COMPLETED Add decoration expander to quilt.cpp                    :story:
    CLOSED: [2016-09-26 Mon 21:24]
    CLOCK: [2016-09-26 Mon 21:19]--[2016-09-26 Mon 21:24] =>  0:05
    CLOCK: [2016-09-26 Mon 18:34]--[2016-09-26 Mon 18:52] =>  0:18

Generates the decoration.

Merged stories:

*Add file properties generator to to quilt.cpp*

We need to generate the file properties for each formattable. The
formatter must supply the modeline name. At present we have a hack in
element properties to determine the modeline.

*** COMPLETED Add aspect expander to quilt.cpp                        :story:
    CLOSED: [2016-09-26 Mon 22:51]
    CLOCK: [2016-09-26 Mon 21:25]--[2016-09-26 Mon 22:51] =>  1:26

Generates the aspect configuration.

- first generate a container with aspect annotations.
- then use it to compute aspect configurations; populate those
  directly into the formattable.

*** COMPLETED Run tests that are passing on windows                   :story:
    CLOSED: [2016-09-27 Tue 08:19]
    CLOCK: [2016-09-26 Mon 21:06]--[2016-09-26 Mon 21:16] =>  0:10

At present we have a release build on windows but we are not running
any tests. This is because some of the tests are failing at the
moment. We should run all test suites that are green to ensure we
don't regress without noticing.

Look at the stories with errors to determine which tests are passing.

*** COMPLETED Add helper expander to quilt.cpp                        :story:
    CLOSED: [2016-09-27 Tue 09:46]
    CLOCK: [2016-09-27 Tue 08:19]--[2016-09-27 Tue 09:45] =>  1:26

Generates the helper configuration.

*** COMPLETED Merge pre and post workflows                            :story:
    CLOSED: [2016-09-27 Tue 10:03]
    CLOCK: [2016-09-27 Tue 09:47]--[2016-09-27 Tue 10:03] =>  0:16

It seems we don't have much of a post reduction workflow. Merge them.

*** COMPLETED Add formattable element                                 :story:
    CLOSED: [2016-09-27 Tue 10:05]

*Rationale*: we introduced the type in the previous sprint. The
hooking of it is a different story.

Create a top-level formattable type that is an aggregation of the
element and the element configuration. Update workflow to output a
list of formattable and formatters to take in formattable.

Previous understanding:

- create a top-level type that has formatter, element properties and
  element. Must be non-generatable. Add formattable id as the sum of
  element id and formatter id.
- add =formattables::model= as an unordered map of id to
  formattable. Implement formatting workflow in terms of formattables
  model. Add all context properties to model such as
  streaming_settings_repository and helpers_. element_settings should
  be merged with configuration.
- remove formatting context and update formatting workflow to call a
  visitor to resolve the element and then call the formatter.
- add an enablement map for all formatters in the formatter

*** CANCELLED Move name builder into yarn                             :story:
    CLOSED: [2016-09-27 Tue 10:07]

*Rationale*: It was used only during formattables generation for the
helpers. The one method was moved into the expander.

At present we have name builder in quilt.cpp simply to build the
merged namespaces. We should have some kind of utility for this in
yarn.

*** CANCELLED Move registration of providers to initialiser           :story:
    CLOSED: [2016-09-27 Tue 10:07]

*Rationale*: No longer applies since provider refactor.

At present we are iterating through the formatters list in properties
and manually registering all include providers via the interface. This
is not ideal because the formatter interface needs to know of include
providers, meaning we can't move it away from =quilt.cpp=.

When we register a formatter we should also register the include
provider too.

Tasks:

- add provider support directly to the formatters instead of another
  class and remove registration from formatter interface.
- add a static registrar for the include providers in workflow.
- change initialiser to register the include providers from the same
  shared pointer.

*** CANCELLED Implement all formatter interfaces                      :story:
    CLOSED: [2016-09-27 Tue 10:10]

*Rationale*: we implemented primitives. there is no need to do this
for concepts.

We still have a couple of skeleton interfaces:

- primitives
- concepts

We should throw if formatting is required.

*** CANCELLED Remove =optional<list>=                                 :story:
    CLOSED: [2016-09-27 Tue 10:12]

*Rationale*: we've already done a few of these. This story is too much
of an epic to be useful.

We should not really be using optional<list>. The empty list is
sufficient for this.

Uses:

- include provider. Fixed with other story.

*** COMPLETED Formatters with duplicate names result in non-intuitive errors :story:
    CLOSED: [2016-09-27 Tue 10:10]

*Rationale*: completed with the addition of the formatter by formatter
name container. We now get a duplicate formatter id exception.

We added two formatters to io with the same name by mistake and the
resulting error was not particularly enlightening:

: std::exception::what: Qualified name defined more than once: cpp.io.enum_header_formatter.inclusion_required

We should have a very early on validation to ensure formatters have
distinct names.

Merged stories:

*Check for duplicate formatter names in formatter registrar*

At present it is possible to register a formatter name more than
once. Registrar should keep track of the names and throw if the name
is duplicated.

*** COMPLETED Fix bug in aspect and helper generation                 :story:
    CLOSED: [2016-09-27 Tue 10:58]
    CLOCK: [2016-09-27 Tue 10:43]--[2016-09-27 Tue 10:58] =>  0:15

It seems we are updating non-target types for these configurations but
we weren't before. This caused a break in the verification that
somehow was not spotted.

*** COMPLETED Investigate element annotation support                  :story:
    CLOSED: [2016-09-27 Tue 20:39]
    CLOCK: [2016-09-27 Tue 20:17]--[2016-09-27 Tue 20:39] =>  0:22
    CLOCK: [2016-09-27 Tue 10:59]--[2016-09-27 Tue 12:14] =>  1:15
    CLOCK: [2016-09-27 Tue 10:14]--[2016-09-27 Tue 10:42] =>  0:28

The new formattables do not yet support element annotations. Figure
out if we need to. Seems like we did a brutal hack and left the
processing of "element annotations" to the formatters
themselves. Also, now its clearer why we thought of an annotation
expander (which we since removed).

The right thing to do:

- rename element annotations to opaque annotations
- add opaque annotations to element configuration
- add a opaque annotations expander to read them into the element
  configuration.

Actually we should just avoid the element annotations altogether as
they make no sense at all. Create an opaque configuration and add it
at the correct level in formatter configuration.

Tried to add a verification step but its just too hard, what with
shared pointers etc.

*** CANCELLED Add streaming settings expander                         :story:
    CLOSED: [2016-09-28 Wed 09:39]
    CLOCK: [2016-09-27 Tue 20:55]--[2016-09-27 Tue 21:17] =>  0:22
    CLOCK: [2016-09-27 Tue 20:40]--[2016-09-27 Tue 20:54] =>  0:14

Add streaming settings to the element properties and populate them via
a new expander.

Actually we need to revert this change as these settings need to be
across the whole model.

*** COMPLETED Create the formattables model                           :story:
    CLOSED: [2016-09-28 Wed 09:40]
    CLOCK: [2016-09-28 Wed 08:30]--[2016-09-28 Wed 09:31] =>  1:01
    CLOCK: [2016-09-27 Tue 21:43]--[2016-09-27 Tue 21:50] =>  0:07
    CLOCK: [2016-09-27 Tue 21:18]--[2016-09-27 Tue 21:42] =>  0:24

There are a couple of properties that are shared by all
formattables. One way of solving this is to create a top-level
container for all formattables that also has these properties.

- create model class
- update workflow to return model
- update verification code.
- remove streaming settings from element, delete streaming expander.
- update streaming annotations factory to return correct container.
- create a model factory and a formattables factory. Model factory
  simply assembles model. Formattables workflow hooks them together.

*** COMPLETED Hook formattables into formatters                       :story:
    CLOSED: [2016-09-28 Wed 21:38]
    CLOCK: [2016-09-28 Wed 20:20]--[2016-09-28 Wed 21:38] =>  1:18
    CLOCK: [2016-09-28 Wed 11:39]--[2016-09-28 Wed 12:16] =>  0:37
    CLOCK: [2016-09-28 Wed 11:17]--[2016-09-28 Wed 11:38] =>  0:21
    CLOCK: [2016-09-28 Wed 11:01]--[2016-09-28 Wed 11:16] =>  0:15
    CLOCK: [2016-09-28 Wed 10:36]--[2016-09-28 Wed 11:00] =>  0:24
    CLOCK: [2016-09-28 Wed 09:32]--[2016-09-28 Wed 10:35] =>  1:03

Find a way to format out of the formattables container, side-by-side
with the current formatting workflow.

- remove element annotations from context, use element configuration
  instead.
- create a new formatters workflow that uses formattables.

*** COMPLETED Remove empty context                                    :story:
    CLOSED: [2016-09-28 Wed 22:21]

*Rationale*: done as part of refactor.

We were generating empty contexts before in context factory, but this
should not be required any longer.

<*** COMPLETED Remove include builder legacy classes                   :story:
    CLOSED: [2016-09-28 Wed 22:48]
    CLOCK: [2016-09-28 Wed 22:22]--[2016-09-28 Wed 22:48] =>  0:26
    CLOCK: [2016-09-28 Wed 21:38]--[2016-09-28 Wed 22:21] =>  0:43

When implementing inclusion expander we did a number of ugly hacks to
support both the legacy API and the new API. We need to remove all the
impls etc we added, in builder, factory, etc.

Merged stories:

*Remove all of the legacy infrastructure*

Includes:

- repositories, repository factories in formattables, annotations.

*** COMPLETED Review main classes in quilt.cpp                        :story:
    CLOSED: [2016-09-30 Fri 10:57]
    CLOCK: [2016-09-30 Fri 10:10]--[2016-09-30 Fri 10:57] =>  0:47
    CLOCK: [2016-09-29 Thu 16:30]--[2016-09-29 Thu 17:30] =>  1:00
    CLOCK: [2016-09-29 Thu 13:50]--[2016-09-29 Thu 14:34] =>  0:44
    CLOCK: [2016-09-29 Thu 10:21]--[2016-09-29 Thu 10:47] =>  0:26
    CLOCK: [2016-09-29 Thu 09:42]--[2016-09-29 Thu 09:53] =>  0:11
    CLOCK: [2016-09-29 Thu 09:07]--[2016-09-29 Thu 09:41] =>  0:34

After the large refactor we probably ended up with a lot of loose ends
in quilt.cpp. Do a cursory review of the code.

*** COMPLETED Clean up element segmentation                           :story:
    CLOSED: [2016-09-30 Fri 12:37]
    CLOCK: [2016-09-30 Fri 11:17]--[2016-09-30 Fri 12:37] =>  1:20

Originally we added all element segments at the same level. But in
truth:

- there are always two segments;
- one of which is the "master" segment: the one with "is element
  extension" set to false.

We should formalise this and make the configuration model reflect it.

*** COMPLETED Get OSX build to compile code                           :story:
    CLOSED: [2016-10-01 Sat 23:02]
    CLOCK: [2016-10-01 Sat 22:52]--[2016-10-01 Sat 23:03] =>  0:11
    CLOCK: [2016-10-01 Sat 20:31]--[2016-10-01 Sat 22:51] =>  2:20
    CLOCK: [2016-10-01 Sat 12:30]--[2016-10-01 Sat 13:40] =>  1:10
    CLOCK: [2016-09-30 Fri 23:52]--[2016-10-01 Sat 00:35] =>  0:43
    CLOCK: [2016-09-30 Fri 22:05]--[2016-09-30 Fri 23:52] =>  1:47
    CLOCK: [2016-09-30 Fri 21:10]--[2016-09-30 Fri 22:04] =>  0:54

We've added the initial support for OSX. However, it still needs a lot
of work:

- we can't install the conan package because we don't know how to
  install pkg files. We should raise a ticket on conan for this.
- Alternatively we could build boost ourselves and upload it to
  DropBox.

Notes:

- [[http://www.mactech.com/articles/mactech/Vol.26/26.02/TheFlatPackage/index.html][The Flat Package]]
- [[https://docs.travis-ci.com/user/multi-os/][Matrix with multiple OSs]]

*** COMPLETED Add a banner to readme                                  :story:
    CLOSED: [2016-10-02 Sun 11:54]
    CLOCK: [2016-10-02 Sun 09:20]--[2016-10-02 Sun 10:49] =>  1:29

It would be nice to have some kind of banner to make the readme a bit
more interesting.

*** COMPLETED Remove formatter group                                  :story:
    CLOSED: [2016-10-02 Sun 22:05]
    CLOCK: [2016-10-02 Sun 21:42]--[2016-10-02 Sun 22:05] =>  0:23

It seems we are not using this at present.

Merged stories:

*Consider supporting multiple formatter groups*

In some cases it would be nice for a field to belong to multiple
groups. For example =integrated_facet= is only applicable to class
header formatters. We could implement this by making the formatter
group a collection and having formatters belong to multiple groups.

*** COMPLETED Add more types to =quilt::cpp= canned tests             :story:
    CLOSED: [2016-10-02 Sun 22:21]
    CLOCK: [2016-10-02 Sun 22:06]--[2016-10-02 Sun 22:21] =>  0:15

Originally we used the =*_info= types in the canned tests, but these
are all about to be removed. We need to hunt for types in the
=quilt::cpp= model and add those to the canned tests.

*** COMPLETED Consider renaming model module to root module           :story:
    CLOSED: [2016-10-03 Mon 08:38]

*Rationale*: this seems to have been already done.

It would be more sensible to call it root module rather than model
module. We should also create a root module property in the model to
make it easier to locate.

*** CANCELLED Remove formatter id                                     :story:
    CLOSED: [2016-10-03 Mon 10:13]
    CLOCK: [2016-09-28 Wed 22:49]--[2016-09-28 Wed 22:53] =>  0:04

*Rationale*: in the new world, formatter names are different from
artefact names so we will need something like formatter id.

Not clear why we need this given we have formatter name.

Actually this requires a little bit of thinking as we use the id's in
the helper formatters.

*** COMPLETED Analysis around terminology in formatting space         :story:
    CLOSED: [2016-10-03 Mon 10:19]
    CLOCK: [2016-10-03 Mon 08:20]--[2016-10-03 Mon 08:59] =>  0:39
    CLOCK: [2016-10-02 Sun 17:08]--[2016-10-02 Sun 18:55] =>  1:47
    CLOCK: [2016-10-02 Sun 16:09]--[2016-10-02 Sun 17:07] =>  0:58

One part of the language which has not yet been clarified is around
formatters. We use the term "formatter" to mean several things:

- a formatting function in formatting space which produces a file; and
  we think of this file as also an entity in formatting space;
- a formatting function in formatting space which produces a part of a
  file - an aspect; we call these helpers at present.
- all of the infrastructure around file generation such as
  boilerplate, etc - the formatters model.

The biggest problem is that this conceptual approach does not
distinguish between the formatter and the conceptual entity underlying
it.

Another way of looking at this is that we have the artefact space,
made up of all the entities that compose a project. An artefact maps
one to one to a file, but a file is a specific representation on a
filesystem, file server etc whereas the artefact is the conceptual
notion behind it. However, the content of the file and the content of
the artefact are byte-wise identical for a given (imaginary) artefact
id. One takes an artefact in memory and expresses it as a file.

Artefacts are instances of archetypes. An archetype of an artefact is
akin to a class of an object; it is its meta-type. Archetypes live in
archetype space, which is partitioned hierarchically by facet,
sub-kernel and kernel.

Archetypes are uniquely identified by their id. An example of an
archetype id is =quilt.cpp.types.class_header=, where =quilt= is the
kernel, =cpp= is the sub-kernel, =types= the facet and =class_header=
the archetype group. Configuration/annotations binds to archetype ids.

Formatting functions (i.e. formatters) take in a set of arguments and
generate artefacts. Formatters inherit the taxonomy of the archetype
of the artefacts they generate. The formatter id is the archetype id
plus the postfix =_formatter=. Formatters are also grouped like
archetypes: =class_header= etc, but they are also support additional
arbitrary grouping via labels (header files, cmakefiles, etc).

Modeling space is made up of entities. Entities abstract one or more
archetypes. One entity is represented by a set of element segments
with a cardinality of one or two. One of the elements is called the
master element and the other is called the extension element.

There is a stereotype called =formatter=. When a type is marked as
=formatter= the user must supply a stitch template in the filesystem
with a name of the class and the extension =.stitch=. The wale
templates are fixed. Wale templates must be part of dogen data. The
expected stitch sections must be present (include dependencies,
format).

=quilt.cpp= has a formatting mode which intercepts the stereotype and
then does additional processing such as if "non-generatable" only
generate if there is no file, if formatter do wale/stitch, etc.

Renames:

- file: artefact
- file formatter: artefact formatter
- ownership_hierarchy: archetype_location, model_name becomes kernel,
  facet name becomes facet and formatter name archetype. Add
  sub-kernel.
- Element concept becomes Entity.

*** COMPLETED Remove =original_model_name=                            :story:
    CLOSED: [2016-10-03 Mon 13:51]
    CLOCK: [2016-10-03 Mon 13:35]--[2016-10-03 Mon 13:51] =>  0:16

This does not seem to be used any longer.

*** COMPLETED Refactor code around model origination                  :story:
    CLOSED: [2016-10-03 Mon 15:30]
    CLOCK: [2016-10-03 Mon 15:24]--[2016-10-03 Mon 15:30] =>  0:06
    CLOCK: [2016-10-03 Mon 14:16]--[2016-10-03 Mon 15:23] =>  1:07
    CLOCK: [2016-10-03 Mon 13:56]--[2016-10-03 Mon 14:15] =>  0:19
    CLOCK: [2016-10-03 Mon 13:52]--[2016-10-03 Mon 13:56] =>  0:04
    CLOCK: [2016-10-03 Mon 13:24]--[2016-10-03 Mon 13:35] =>  0:11
    CLOCK: [2016-10-03 Mon 10:22]--[2016-10-03 Mon 12:43] =>  2:21

We have the following use cases around generation type and
origination:

- serialisation registrar needs to know which of the references are
  "real" (dogen; non-proxy) models and which are proxy models. We are
  only interested in calling the registrars for the "real" models.
- inclusion directives should only be generated for the target and
  non-proxy models.
- in a target model, we need to distinguish between elements for which
  the overwrite flag will be false (services; non-generatable) and
  those for which it will be true (all others).
- in a target model, we need to determine which formatters will be
  enabled for a given element. For services at present we just have
  types. All other types enable all formatters.
- we need to filter out all non-target elements before we code
  generate.

Tasks:

- add field for is proxy reference
- add new enum in origin types for not yet determined
- in yarn, read field; if set to proxy reference, update all model
  elements.
- update json code to stop reading origin types, remove it from json
  and add it as a field in meta-data. Alternatively, JSON has the
  flag, and field is specific to dia; frontend just sets the model
  origin and leaves the rest as undetermined; yarn pipeline sets it
  correctly.

*Previous Understanding*

- remove origin types and generation types, replacing it with just a
  boolean for is target. Actually we need something like:
  proxy_reference, non_proxy_reference, target. We also need a good
  name for this enumeration.
- add a model-level flag: is empty. It is true if there are no model
  elements. has_generatable_types is then is_target && !is_empty.
- at present we are using origin type to determine whether to create a
  registrar, etc in cpp model. There is no other use case for
  this. This is done in several places due to the bad handling of C++
  specific types. Grep for =references= in =cpp= to find all
  locations. We could split references into two (dogen, non-dogen). Or
  references could have a origin type too.
- we should also replace has generatable types with something more
  like "target model has types" or "is target model empty". The idea
  we are trying to capture is that the target model contained at least
  one type. This could be set by the merger when it processes the
  target model.

*Previous Understanding*

In the past we added a number of knobs around generation, all with
their own problems:

- =origin_types=: was the model/type created by the user or the
  system. in reality this means did the model come from Dia or
  JSON. this is confusing as the user can also add JSON files (their
  own model library) and in the future the user can use JSON
  exclusively without needed Dia at all.
- =generation_types=: if the model is target, all types are to be
  generated /unless/ they are not properly supported, in which case
  they are to be "partially" generated (as is the case with
  services). This is a formatter decision and yarn should not know
  anything about it. Actually this is not quite true; users may want
  to stop generation.

These can be replaced by a single enumeration that indicates if the
type/model is target or not.

This work should be integrated with the model types story.

Merged stories:

*Split references into dogen and non-dogen models*

If we had two containers of references, one for dogen models and
another one for non-dogen models - which we could give a nice name, to
imply its foreign origin - we could then use the dogen references for
registrar, etc. This is a replacement for the origin type.

We need a good name for these. Candidates:

- proxy model: represents something that exists in the outside
  world. e.g. =is_proxy=.

*Remove =service= stereotype*

This really just means non-generatable, or do not generate. We already
have a stereotype for this. Remove =service= and any other stereotype
which is not being used such as =value_object= etc.

Actually, non-generatable is not a stereotype really. We should
instead have some meta-data that can affect generation:

- do not generate: do nothing at all. For references only. If a file
  exists with this file name, it will be deleted as part of
  housekeeping.
- generate blank file if it doesn't exist: we don't even want a
  template.
- generate with content if it doesn't exist, do not touch otherwise:
  what we call services at the moment. Generate a "template" that then
  gets filled in manually.
- generate and merge: merge the contents of the generated file with
  the current contents in the file system. When we support merging.
- generate and overwrite: generate the file and overwrite whatever
  exists in the file system.

This could be called "generation policy".

The second behaviour we get for free with services is that we disable
all facets except for types. A few points:

- we may want to have io, serialisation, etc. This is not possible at
  present. If a state of a service is made up of supported types, we
  could even use existing code generation.
- in order for this to be implemented correctly we need to hook in to
  the enablement management somehow. In addition, it seems each facet
  can have its own generation policy. For example we may want to
  manually create types but automatically generate io.
- the best way to handle this may be to setup "enablement profiles"
  that the user can hook up to. For example we could have a "default"
  profile that enables all facets (or uses facet defaults), a second
  "service" profile that enables types with partial generation and io
  with full generation and so on. We probably also need "generation
  profiles" to go with "enablement profiles".

*Allow creating "system" models in Dia*

With the "proxy/non-proxy" models refactoring, we now have all the
bits in place to allow users to create "system" models from Dia (what
we now call proxy models). The only tasks missing are:

- add meta-data to dia subsystem to allow users to supply a "is proxy"
  flag.
- post-process model if is proxy flag is set, updating all types to
  proxy references.

Actually this is probably best handled in yarn, so that dia and json
have common logic. We should just add the fields and add the
processing in yarn somewhere.

*** COMPLETED Remove formatter level facet folders                    :story:
    CLOSED: [2016-10-03 Mon 16:02]
    CLOCK: [2016-10-03 Mon 16:03]--[2016-10-03 Mon 16:05] =>  0:02
    CLOCK: [2016-10-03 Mon 15:58]--[2016-10-03 Mon 16:02] =>  0:04

We seem to have two of these, but the real one is at the model level.

Merged stories:

*Move facet directory to a better place*

At present we have this property at the formatter configuration level,
but its not clear why we need to duplicate it. In fact, it may even
make more sense to have it at a higher level since its the same for
all elements.

*** COMPLETED Consider removing the "fake" primitive formatters       :story:
    CLOSED: [2016-10-03 Mon 20:38]
    CLOCK: [2016-10-03 Mon 20:37]--[2016-10-03 Mon 20:38] =>  0:01

It is actually not possible to remove these formatters without major
changes to the code. Instead, we introduce the notion of "pseudo"
formatters which do not actually format (they will throw if attempts
are made). Pseudo formatters make the conceptual model consistent and
work well with aliases.

*Previous Understanding*

We need to support a strange use case: where the formatter does not
exist for a given element type. For example, we do not have primitive
formatters, but there are directives set in them:

#+begin_src json-mode
        {
            "meta_type" : "primitive",
            "simple_name" : "uint64_t",
            "extensions" : {
                "quilt.cpp.helper.family" : "Number",
                "quilt.cpp.aspect.requires_manual_default_constructor" : true,
                "quilt.cpp.types.class_header_formatter.inclusion_directive" : "<cstdint>",
                "quilt.cpp.hash.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.io.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.test_data.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.serialization.class_header_formatter.inclusion_required" : false,
                "quilt.cpp.odb.class_header_formatter.inclusion_required" : false
            }
        },
#+end_src

The problem with this is that if we do not have a formatter for
primitives, then we will not read the directives. In the past this
worked because we were processing the cross-product of formatters and
element sub-types, so the mistake of
=quilt.cpp.types.class_header_formatter.inclusion_directive= was
actually resulted in the correct result. But of course, we cannot
replace class_header_formatter with the correct formatter name (as we
don't have one). Nor does it sound good to have to hard-code the
formatter name against the type. One way to solve this is with
canonical formatters:

- use the canonical formatter name in the declaration
- ensure we always read directives for the canonical formatter from
  the meta-data.
- when processing, only set the canonical formatter if it was not
  already set by meta-data.

When testing the fix, we need to delete the mock formaters created for
primitives.

Actually this won't work. This is because we do not have a canonical
formatter for these types. What we need instead is to read and store
these fields by facet as well. This is a bit of a problem because we
are now saying that some times we want to resolve a facet name into a
canonical formatter, but some other times we want to resolve a facet
name directly into a inclusion directive. We could do as follows:

- first try as is;
- if failed, try resolving name using facet to canonical.

Basically, we need to extract enablement information from
formattables. This container is then augmented with facet
information. This is obtained in two ways:

- using facet directives directly, if available;
- mapping facet to canonical and using the canonical;

*** COMPLETED Expander refactor in =quilt.cpp=                        :story:
    CLOSED: [2016-10-04 Tue 10:29]
    CLOCK: [2016-10-04 Tue 10:30]--[2016-10-04 Tue 10:37] =>  0:07
    CLOCK: [2016-10-04 Tue 09:59]--[2016-10-04 Tue 10:29] =>  0:30
    CLOCK: [2016-10-04 Tue 09:42]--[2016-10-04 Tue 09:58] =>  0:16
    CLOCK: [2016-10-03 Mon 22:30]--[2016-10-03 Mon 23:06] =>  0:36
    CLOCK: [2016-10-03 Mon 20:59]--[2016-10-03 Mon 22:29] =>  1:30
    CLOCK: [2016-10-03 Mon 20:53]--[2016-10-03 Mon 20:57] =>  0:04

We found some fundamental impedance mismatches whilst handling
enablement, which mean we need to change the expanders once again.

Tasks:

- change model to map of formattable.
- add facet configuration with enabled and directory.
- make the expanders "model expanders" rather than formattable
  expanders.
- update the file path expander to also compute the facet directories;
  for this we need to supply the path annotations. Actually we should
  just add another expander (facet_directory_expander?).
- update the enablement expander to also compute: a) facet enabelment
  b) enablement by id.
- update assistant with a "is facet xxx enabled".
- add a "facet dependencies" to formatter interface. Add a "enabled
  facet dependencies" to formatter configuration. During enablement,
  check to see if the facet dependency is enabled and if so, add it to
  the container. During formatting, assistant supplies a "is facet
  dependency enabled" method that queries the container. This is used
  for odb in cmakelists.

Merged stories:

*Add facet configuration to element configuration*

At present we need:

- facet folder
- enabled

We need to also add a "is facet enabled" method in assistant.

*** COMPLETED Create the notion of a formatter alias                  :story:
    CLOSED: [2016-10-04 Tue 13:14]
    CLOCK: [2016-10-04 Tue 12:05]--[2016-10-04 Tue 13:14] =>  1:09
    CLOCK: [2016-10-04 Tue 10:51]--[2016-10-04 Tue 12:04] =>  1:13
    CLOCK: [2016-10-04 Tue 10:37]--[2016-10-04 Tue 10:50] =>  0:13
    CLOCK: [2016-10-03 Mon 20:39]--[2016-10-03 Mon 20:51] =>  0:12
    CLOCK: [2016-10-03 Mon 20:09]--[2016-10-03 Mon 20:37] =>  0:28

Tasks:

- add a new trait for canonical formatters: facet + ".canonical";
- create a map of canonical formatter to actual formatter during model
  generation. Supply the map to the inclusion expander and from there
  to the inclusion builder.
- before we build the includes, first resolve it against the map; if
  it resolves, use the formatter name from resolution, if not use the
  original.
- map is copied across to model and from model into context.
- when formatting registrar, for each leaf ask if the formatter is
  enabled. Supply the id of the leaf and the serialisation facet; use
  the map to resolve the facet to a formatter name. If the id is not
  enabled, do not add it to registrar.
- in assistant, replace "is serialisation enabled" etc with calls to
  the canonical formatter instead. Remove those that are not in
  use. Make the name reflect the fact that we are looking at the
  canonical formatter.

*Previous Understanding*

We did a bit of a hack with mapping the facet to the default
formatter. What we really need is the notion of an alias. It still
looks like a formatter name (for example "header_formatter") but it
must be first resolved into an actual formatter. For this we need a
type index.

Other names:

- canonical formatter
- reference formatter

*** COMPLETED Remove enabled formatters from formatter configuration  :story:
    CLOSED: [2016-10-04 Tue 17:56]
    CLOCK: [2016-10-04 Tue 13:50]--[2016-10-04 Tue 14:12] =>  0:22

We left some remnants of the legacy approach. Remove and tidy-up
around this area.

*** COMPLETED Handle registration of services properly                :story:
    CLOSED: [2016-10-04 Tue 18:55]
    CLOCK: [2016-10-04 Tue 18:53]--[2016-10-04 Tue 18:55] =>  0:01
    CLOCK: [2016-10-04 Tue 18:13]--[2016-10-04 Tue 18:52] =>  0:39
    CLOCK: [2016-10-04 Tue 17:50]--[2016-10-04 Tue 18:12] =>  0:22
    CLOCK: [2016-10-04 Tue 14:21]--[2016-10-04 Tue 14:41] =>  0:20
    CLOCK: [2016-10-04 Tue 13:15]--[2016-10-04 Tue 13:20] =>  0:05
    CLOCK: [2016-10-03 Mon 20:01]--[2016-10-03 Mon 20:08] =>  0:07
    CLOCK: [2016-10-03 Mon 17:55]--[2016-10-03 Mon 19:02] =>  1:07
    CLOCK: [2016-10-03 Mon 16:07]--[2016-10-03 Mon 16:39] =>  0:32
    CLOCK: [2016-10-03 Mon 15:44]--[2016-10-03 Mon 15:58] =>  0:14
    CLOCK: [2016-10-03 Mon 15:31]--[2016-10-03 Mon 15:44] =>  0:13

The only way to do this is to filter the list of leaves by enabled
formatters. We need a container of enabled formatters by element id at
the formattable model level.

Problems:

- we need to be able to cope with lookups by facet id, e.g. is odb
  facet enabled? I don't necessarily have a qname or if I do, it may
  not have all of the formatters required (e.g. cmakelists).
- we need to be able to cope with lookups by canonical formatter name,
  e.g. I have included name x in types but I don't know what formatter
  it corresponds to.

Both of these problems have been addressed on their own stories. We
can now tackle leaves.

Tasks:

- change context to have the entire formattables model; setup the
  resolver and use it in is formatter name enabled.
- use the resolver to check if each leaf is enabled for serialisation
  using the canonical formatter. This can be a helper method in
  assistant.

*Previous Understanding*

We need a flag to determine if a class should contribute its leaves or
not. By default, if it is hand-crafted it does not contribute
leaves. This could (eventually) be overridable by users.

*Previous Understanding*

We need a way to determine if a type which is part of a generalisation
should be added to the registrar or not. In =generalisation_indexer=:

:     // FIXME: massive hack. must not add leafs for services.

One way would be to check if serialisation is enabled for that type
and if not, skip the type.

Another way is to check if the type is generatable. If not, skip
it. If we do it this way we need to wait for the generatable clean up.

*** CANCELLED Supply formatter's container to injector                :story:
    CLOSED: [2016-10-04 Tue 19:11]

*Rationale*: this would involve having to remove the utility method
for registration. In this particular case we'll keep the lack of
transparency.

At present the injector is calling the formatters' workflow
directly, in order to obtain the formatters' container. It should
receive it as a parameter during initialisation.

*** COMPLETED Introduce the concept of proxy models                   :story:
    CLOSED: [2016-10-04 Tue 19:12]

*Rationale*: this was completed as part of the origin types refactor.

These are models that exist solely to bring types in, but do not
define those types. Typically one uses a proxy model to expose
non-dogen types into dogen. We could add a flag to models
=is_proxy=. It would replace the notion of system models. We need to
check the stories in the backlog around this.

Interestingly we could have different defaults for formatters in proxy
models. For example, if a model is proxy we can assume that we should
not compute inclusion paths. This could save a lot of time when
specifying the models in JSON.

*** COMPLETED Add more validation to formatter registration           :story:
    CLOSED: [2016-10-04 Tue 19:12]

*Rationale*: this was completed as part of the leaves tidy-up.

We should check to ensure that only one formatter per facet is
declared the canonical formatter.

*** COMPLETED Check which properties need to loop through the entire model :story:
    CLOSED: [2016-10-04 Tue 19:14]

*Rationale*: the expander rewrite took care of this; all expanders are
now filtering as required.

In certain cases such as helpers we probably don't need to go through
all types; only the target types matter. Ensure we are not processing
other types for no reason.

Merged stories:

*Element properties includes non-target types*

We seem to be generating a lot of element properties and formatter
properties as well. We should only be generating these for the target
model.

*** COMPLETED Check generation type before dispatching element        :story:
    CLOSED: [2016-10-04 Tue 19:15]

*Rationale*: This was addressed with the expanders refactor.

At present we are doing this check in =visit=:

:     if (o.generation_type() == yarn::generation_types::no_generation)
:        return;

If we did it before the =visit= call we'd save the cost of
dispatching.

*** COMPLETED Move stereotypes to element                             :story:
    CLOSED: [2016-10-05 Wed 21:46]
    CLOCK: [2016-10-05 Wed 21:25]--[2016-10-05 Wed 21:46] =>  0:21

We need to have the ability to add stereotypes to any element.

*** COMPLETED Improve project banner                                  :story:
    CLOSED: [2016-10-06 Thu 09:13]
    CLOCK: [2016-10-06 Thu 09:14]--[2016-10-06 Thu 09:18] =>  0:04
    CLOCK: [2016-10-06 Thu 08:45]--[2016-10-06 Thu 09:13] =>  0:28

Do a couple of minor cosmetic changes to project banner.

*** CANCELLED Add support for profiles                                :story:
    CLOSED: [2016-10-06 Thu 10:21]
    CLOCK: [2016-10-06 Thu 09:14]--[2016-10-06 Thu 09:56] =>  0:42
    CLOCK: [2016-10-05 Wed 23:13]--[2016-10-05 Wed 23:24] =>  0:11
    CLOCK: [2016-10-05 Wed 22:15]--[2016-10-05 Wed 23:12] =>  0:57
    CLOCK: [2016-10-05 Wed 21:47]--[2016-10-05 Wed 22:14] =>  0:27
    CLOCK: [2016-10-05 Wed 21:04]--[2016-10-05 Wed 21:24] =>  0:20
    CLOCK: [2016-10-05 Wed 20:46]--[2016-10-05 Wed 21:03] =>  0:17
    CLOCK: [2016-10-05 Wed 15:22]--[2016-10-05 Wed 18:14] =>  2:52
    CLOCK: [2016-10-05 Wed 14:53]--[2016-10-05 Wed 15:21] =>  0:28
    CLOCK: [2016-10-05 Wed 13:01]--[2016-10-05 Wed 14:52] =>  1:51
    CLOCK: [2016-10-05 Wed 11:40]--[2016-10-05 Wed 12:15] =>  0:35
    CLOCK: [2016-10-05 Wed 11:17]--[2016-10-05 Wed 11:28] =>  0:11
    CLOCK: [2016-10-05 Wed 10:10]--[2016-10-05 Wed 11:16] =>  1:06
    CLOCK: [2016-10-05 Wed 09:26]--[2016-10-05 Wed 10:09] =>  0:43

At present we have to manually add a lot of configuration to each
model. In truth, most of the configuration is the same for a group of
models. It would be great to provide canned configurations that users
can reuse (or add their own) and then refer to in the model.

Tasks:

- add data files to specify profiles, with classes to read them in
  from JSON. Profiles must be settable to global or local.
- add meta-data to allow users to supply a profile (local or global).
- update enablement expander to look for profiles.
- update decoration expander to use profiles.
- update all facet test models to use profiles.

Algorithm:

- for each formatter, get its facet. Need formatter container.
- set model enabled or default it.
- see if facet enabled is set on meta-data.
  - if it is, set it.
  - if its not, see if there is a default facet profile. If so, see if
    its enabled or not.
  - if there is no default facet profile, see if there is a facet
    specific profile. If so, see if its enabled or not.
  - if nothing was found, get the default value of the meta-data.
- see if formatter enabled is set on meta-data.
  - if it is, set it.
  - if its not, see if there is a default formatter profile. If so,
    see if its enabled or not.
  - if there is no default formatter profile, see if there is a
    formatter specific profile. If so, see if its enabled or not.
  - if nothing was found, get the default value of the meta-data.

*** COMPLETED Move emacs to rtags                                     :spike:
    CLOSED: [2016-10-09 Sun 17:04]
    CLOCK: [2016-10-08 Sat 09:02]--[2016-10-08 Sat 13:02] =>  4:00
    CLOCK: [2016-10-08 Sat 21:02]--[2016-10-08 Sat 22:30] =>  1:28

Our present emacs setup is costly:

- no ide-like features meaning renames, lookups etc take longer than
  needed;
- problems with ede mode on loading large compilation databases and
  locking up emacs.

Try to move to a full rtags setup.

*** COMPLETED Refactor =yarn.dia= transformer                         :story:
    CLOSED: [2016-10-07 Fri 11:34]
    CLOCK: [2016-10-07 Fri 11:08]--[2016-10-07 Fri 11:35] =>  0:27
    CLOCK: [2016-10-07 Fri 10:32]--[2016-10-07 Fri 11:07] =>  0:35
    CLOCK: [2016-10-07 Fri 10:07]--[2016-10-07 Fri 10:31] =>  0:24
    CLOCK: [2016-10-07 Fri 09:01]--[2016-10-07 Fri 10:06] =>  1:05
    CLOCK: [2016-10-07 Fri 00:23]--[2016-10-07 Fri 00:48] =>  0:25
    CLOCK: [2016-10-06 Thu 23:34]--[2016-10-07 Fri 00:22] =>  0:48
    CLOCK: [2016-10-06 Thu 22:47]--[2016-10-06 Thu 23:34] =>  0:47
    CLOCK: [2016-10-06 Thu 22:23]--[2016-10-06 Thu 22:46] =>  0:23
    CLOCK: [2016-10-06 Thu 20:36]--[2016-10-06 Thu 21:33] =>  0:57
    CLOCK: [2016-10-06 Thu 20:20]--[2016-10-06 Thu 20:35] =>  0:15
    CLOCK: [2016-10-06 Thu 15:40]--[2016-10-06 Thu 17:06] =>  1:26
    CLOCK: [2016-10-06 Thu 13:23]--[2016-10-06 Thu 14:40] =>  1:17

Renames:

- processed object => object
- object processor => object factory
- profiler => profile factory
- processed comment => comment
- processed attribute => attribute
- comment processor => comment factory

Renames abandoned; they cause clashes with the names in dia. There are
no good alternatives, so we'll just stick with "processed" as a way of
distinguishing names across models.

Tasks:

- rename context to repository and make it const for the
  transformer. The only reason why we are mutating it now is because
  of the =id_to_name= container. It must be possible to update this
  container from outside the transformer.
- transformer should just return an element for a given processed
  object; we should then dispatch the list and insert the elements
  into the appropriate containers.
- in workflow =transformation_activity= we should move the logic of
  defaulting to value object into the profiler.
- the transformer should ensure only zero or one notes can exist for a
  module.
- the setting of the documentation should be done as a separate step
  in transformation - i.e. look for =dia.comment= field, if set, use
  its value to populate documentation. This could be done to all types
  for completeness.
- the workflow should not be creating transformers half-way
  through. They should be as stateless as possible.
- tests need to be cleaned up - we need to check for text of the
  exception being thrown.

Actually this is not quite so straight forward. We could move the
logic of dispatching outside of transformer, but we have to bear in
mind we are traversing a graph, so this would have to be done in the
graph itself - not ideal. This story needs more thinking.

*** COMPLETED Create a dynamic expander in yarn                       :story:
    CLOSED: [2016-10-08 Sat 00:19]
    CLOCK: [2016-10-08 Sat 00:01]--[2016-10-08 Sat 00:19] =>  0:18
    CLOCK: [2016-10-07 Fri 23:06]--[2016-10-07 Fri 23:59] =>  0:52
    CLOCK: [2016-10-07 Fri 23:01]--[2016-10-07 Fri 23:05] =>  0:04
    CLOCK: [2016-10-07 Fri 22:20]--[2016-10-07 Fri 23:00] =>  0:40
    CLOCK: [2016-10-07 Fri 18:44]--[2016-10-07 Fri 19:01] =>  0:17
    CLOCK: [2016-10-07 Fri 18:08]--[2016-10-07 Fri 18:43] =>  0:35
    CLOCK: [2016-10-07 Fri 17:25]--[2016-10-07 Fri 18:07] =>  0:42
    CLOCK: [2016-10-07 Fri 15:31]--[2016-10-07 Fri 15:59] =>  0:28
    CLOCK: [2016-10-07 Fri 13:09]--[2016-10-07 Fri 13:15] =>  0:06
    CLOCK: [2016-10-07 Fri 12:53]--[2016-10-07 Fri 13:08] =>  0:15
    CLOCK: [2016-10-07 Fri 12:46]--[2016-10-07 Fri 12:52] =>  0:06
    CLOCK: [2016-10-07 Fri 11:55]--[2016-10-07 Fri 12:45] =>  0:50
    CLOCK: [2016-10-07 Fri 11:36]--[2016-10-07 Fri 11:54] =>  0:18
    CLOCK: [2016-10-06 Thu 13:03]--[2016-10-06 Thu 13:23] =>  0:20

We need to move this work from the front end into yarn.

Notes:

- move raw kvps to dynamic
- as first step, add dynamic expander doing one object at a time;
  remove all references to workflow.
- look at stitch code and see how this refactor will impact it.

Tasks:

- add a map of string to raw kvps in intermediate model. Populate it
  from the frontend.
- remove all uses of dynamic in the frontends
- add an expander that takes the map and generates the dynamic
  objects. Update intermediate model with them.
- change dynamic workflow to take all of the objects in one go (plus
  the root object name) and return all dynamic objects against the
  element id.

*** COMPLETED Create a streaming configuration expander               :story:
    CLOSED: [2016-10-09 Sun 16:28]
    CLOCK: [2016-10-09 Sun 15:13]--[2016-10-09 Sun 16:28] =>  1:15

Tasks:

- create class, move code from workflow into it.
- move all annotations code into it.
- make use of container in helper expander.
- delete streaming annotations, factory etc in annotations.

*** COMPLETED Merge helper annotations with helper expander           :story:
    CLOSED: [2016-10-09 Sun 16:43]
    CLOCK: [2016-10-09 Sun 16:29]--[2016-10-09 Sun 16:43] =>  0:14

- Move code from annotations.

*** COMPLETED Merge aspect annotations with expander                  :story:
    CLOSED: [2016-10-09 Sun 17:00]
    CLOCK: [2016-10-09 Sun 16:44]--[2016-10-09 Sun 17:00] =>  0:16

Get rid of the annotations for aspects.

*** COMPLETED Merge inclusion directive annotations                   :story:
    CLOSED: [2016-10-09 Sun 18:01]
    CLOCK: [2016-10-09 Sun 17:01]--[2016-10-09 Sun 18:00] =>  0:59

Get rid of the annotations for inclusion directives.

*** COMPLETED Merge path annotations with locator                     :story:
    CLOSED: [2016-10-09 Sun 23:21]
    CLOCK: [2016-10-09 Sun 22:56]--[2016-10-09 Sun 23:21] =>  0:25
    CLOCK: [2016-10-09 Sun 21:38]--[2016-10-09 Sun 22:55] =>  1:17
    CLOCK: [2016-10-09 Sun 20:45]--[2016-10-09 Sun 21:37] =>  0:52

The only class using path annotations is now the locator. Move all the
infrastructure to generate them into locator.

*** COMPLETED Refactor facet directory expander                       :story:
    CLOSED: [2016-10-09 Sun 23:21]

Read meta-data for directory name direclty rather than use path
annotations.

Merged stories:

*Refactor path annotations factory*

As part of this work we should also look at how the facet directory
expander is computing the facet directory; we are going through all
formatters. We could just read the facet information.

Tasks:

- get distinct list of facets across all formatters and generate field
  definitions from this list;
- cache top-level fields and facet fields and copy results instead of
  re-reading them.

*** CANCELLED Merge annotations with formattables                      :epic:
    CLOSED: [2016-10-10 Mon 09:04]
    CLOCK: [2016-10-09 Sun 10:41]--[2016-10-09 Sun 13:14] =>  2:33
    CLOCK: [2016-10-08 Sat 10:41]--[2016-10-08 Sat 10:43] =>  0:02

*Rationale*: the epic does not add any value now we created individual
stories.

Originally we split annotations from formattables because we thought
they had enough responsibilities to stand on their own as
classes. However, its now clear that the only job of the annotations
is to provide data for one expander. It makes a lot more sense to have
it all in one class.

Tasks:

- merge path annotations with model expander
- create separate annotations for facet directory expander
- merge streaming annotations and helper annotations with helper
  expander
- merge inclusion directive annotations with inclusion expander and
  possibly get rid of factory
- merge aspect annotations with aspect expander
- merge opaque annotations with opaque annotations expander and move
  all other opaque classes into formattables
- delete annotations namespace.

Actually this is an epic, so we'll track tasks on its own stories.

Merged stories:

*Drop annotations prefix in yarn*

Tasks:

- merge traits into each factory;
- do not use the name annotations - just drop the prefix.

*** POSTPONED Clean up terminology in dynamic                         :story:
    CLOSED: [2016-10-10 Mon 08:59]
    CLOCK: [2016-10-08 Sat 10:30]--[2016-10-08 Sat 10:41] =>  0:11
    CLOCK: [2016-10-08 Sat 08:20]--[2016-10-08 Sat 09:16] =>  0:56

We have to do a number of renames to make space for profilers:

- rename object aggregates to something slightly more sensible as it
  clashes with previous uses of the term aggregation in dynamic.
- rename property scope type to attribute in dynamic
- rename fields to field_definitions in data;
- rename definition types to instantiation types;
- hydration workflow is field definition factory
- json hydrator is field definition hydrator
- repository is field definition repository
- repository factory should be merged into field definition factory
- repository selector is field definition selector

Actually this rename is a bit more profound than we originally
anticipated. The objective of dynamic is to provide a way to annotate
objects in yarn (well, anywhere in theory). Interpreting some
[[https://en.wikipedia.org/wiki/Text_annotation][annotation terminology]] fairly liberally we have:

- fields folder renamed to annotations.
- dynamic -> annotations
- object -> annotation. The marker for the annotation is the linkage
  between the annotation and the yarn element it annotates. Fields
  become the body of the annotation.
- field instance -> entry.
- field instance definition -> entry template.
- field definition -> split into type and type template. JSON file can
  contain both. Add some kind of meta-data to figure out the type.
- field definition types: template types
- json_hydrator -> type_hydrator
- repository ->  type_repository
- repository workflow: merge repository factory, repository workflow,
  hydration workflow into a type repository factory.
- raw aggregate: scribbles, scribble group?
- object aggregate: annotation group (and top level container
  annotation groups). In annotation group we have parent and
  children. Also add a flag for is master/root.
- scopes: remove unused scopes. Rest of the scopes should be root,
  top-level, child (avoid references to yarn concepts).
- workflow: annotation groups factory. Takes in scribble groups.

*** POSTPONED Rewrite profile support                                 :story:
    CLOSED: [2016-10-10 Mon 08:59]
    CLOCK: [2016-10-06 Thu 10:20]--[2016-10-06 Thu 11:30] =>  1:10
    CLOCK: [2016-10-06 Thu 10:03]--[2016-10-06 Thu 10:19] =>  0:16

Our first stab at implementing profiles was a valiant effort but sadly
it was not the right approach. Profiles need to be implemented
directly into dynamic, and they must be totally transparent to the
layers above.

The profile structure is very similar to what we did in v1, but we
must implement it in terms of dynamic infrastructure:

- we need to make use of dynamic templates to expand facets and
  formatters, and to refer to instances;

Tasks:

- implement all of the new dynamic classes
- remove profiles in quilt.cpp and ensure the code works with the
  profile expansion. Update models to make use of global profiles.
- we need to supply a list of stereotypes to dynamic workflow, against
  the id's that have them. If we can find a profile with the
  stereotype name, apply it.

*** POSTPONED Generate formatter interfaces                            :epic:
    CLOSED: [2016-10-10 Mon 08:59]
    CLOCK: [2016-10-04 Tue 18:56]--[2016-10-04 Tue 19:05] =>  0:09
    CLOCK: [2016-09-30 Fri 10:58]--[2016-09-30 Fri 11:17] =>  0:19

We should create another template language, in addition to stitch:
"wale". Wale is a very simple language that has templates that just do
token replacement. The tokens must have a special format:
={{{TOKEN}}}=. We receive a map of keys to values and do a blind
replacement to the keys on the wale document.

This links to stitch as follows:

- create a single file implementation of a formatter. It will
  implement both the provider interface and the appropriate formatter
  interface. It will call the stitch method to start off with. There
  are no headers, just cpp. It does the formatter registration.
- add support in stitch for "named sections": its possible to start a
  section and assign it a name. A stitch template will have two
  sections: inclusion provision and formatting.
- add support in stitch for "wale variables". These are just kvp's
  defined at the top:

: <#@ wale.variable="formatter_name=abcd" #>

  wale variables and sections are converted into a kvp container for
  wale input. Examples: facet, formatter name, etc.
- convert the formatter code into a wale template, adding wale
  variables as required.
- update stitch to detect wale usage and to call wale in those
  cases. This could be done by supplying a wale template:

: <#@ wale.template="abcd.wale" #>

- note that wale could be useful outside of stitch, for example for
  dart: we could wale-lise utility and then instantiate it for a given
  project.

*Previous Understanding*

It should be possible to generate some trivial types such as formatter
interfaces, formatter container, registrar and so on. For this we
need:

- a mustache type template;
- a set of fields from yarn types to be exposed to mustache;
- a list of types to iterate through.

Once we got this we could instantiate the templates. To integrate this
with knit we would need some way of specifying which types the
iteration would be over. We could mark a specific type with a given
stereotype, and then supply say the base class ("all leaf descendants
of xyz"). Dogen would then locate the descendants and for each call
the template.

For registrar and container its a bit trickier because we want a
collection of types in one go.

We also need a way to keep these templates away from the main (user
visible) code, since they are useful only for dogen.

See also [[https://github.com/cierelabs/boostache/tree/develop][boostache]].

Notes:

- we will need some "special" tags for copyright, includes
  etc. Includes will be particularly special because we need to
  augment the include list with additional includes. However, we may
  not even need to be aware of this.

*Stitch meta-templates*

*Note*: re-read story [[https://github.com/DomainDrivenConsulting/dogen/blob/master/doc/agile/sprint_backlog_64.org#code-generating-formatters-as-text-templates][Code-generating formatters as text templates]] as
some of these ideas were already there. Also: see [[https://github.com/no1msd/mstch][mstch]].

In the quest for defining a single stitch template which then becomes
a formatter - without any additional infrastructure required at all -
we hit on an idea: stitch meta-templates. Basically we would have two
different kinds of inputs to stitch: the template itself and the
meta-template. Meta-template is a provisional name. The meta-template
would define the formatter layout:

- class definition, using a stitch variable for the yarn element type
- registration of the formatter
- definition of a method for the includes
- definition of a method for the stitching

These last two would result in the creation of "regions". These
regions must then be "instantiated" in the template. This could easily
be achieved with some kind of new element:

: <#% region "includes">

Or some such stitch construct. All lines after this line are part of
the region "includes" until a new region is defined. The region is
stitched and then transposed to the place in the meta-template where
it was defined, for example:

: int f(int a, int b) {
: <#% region "includes">
: }

Would result in copying across the region into these brackets. This
will make defining multiple functions very easy, without having to
supply command line arguments, etc.

Notes:

- meta-templates are supplied as command line arguments.
- potential extension: =meta.stitch=
- stitch should still work on non-meta-template mode.
- some of these ideas had already been covered on another story but
  can't find it in backlog. It could be part of the original stitch
  epic. We need to revisit it to see if it contains additional
  insights.
- when an error occurs, it would be great if we could pin point the
  error to the template or to the meta-template. This is more of a
  concern when we add clang compilation support.

Further thoughts:

- there are two approaches for this: we could integrate stitch tighter
  with knit and have it return "chunks" of processed code instead of
  files. As per story "Integration of stitch and dogen", dogen would
  then be responsible for writing the header file as per methods
  defined in the class diagram. Each method would be marked as a
  region. Meta-data in the class associates a template with the
  class. Knitter uses stitch to convert the template into regions, and
  then takes these regions and inserts them into a generated
  file. This approach is very clever and requires a lot of machinery.
- the easier approach uses meta-templates. Class diagram associates
  both meta-template and template with class via meta-data. We could
  possibly also have a stitch stereotype to make it clearer. Yarn has
  a stitch class with attributes of these parameters. Dogen
  instantiates stitch (probably within quilt) with the parameters and
  generates the file. Actually we probably can't have this in quilt
  because we still need formatter properties.

** Deprecated
*** CANCELLED Consider caching "all modules" in location              :story:
    CLOSED: [2016-10-02 Sun 20:39]

*Rationale*: we don't have enough use cases to justify the
cost. Instead we created the name flattener in yarn.

At present we are adding the module lists together to build the
qualified name; location could have a "all modules" list that
concatenates external, model and internal modules. We should look at
performance before doing this change though.

We are also using this information in =quilt.cpp= via the name builder
(this is the only reason it cannot be removed). Adding it to the
name/location is a bit painful since we use it in a lot of places, but
we have other options:

- create a service to do the merging and do it on the fly
- add a method to nameable with the flat module list.

Merged stories:

*Add "namespaces" to name*

Name should have a flat class with all namespaces in yarn, instead of
generating it on every formatter.
*** CANCELLED Consider reducing the number of qname lookups in cpp model :story:
    CLOSED: [2016-10-02 Sun 20:40]

*Rationale*: The refactoring of quilt reduced the look-ups.

At present we are still using =yarn::name= in a lot of repositories in
quilt. We already had one go in moving to id's but there are still
quite a few left. Investigate to see if there are more that can be
moved.

*** CANCELLED Group the file related fields under a prefix            :story:
    CLOSED: [2016-10-02 Sun 20:42]

*Rationale*: this does not line up with the new understanding of the
conceptual model.

Now we have =element= as a prefix, it probably makes sense to also
group the fields that are related to file names, paths etc. These
could be under =file= or perhaps =paths=? Examples:

- =quilt.cpp.file.include_directory_name=
- =quilt.cpp.source_directory_name=

*** CANCELLED Element formatter should have a container api           :story:
    CLOSED: [2016-10-02 Sun 20:45]

*Rationale*: Not applicable after the =quilt.cpp= refactor.

In general, where the client is performing a loop over a well known
container and then calling a method, we should add an API for that
well known container. This is the case with the element formatter.

This also reduces the number of splices done by the calling code. All
the logging should be done in the element formatter as well.

*** CANCELLED Perform an in-depth product backlog groom                :epic:
    CLOSED: [2016-10-02 Sun 21:04]

*Rationale*: we've added the tags; the process is continuous so the
story does not add any value.

We now have lots of references to types (and models) that have been
refactored away - either renamed or deleted altogether. As we are
reaching the final form for =yarn= and =quilt=, we need to go
through all the stories and update them to the new world.

- add two todos to the backlog: not reviewed, reviewed
  (=<REVIEWING>=). Actually, added org mode tag support for this to
  make it more obvious and filterable.
- mark all stores as not reviewed
- go through all the stories and mark them suitably as we review them.

*** CANCELLED Create a set of definitions for tagging and meta-data   :story:
    CLOSED: [2016-10-02 Sun 21:12]

*Rationale*: This is part of the conceptual model work.

We still use these terms frequently. We should define them in dynamic
to have specific meanings.
*** CANCELLED Handling of managed directories is incorrect            :story:
    CLOSED: [2016-10-02 Sun 21:14]

*Rationale*: its not clear this is a problem at present.

At present we are querying the yarn dia importer to figure out what
the managed directories are. These are basically the top-level
directories from where we want the housekeeper to operate. In reality
this is (or can be placed) in the meta-data. We should be able to
extract the managed directories from the meta-data as a step in one of
the workflows.

This can be done by the backend. It does mean that we should be
returning a composite type from generation:

- list of files;
- list of managed directories.

Alternatively we could have a =managed_directories= method that takes
in an yarn model and then internally reads in the meta-data for a given
model to produce the list.

*Merged with previous story*

Compute managed directories from knitting options

At present the backend is returning empty managed directories. This
means housekeeping will fail in the new world. We need to change the
interface of this method to take in the knitting options and return
the managed directories.

This is not entirely trivial. At present the managed directories are
computed in the locator. It takes into account split project, etc to
come up with all the directories used by the backend. We need to make
these decisions during path expansion, expect we only need manged
directories for the root object. However we do not know which object
is the root object at present, during the expansion. We could identify
it via the QName and the yarn model in context thought. We could then
populate the managed directories as a text collection. We then need
some settings and a factory to pull out the managed directories from
the root object. This could be done in =managed_directories=, by
having an yarn model as input.

*** CANCELLED Header guard in formatters should be optional           :story:
    CLOSED: [2016-10-02 Sun 21:15]

*Rationale*: new approach is to use =empty()= where available.

At present we are relying on empty header guards to determine what to
do in boilerplate. We should use boost optional.

*** CANCELLED Add kvp support to =identifier_parser=                  :story:
    CLOSED: [2016-10-02 Sun 21:24]

*Rationale*: This is only done in yarn.dia these days.

We have code to split kvps all over the place. We should do this in a
single pace, and use boost spirit or tokenizer. For one such
implementation with spirit see:

[[http://boost-spirit.com/home/2010/02/24/parsing-skippers-and-skipping-parsers/][Parsing Skippers and Skipping Parsers]]
*** CANCELLED Create =src= and =include= facets                       :story:
    CLOSED: [2016-10-02 Sun 21:36]

*Rationale*: according to the new conceptual model, these are not
facets; the formatter is just selecting a different physical location
for the artefact.

At present we have some formatters that are not in the traditional
facets such as =types=, etc. We should make facets for them. We need
to check what the current facet name is. There should only be one case
of this, the CMakeLists formatters.
*** CANCELLED Move enabled formatters to element configuration        :story:
    CLOSED: [2016-10-04 Tue 19:08]

*Rationale*: this is now handled correctly.

All elements have the same view of enabled formatters.

*** CANCELLED Move enabled formatters to a higher level               :story:
    CLOSED: [2016-10-04 Tue 19:09]

*Rationale*: this is now handled correctly.

At present we have =enabled_formatters= at the formatter level. This
should be at the element level. It can't be model level because
eventually we will have different enablement configurations for each
formatter.
